<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Anatomy of an Implementation · LearnAPI.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LearnAPI.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li class="is-active"><a class="tocitem" href>Anatomy of an Implementation</a><ul class="internal"><li><a class="tocitem" href="#Defining-a-model-type"><span>Defining a model type</span></a></li><li><a class="tocitem" href="#A-method-to-fit-the-model"><span>A method to fit the model</span></a></li><li><a class="tocitem" href="#Operations"><span>Operations</span></a></li><li><a class="tocitem" href="#Accessor-functions"><span>Accessor functions</span></a></li><li><a class="tocitem" href="#traits"><span>Model traits</span></a></li><li><a class="tocitem" href="#Training-data-types"><span>Training data types</span></a></li><li><a class="tocitem" href="#Input-types-for-operations"><span>Input types for operations</span></a></li><li><a class="tocitem" href="#workflow"><span>Illustrative fit/predict workflow</span></a></li></ul></li><li><a class="tocitem" href="../reference/">Reference</a></li><li><a class="tocitem" href="../fit_update_and_ingest/">Fit, update and ingest</a></li><li><a class="tocitem" href="../operations/">Predict and other operations</a></li><li><a class="tocitem" href="../accessor_functions/">Accessor Functions</a></li><li><a class="tocitem" href="../optional_data_interface/">Optional Data Interface</a></li><li><a class="tocitem" href="../model_traits/">Model Traits</a></li><li><a class="tocitem" href="../common_implementation_patterns/">Common Implementation Patterns</a></li><li><a class="tocitem" href="../testing_an_implementation/">Testing an Implementation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Anatomy of an Implementation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Anatomy of an Implementation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaAI/LearnAPI.jl/blob/dev/docs/src/anatomy_of_an_implementation.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Anatomy-of-an-Implementation"><a class="docs-heading-anchor" href="#Anatomy-of-an-Implementation">Anatomy of an Implementation</a><a id="Anatomy-of-an-Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Anatomy-of-an-Implementation" title="Permalink"></a></h1><blockquote><p><strong>Summary.</strong> A <strong>model</strong> is just a container for hyper-parameters. A basic implementation of the ridge regressor requires implementing <code>fit</code> and <code>predict</code> methods dispatched on the model type; <code>predict</code> is an example of an <strong>operation</strong> (another is <code>transform</code>). In this example we also implement an <strong>accessor function</strong>, called <code>feature_importance</code>, returning the absolute values of the linear coefficients. The ridge regressor has a target variable and <code>predict</code> makes literal predictions of the target (rather than, say, probabilistic predictions); this behavior is flagged by the <code>predict_proxy</code> model trait.  Other traits articulate the model&#39;s training data type requirements and the input/output type of <code>predict</code>.</p></blockquote><p>We begin by describing an implementation of LearnAPI.jl for basic ridge regression (no intercept) to introduce the main actors in any implementation.</p><h2 id="Defining-a-model-type"><a class="docs-heading-anchor" href="#Defining-a-model-type">Defining a model type</a><a id="Defining-a-model-type-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-a-model-type" title="Permalink"></a></h2><p>The first line below imports the lightweight package LearnAPI.jl whose methods we will be extending, the second, libraries needed for the core algorithm.</p><pre><code class="language-julia hljs">using LearnAPI
using LinearAlgebra, Tables</code></pre><p>Next, we define a struct to store the single hyper-parameter <code>lambda</code> of this model:</p><pre><code class="language-julia hljs">struct MyRidge &lt;: LearnAPI.Model
        lambda::Float64
end</code></pre><p>The subtyping <code>MyRidge &lt;: LearnAPI.Model</code> is optional but recommended where it is not otherwise disruptive.</p><p>Instances of <code>MyRidge</code> are called <strong>models</strong> and <code>MyRidge</code> is a <strong>model type</strong>.</p><p>A keyword argument constructor providing defaults for all hyper-parameters should be provided:</p><pre><code class="language-julia hljs">MyRidge(; lambda=0.1) = MyRidge(lambda)</code></pre><h2 id="A-method-to-fit-the-model"><a class="docs-heading-anchor" href="#A-method-to-fit-the-model">A method to fit the model</a><a id="A-method-to-fit-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#A-method-to-fit-the-model" title="Permalink"></a></h2><p>A ridge regressor requires two types of data for training: <strong>input features</strong> <code>X</code> and a <a href="../#scope"><strong>target</strong></a> <code>y</code>. Training is implemented by overloading <code>fit</code>. Here <code>verbosity</code> is an integer (<code>0</code> should train silently, unless warnings are needed):</p><pre><code class="language-julia hljs">function LearnAPI.fit(model::MyRidge, verbosity, X, y)

        # process input:
        x = Tables.matrix(X)  # convert table to matrix
        s = Tables.schema(X)
        features = s.names

        # core solver:
        coefficients = (x&#39;x + model.lambda*I)\(x&#39;y)

        # prepare output - learned parameters:
        fitted_params = (; coefficients)

        # prepare output - model state:
        state = nothing  # not relevant here

        # prepare output - byproducts of training:
        feature_importances =
                [features[j] =&gt; abs(coefficients[j]) for j in eachindex(features)]
        sort!(feature_importances, by=last) |&gt; reverse!
        verbosity &gt; 0 &amp;&amp; @info &quot;Features in order of importance: $(first.(feature_importances))&quot;
        report = (; feature_importances)

        return fitted_params, state, report
end</code></pre><p>Regarding the return value of <code>fit</code>:</p><ul><li><p>The <code>fitted_params</code> variable is for the model&#39;s learned parameters, for passing to <code>predict</code> (see below).</p></li><li><p>The <code>state</code> variable is only relevant when additionally implementing a <a href="../fit_update_and_ingest/#LearnAPI.update!"><code>LearnAPI.update!</code></a> or <a href="../fit_update_and_ingest/#LearnAPI.ingest!"><code>LearnAPI.ingest!</code></a> method (see <a href="../fit_update_and_ingest/#Fit,-update!-and-ingest!">Fit, update! and ingest!</a>).</p></li><li><p>The <code>report</code> is for other byproducts of training, apart from the learned parameters (the ones we&#39;ll need to provide <code>predict</code> below).</p></li></ul><p>Our <code>fit</code> method assumes that <code>X</code> is a table (satisfies the <a href="https://github.com/JuliaData/Tables.jl">Tables.jl spec</a>) whose rows are the observations; and it will need need <code>y</code> to be an <code>AbstractFloat</code> vector. A model implementation is free to dictate the representation of data that <code>fit</code> accepts but articulates its requirements using appropriate traits; see <a href="#Training-data-types">Training data types</a> below. We recommend against data type checks internal to <code>fit</code>; this would ordinarily be the responsibility of a higher level API, using those traits. </p><h2 id="Operations"><a class="docs-heading-anchor" href="#Operations">Operations</a><a id="Operations-1"></a><a class="docs-heading-anchor-permalink" href="#Operations" title="Permalink"></a></h2><p>Now we need a method for predicting the target on new input features:</p><pre><code class="language-julia hljs">function LearnAPI.predict(::MyRidge, fitted_params, Xnew)
    Xmatrix = Tables.matrix(Xnew)
    report = nothing
    return Xmatrix*fitted_params.coefficients, report
end</code></pre><p>In some models <code>predict</code> computes something of interest in addition to the target prediction, and this <code>report</code> item is returned as the second component of the return value. When there&#39;s nothing to report, we must return <code>nothing</code>, as here.</p><p>Our <code>predict</code> method is an example of an <strong>operation</strong>. Other operations include <code>transform</code> and <code>inverse_transform</code> and a model can implement more than one. For example, a K-means clustering model might implement a <code>transform</code> for dimension reduction, and a <code>predict</code> to return cluster labels.</p><h2 id="Accessor-functions"><a class="docs-heading-anchor" href="#Accessor-functions">Accessor functions</a><a id="Accessor-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Accessor-functions" title="Permalink"></a></h2><p>The arguments of an operation are always <code>(model, fitted_params, data...)</code>. The interface also provides <strong>accessor functions</strong> for extracting information, from the <code>fitted_params</code> and/or fit <code>report</code>, that is shared by several model types.  There is one for feature importances that we can implement for <code>MyRidge</code>:</p><pre><code class="language-julia hljs">LearnAPI.feature_importances(::MyRidge, fitted_params, report) =
    report.feature_importances</code></pre><p>Another example of an accessor function is <a href="../accessor_functions/#LearnAPI.training_losses"><code>LearnAPI.training_losses</code></a>.</p><h2 id="traits"><a class="docs-heading-anchor" href="#traits">Model traits</a><a id="traits-1"></a><a class="docs-heading-anchor-permalink" href="#traits" title="Permalink"></a></h2><p>Our model has a target variable, in the sense outlined in <a href="../#scope">Scope and undefined notions</a>, and <code>predict</code> returns an object with exactly the same form as the target. We indicate this behavior by declaring</p><pre><code class="language-julia hljs">LearnAPI.predict_proxy(::Type{&lt;:MyRidge}) = LearnAPI.TrueTarget()</code></pre><p>Or, you can use the shorthand</p><pre><code class="language-julia hljs">@trait MyRidge predict_proxy=LearnAPI.TrueTarget()</code></pre><p>More generally, <code>predict</code> only returns a <em>proxy</em> for the target, such as probability distributions, and we would make a different declaration here. See <a href="../operations/#Target-proxies">Target proxies</a> for details.</p><p><code>LearnAPI.predict_proxy</code> is an example of a <strong>model trait</strong>. A complete list of traits and the contracts they imply is given in <a href="../model_traits/#Model-Traits">Model Traits</a>.</p><p>We also need to indicate that a target variable appears in training (this is a supervised model). We do this by declaring <em>where</em> in the list of training data arguments (in this case <code>(X, y)</code>) the target variable (in this case <code>y</code>) appears:</p><pre><code class="language-julia hljs">@trait MyRidge position_of_target=2</code></pre><p>As explained in the introduction, LearnAPI.jl does not attempt to define strict model &quot;types&quot;, such as &quot;regressor&quot; or &quot;clusterer&quot;. However, we can optionally specify suggestive descriptors, as in</p><pre><code class="language-julia hljs">@trait MyRidge descriptors=(:regression,)</code></pre><p>but note that this declaration promises nothing. Do <code>LearnAPI.descriptors()</code> to get a list of available descriptors.</p><p>Finally, we are required to declare what methods (excluding traits) we have explicitly overloaded for our type:</p><pre><code class="language-julia hljs">@trait MyRidge methods=(
        :fit,
        :predict,
        :feature_importances,
)</code></pre><h2 id="Training-data-types"><a class="docs-heading-anchor" href="#Training-data-types">Training data types</a><a id="Training-data-types-1"></a><a class="docs-heading-anchor-permalink" href="#Training-data-types" title="Permalink"></a></h2><p>Since LearnAPI.jl is a basement level API, one is discouraged from including explicit type checks in an implementation of <code>fit</code>. Instead one uses traits to make promises about the acceptable type of <code>data</code> consumed by <code>fit</code>. In general, this can be a promise regarding the ordinary type of <code>data</code> or the <a href="https://github.com/JuliaAI/ScientificTypes.jl">scientific type</a> of <code>data</code> (but not both). Alternatively, one may only make a promise about the type/scitype of <em>observations</em> in the data . See <a href="../model_traits/#Model-Traits">Model Traits</a> for further details. In this case we&#39;ll be happy to restrict the scitype of the data:</p><pre><code class="language-julia hljs">import ScientificTypesBase: scitype, Table, Continuous
@trait MyRidge fit_scitype = Tuple{Table(Continuous), AbstractVector{Continuous}}</code></pre><p>This is a contract that <code>data</code> is acceptable in the call <code>fit(model, verbosity, data...)</code> whenever</p><pre><code class="language-julia hljs">scitype(data) &lt;: Tuple{Table(Continuous), AbstractVector{Continuous}}</code></pre><p>Or, in other words:</p><ul><li><p><code>X</code> in <code>fit(model, verbosity, X, y)</code> is acceptable, provided <code>scitype(X) &lt;: Table(Continuous)</code> - meaning that <code>X</code> <code>Tables.istable(X) == true</code> (see <a href="https://github.com/JuliaData/Tables.jl">Tables.jl</a>) and each column has some <code>&lt;:AbstractFloat</code> element type.</p></li><li><p><code>y</code> in <code>fit(model, verbosity, X, y)</code> is acceptable if <code>scitype(y) &lt;: AbstractVector{Continuous}</code> - meaning that it is an abstract vector with <code>&lt;:AbstractFloat</code> elements.</p></li></ul><h2 id="Input-types-for-operations"><a class="docs-heading-anchor" href="#Input-types-for-operations">Input types for operations</a><a id="Input-types-for-operations-1"></a><a class="docs-heading-anchor-permalink" href="#Input-types-for-operations" title="Permalink"></a></h2><p>An optional promise about what <code>data</code> is guaranteed to work in a call like <code>predict(model, fitted_params, data...)</code> is articulated this way:</p><pre><code class="language-julia hljs">@trait MyRidge predict_input_scitype = Tuple{AbstractVector{&lt;:Continuous}}</code></pre><p>Note that <code>data</code> is always a <code>Tuple</code>, even if it has only one component (the typical case), which explains the <code>Tuple</code> on the right-hand side.</p><p>Optionally, we may express our promise using regular types, using the <a href="../model_traits/#LearnAPI.predict_input_type"><code>LearnAPI.predict_input_type</code></a> trait.</p><p>One can optionally make promises about the outut of an operation. See <a href="../model_traits/#Model-Traits">Model Traits</a> for details.</p><h2 id="workflow"><a class="docs-heading-anchor" href="#workflow">Illustrative fit/predict workflow</a><a id="workflow-1"></a><a class="docs-heading-anchor-permalink" href="#workflow" title="Permalink"></a></h2><p>Here&#39;s some toy data for supervised learning:</p><pre><code class="language-julia hljs">using Tables

n = 10          # number of training observations
train = 1:6
test = 7:10

a, b, c = rand(n), rand(n), rand(n)
X = (; a, b, c) |&gt; Tables.rowtable
y = 2a - b + 3c + 0.05*rand(n)</code></pre><p>Instantiate a model with relevant hyperparameters (which is all the object stores):</p><pre><code class="language-julia hljs">model = MyRidge(lambda=0.5)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Main.MyRidge(0.5)</code></pre><p>Train the model (the <code>0</code> means do so silently):</p><pre><code class="language-julia hljs">import LearnAPI: fit, predict, feature_importances

fitted_params, state, fit_report = fit(model, 0, X[train], y[train])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((coefficients = [1.6216077238538527, 0.023129720841819107, 2.1367815917890507],), nothing, (feature_importances = [:c =&gt; 2.1367815917890507, :a =&gt; 1.6216077238538527, :b =&gt; 0.023129720841819107],))</code></pre><p>Inspect the learned parameters and report:</p><pre><code class="language-julia hljs">@info &quot;training outcomes&quot; fitted_params fit_report</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: training outcomes
│   fitted_params = (coefficients = [1.6216077238538527, 0.023129720841819107, 2.1367815917890507],)
└   fit_report = (feature_importances = [:c =&gt; 2.1367815917890507, :a =&gt; 1.6216077238538527, :b =&gt; 0.023129720841819107],)</code></pre><p>Inspect feature importances:</p><pre><code class="language-julia hljs">feature_importances(model, fitted_params, fit_report)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Pair{Symbol, Float64}}:
 :c =&gt; 2.1367815917890507
 :a =&gt; 1.6216077238538527
 :b =&gt; 0.023129720841819107</code></pre><p>Make a prediction using new data:</p><pre><code class="language-julia hljs">yhat, predict_report = predict(model, fitted_params, X[test])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([1.9084966585898386, 1.436132657451369, 1.96302908074303, 0.31213973477199686], nothing)</code></pre><p>Compare predictions with ground truth</p><pre><code class="language-julia hljs">deviations = yhat - y[test]
loss = deviations .^2 |&gt; sum
@info &quot;Sum of squares loss&quot; loss</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Sum of squares loss
└   loss = 0.6197559508544644</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Overview</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Friday 27 January 2023 06:21">Friday 27 January 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
