var documenterSearchIndex = {"docs":
[{"location":"patterns/missing_value_imputation/#Missing-Value-Imputation","page":"Missing Value Imputation","title":"Missing Value Imputation","text":"","category":"section"},{"location":"patterns/iterative_algorithms/#Iterative-Algorithms","page":"Iterative Algorithms","title":"Iterative Algorithms","text":"","category":"section"},{"location":"patterns/survival_analysis/#Survival-Analysis","page":"Survival Analysis","title":"Survival Analysis","text":"","category":"section"},{"location":"optional_data_interface/#data_interface","page":"Optional Data Interface","title":"Optional Data Interface","text":"","category":"section"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"Summary. Implement getobs to articulate how to generate individual observations from data consumed by a LearnAPI algorithm. Implement reformat to provide a higher level interface the means to avoid repeating transformations from user representations of data (such as a dataframe) and algorithm-specific representations (such as a matrix).","category":"page"},{"location":"optional_data_interface/#Resampling","page":"Optional Data Interface","title":"Resampling","text":"","category":"section"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"To aid in programmatic resampling, such as cross-validation, it is helpful if each machine learning algorithm articulates how the data it consumes can be subsampled - that is, how a subset of observations can be extracted from that data. Another advantage of doing so is to mitigate some of the ambiguities around structuring observations within the container: Are the observations in a matrix the rows or the columns?","category":"page"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"In LearnAPI, an implementation can articulate a subsampling method by implementing LearnAPI.getobs(algorithm, func, I, data...) for each function func consuming data, such as fit and predict. Examples are given below.","category":"page"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"LearnAPI.getobs","category":"page"},{"location":"optional_data_interface/#LearnAPI.getobs","page":"Optional Data Interface","title":"LearnAPI.getobs","text":"LearnAPI.getobs(algorithm, LearnAPI.fit, I, data...)\n\nReturn a subsample of data consisting of all observations with indices in I. Here data is data of the form expected in a call like LearnAPI.fit(algorithm, verbosity, data...; metadata...).\n\nAlways returns a tuple of the same length as data.\n\nLearnAPI.getobs(algorithm, operation, I, data...)\n\nReturn a subsample of data consisting of all observations with indices in I. Here data is data of the form expected in a call of the specified operation, e.g., in a call like LearnAPI.predict(algorithm, data...), if operation = LearnAPI.predict. Possible values for operation are: LearnAPI.predict, LearnAPI.transform, LearnAPI.inverse_transform.\n\nAlways returns a tuple of the same length as data.\n\nNew implementations\n\nImplementation is optional. If implemented, then ordinarily implemented for each signature of fit and operation implemented for algorithm.\n\nIf implemented, you must include :reformat in the tuple returned by the LearnAPI.functions trait. \n\nThe subsample returned must be acceptable in place of data in calls of the function named in the second argument.\n\nSample implementation\n\nSuppose that MyClassifier is an algorithm type for simple supervised classification, with LearnAPI.fit(algorithm::MyClassifier, verbosity, A, y) and predict(algorithm::MyClassifier, fitted_params, A) implemented assuming the target y is an ordinary abstract vector and the features A is an abstract matrix with columns as observations. Then the following is a valid implementation of getobs:\n\nLearnAPI.getobs(::MyClassifier, ::typeof(LearnAPI.fit), I, A, y) =\n    (view(A, :, I), view(y, I))\nLearnAPI.getobs(::MyClassifier, ::typeof(LearnAPI.predict), I, A) = (view(A, :, I),)\n\n\n\n\n\n","category":"function"},{"location":"optional_data_interface/#Preprocessing","page":"Optional Data Interface","title":"Preprocessing","text":"","category":"section"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"So that a higher level interface can avoid unnecessarily repeating calls to convert user-supplied data (e.g., a dataframe) into some performant, algorithm-specific representation, an algorithm can move such data conversions out of fit, predict, etc., and into an implementation of LearnAPI.reformat created for each signature of such methods that are implemented. Examples are given below.","category":"page"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"LearnAPI.reformat","category":"page"},{"location":"optional_data_interface/#LearnAPI.reformat","page":"Optional Data Interface","title":"LearnAPI.reformat","text":"LearnAPI.reformat(algorithm, LearnAPI.fit, user_data...; metadata...)\n\nReturn the algorithm-specific representations (data, metadata) of user-supplied (user_data, user_metadata), for consumption, after splatting, by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!.\n\nLearnAPI.reformat(algorithm, operation, user_data...)\n\nReturn the algorithm-specific representation data of user-supplied user_data, for consumption, after splatting, by the specified operation, dispatched on algorithm. Here operation is one of: LearnAPI.predict, LearnAPI.transform, LearnAPI.inverse_transform.\n\nThe following sample workflow illustrates the use of both versions of reformatabove. The data objects X, y, and Xtest are the user-supplied versions of data.\n\ndata, metadata = LearnAPI.reformat(algorithm, LearnAPI.fit, X, y; class_weights=some_dictionary)\nfitted_params, state, fit_report = LearnAPI.fit(algorithm, 0, data...; metadata...)\n\ntest_data = LearnAPI.reformat(algorithm, LearnAPI.predict, Xtest)\nŷ, predict_report = LearnAPI.predict(algorithm, fitted_params, test_data...)\n\nNew implementations\n\nImplementation of reformat is optional. The fallback simply slurps the supplied data/metadata. You will want to implement for each fit or operation signature implemented for algorithm.\n\nIf overloaded, you must include :reformat in the tuple returned by the LearnAPI.functions trait. \n\nIdeally, any potentially expensive transformation of user-supplied data that is carried out during training only once, at the beginning, should occur in reformat instead of fit/update!/ingest!.\n\nNote that the first form of reformat, for operations, should always return a tuple, because the output is splat in calls to the operation (see the sample workflow above). Similarly, in the return value (data, metadata) for the fit variant, data is always a tuple and metadata always a named tuple (or Base.Pairs object). If there is no metadata, a NamedTuple() can be returned in its place.\n\nExample implementation\n\nSuppose that MyClassifier is an algorithm type for simple supervised classification, with LearnAPI.fit(algorithm::MyClassifier, verbosity, A, y; names=...) and predict(algorithm::MyClassifier, fitted_params, A) implemented assuming that the target y is an ordinary vector, the features A is a matrix with columns as observations, and names are the names of the features. Then, supposing users supply features in tabular form, but target as expected, then we can provide the following implementation of reformat:\n\nusing Tables\nfunction LearnAPI.reformat(::MyClassifier, ::typeof(LearnAPI.fit), X, y)\n    names = Tables.schema(Tables.rows(X)).names\n    return ((Tables.matrix(X)', y), (; names))\nend\nLearnAPI.reformat(::MyClassifier, ::typeof(LearnAPI.predict), X) = (Tables.matrix(X)',)\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#Algorithm-Traits","page":"Algorithm Traits","title":"Algorithm Traits","text":"","category":"section"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"Summary. Traits allow one to promise particular behaviour for an algorithm, such as: This algorithm supports per-observation weights, which must appear as the third argument of fit, or This algorithm's transform method predicts Real vectors.","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"For any (non-trivial) algorithm, LearnAPI.functions(algorithm) must be overloaded to list the LearnAPI methods that have been explicitly implemented/overloaded (algorithm traits excluded). Overloading other traits is optional, except where required by the implementation of some LearnAPI method and explicitly documented in that method's docstring.","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"Traits are often called on instances but are usually defined on algorithm types, as in","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"LearnAPI.is_pure_julia(::Type{<:MyAlgorithmType}) = true","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"which has the shorthand","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"@trait MyAlgorithmType is_pure_julia=true","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"So, for convenience, every trait t is provided the fallback implementation","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"t(algorithm) = t(typeof(algorithm))","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"This means LearnAPI.is_pure_julia(algorithm) = true whenever algorithm isa MyAlgorithmType in the above example.","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"Every trait has a global fallback implementation for ::Type. See the table below.","category":"page"},{"location":"algorithm_traits/#When-traits-depdend-on-more-than-algorithm-type","page":"Algorithm Traits","title":"When traits depdend on more than algorithm type","text":"","category":"section"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"Traits that vary from instance to instance of the same type are disallowed, except in the case of composite algorithms (is_wrapper(algorithm) = true) where this is typically unavoidable. The reason for this is so one can associate, with each non-composite algorithm type, unique trait-based \"algorithm metadata\", for inclusion in searchable algorithm databases. This requirement occasionally requires that an existing algorithm implementation be split into separate LearnAPI implementations (e.g., one for regression and another for classification).","category":"page"},{"location":"algorithm_traits/#Special-two-argument-traits","page":"Algorithm Traits","title":"Special two-argument traits","text":"","category":"section"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"The two-argument version of LearnAPI.predict_output_scitype and LearnAPI.predict_output_scitype are the only overloadable traits with more than one argument. They cannot be declared using the @trait macro.","category":"page"},{"location":"algorithm_traits/#Trait-summary","page":"Algorithm Traits","title":"Trait summary","text":"","category":"section"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"Overloadable traits are available for overloading by any new LearnAPI implementation. Derived traits are not, and should not be called by performance critical code","category":"page"},{"location":"algorithm_traits/#Overloadable-traits","page":"Algorithm Traits","title":"Overloadable traits","text":"","category":"section"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"In the examples column of the table below, Table, Continuous, Sampleable are names owned by the package ScientificTypesBase.jl.","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"trait fallback value return value example\nLearnAPI.functions(algorithm) () implemented LearnAPI functions (traits excluded) (:fit, :predict)\nLearnAPI.preferred_kind_of_proxy(algorithm) LearnAPI.None() an instance tp of KindOfProxy for which an implementation of LearnAPI.predict(algorithm, tp, ...) is guaranteed. LearnAPI.Distribution()\nLearnAPI.position_of_target(algorithm) 0 ¹ the positional index of the target in data in fit(..., data...; metadata) calls 2\nLearnAPI.position_of_weights(algorithm) 0 ¹ the positional index of per-observation weights in data in fit(..., data...; metadata) 3\nLearnAPI.descriptors(algorithm) () lists one or more suggestive algorithm descriptors from LearnAPI.descriptors() (:classifier, :probabilistic)\nLearnAPI.is_pure_julia(algorithm) false is true if implementation is 100% Julia code true\nLearnAPI.pkg_name(algorithm) \"unknown\" name of package providing core code (may be different from package providing LearnAPI.jl implementation) \"DecisionTree\"\nLearnAPI.pkg_license(algorithm) \"unknown\" name of license of package providing core code \"MIT\"\nLearnAPI.doc_url(algorithm) \"unknown\" url providing documentation of the core code \"https://en.wikipedia.org/wiki/Decision_tree_learning\"\nLearnAPI.load_path(algorithm) \"unknown\" a string indicating where the struct for typeof(algorithm) is defined, beginning with name of package providing implementation FastTrees.LearnAPI.DecisionTreeClassifier\nLearnAPI.is_wrapper(algorithm) false is true if one or more properties (fields) of algorithm may be an algorithm true\nLearnAPI.human_name(algorithm) type name with spaces human name for the algorithm; should be a noun \"elastic net regressor\"\nLearnAPI.iteration_parameter(algorithm) nothing symbolic name of an iteration parameter :epochs\nLearnAPI.fit_keywords(algorithm) () tuple of symbols for keyword arguments accepted by fit (corresponding  to metadata) (:class_weights,)\nLearnAPI.fit_scitype(algorithm) Union{} upper bound on scitype(data) in fit(algorithm, verbosity, data...)² Tuple{Table(Continuous), AbstractVector{Continuous}}\nLearnAPI.fit_observation_scitype(algorithm) Union{} upper bound on scitype(observation) for observation in data and data in fit(algorithm, verbosity, data...)² Tuple{AbstractVector{Continuous}, Continuous}\nLearnAPI.fit_type(algorithm) Union{} upper bound on type(data) in fit(algorithm, verbosity, data...)² Tuple{AbstractMatrix{<:Real}, AbstractVector{<:Real}}\nLearnAPI.fit_observation_type(algorithm) Union{} upper bound on type(observation) for observation in data and data in fit(algorithm, verbosity, data...)* Tuple{AbstractVector{<:Real}, Real}\nLearnAPI.predict_input_scitype(algorithm) Union{} upper bound on scitype(data) in predict(algorithm, fitted_params, data...)² Table(Continuous)\nLearnAPI.predict_output_scitype(algorithm, kind_of_proxy) Any upper bound on scitype(first(predict(algorithm, kind_of_proxy, ...))) AbstractVector{Continuous}\nLearnAPI.predict_input_type(algorithm) Union{} upper bound on typeof(data) in predict(algorithm, fitted_params, data...)² AbstractMatrix{<:Real}\nLearnAPI.predict_output_type(algorithm, kind_of_proxy) Any upper bound on typeof(first(predict(algorithm, kind_of_proxy, ...))) AbstractVector{<:Real}\nLearnAPI.transform_input_scitype(algorithm) Union{} upper bound on scitype(data) in transform(algorithm, fitted_params, data...)² Table(Continuous)\nLearnAPI.transform_output_scitype(algorithm) Any upper bound on scitype(first(transform(algorithm, ...))) Table(Continuous)\nLearnAPI.transform_input_type(algorithm) Union{} upper bound on typeof(data) in transform(algorithm, fitted_params, data...)² AbstractMatrix{<:Real}}\nLearnAPI.transform_output_type(algorithm) Any upper bound on typeof(first(transform(algorithm, ...))) AbstractMatrix{<:Real}","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"¹ If the value is 0, then the variable in boldface type is not supported and not expected to appear in data. If length(data) is less than the trait value, then data is understood to exclude the variable, but note that fit can have multiple signatures of varying lengths, as in fit(algorithm, verbosity, X, y) and fit(algorithm, verbosity, X, y, w). A non-zero value is a promise that fit includes a signature of sufficient length to include the variable.","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"² Assuming no optional data interface is implemented. See docstring for the general case.","category":"page"},{"location":"algorithm_traits/#Derived-Traits","page":"Algorithm Traits","title":"Derived Traits","text":"","category":"section"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"The following convenience methods are provided but intended for overloading:","category":"page"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"trait return value example\nLearnAPI.name(algorithm) algorithm type name as string \"PCA\"\nLearnAPI.is_algorithm(algorithm) true if functions(algorithm) is not empty true\nLearnAPI.predict_output_scitype(algorithm) dictionary of upper bounds on the scitype of predictions, keyed on subtypes of LearnAPI.KindOfProxy \nLearnAPI.predict_output_type(algorithm) dictionary of upper bounds on the type of predictions, keyed on subtypes of LearnAPI.KindOfProxy ","category":"page"},{"location":"algorithm_traits/#Reference","page":"Algorithm Traits","title":"Reference","text":"","category":"section"},{"location":"algorithm_traits/","page":"Algorithm Traits","title":"Algorithm Traits","text":"LearnAPI.functions\nLearnAPI.preferred_kind_of_proxy\nLearnAPI.position_of_target\nLearnAPI.position_of_weights\nLearnAPI.descriptors\nLearnAPI.is_pure_julia\nLearnAPI.pkg_name\nLearnAPI.pkg_license\nLearnAPI.doc_url\nLearnAPI.load_path\nLearnAPI.is_wrapper\nLearnAPI.fit_keywords\nLearnAPI.human_name\nLearnAPI.iteration_parameter\nLearnAPI.fit_scitype\nLearnAPI.fit_type\nLearnAPI.fit_observation_scitype\nLearnAPI.fit_observation_type\nLearnAPI.predict_input_scitype\nLearnAPI.predict_output_scitype\nLearnAPI.predict_input_type\nLearnAPI.predict_output_type\nLearnAPI.transform_input_scitype\nLearnAPI.transform_output_scitype\nLearnAPI.transform_input_type\nLearnAPI.transform_output_type","category":"page"},{"location":"algorithm_traits/#LearnAPI.functions","page":"Algorithm Traits","title":"LearnAPI.functions","text":"LearnAPI.functions(algorithm)\n\nReturn a tuple of symbols, such as (:fit, :predict), corresponding to LearnAPI methods specifically implemented for objects having the same type as algorithm.  If non-empty, this also guarantees algorithm is an algorithm, in the LearnAPI sense. See the Reference section of the manual for details.\n\nNew implementations\n\nEvery LearnAPI method that is not a trait and which is specifically implemented for typeof(algorithm) must be included in the return value of this trait. Specifically, the return value is a tuple of symbols from this list: :fit, :update!, :ingest!, :predict, :transform, :inverse_transform, :features_importances, :training_labels, :training_losses, :training_scores. To regenerate this list, do LearnAPI.functions().\n\nSee also LearnAPI.Algorithm.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.preferred_kind_of_proxy","page":"Algorithm Traits","title":"LearnAPI.preferred_kind_of_proxy","text":"LearnAPI.preferred_kind_of_proxy(algorithm)\n\nReturns an instance of LearnAPI.KindOfProxy, unless LearnAPI.predict is not implemented for objects of type typeof(algorithm), in which case it returns nothing.\n\nThe returned target proxy is generally the one with the smallest computational cost, if more than one type is supported.\n\nSee also LearnAPI.predict, LearnAPI.KindOfProxy.\n\nNew implementations\n\nAny algorithm implementing LearnAPI.predict must overload this trait.\n\nThe trait must return a lone instance T() for some concrete subtype T <: LearnAPI.KindOfProxy. List these with subtypes(LearnAPI.KindOfProxy) and subtypes(LearnAPI.IID).\n\nSuppose, for example, we have the following implementation of a supervised learner returning only probablistic predictions:\n\nLearnAPI.predict(algorithm::MyNewAlgorithmType, LearnAPI.Distribution(), Xnew) = ...\n\nThen we can declare\n\n@trait MyNewAlgorithmType  preferred_kind_of_proxy = LearnAPI.LiteralTarget()\n\nwhich is shorthand for\n\nLearnAPI.preferred_kind_of_proxy(::Type{<:MyNewAlgorithmType}) = LearnAPI.Distribution()\n\nFor more on target variables and target proxies, refer to the LearnAPI documentation.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.position_of_target","page":"Algorithm Traits","title":"LearnAPI.position_of_target","text":"LearnAPI.position_of_target(algorithm)\n\nReturn the expected position of the target variable within data in calls of the form LearnAPI.fit(algorithm, verbosity, data...).\n\nIf this number is 0, then no target is expected. If this number exceeds length(data), then data is understood to exclude the target variable.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.position_of_weights","page":"Algorithm Traits","title":"LearnAPI.position_of_weights","text":"LearnAPI.position_of_weights(algorithm)\n\nReturn the expected position of per-observation weights within data in calls of the form LearnAPI.fit(algorithm, verbosity, data...).\n\nIf this number is 0, then no weights are expected. If this number exceeds length(data), then data is understood to exclude weights, which are assumed to be uniform.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.descriptors","page":"Algorithm Traits","title":"LearnAPI.descriptors","text":"LearnAPI.descriptors(algorithm)\n\nLists one or more suggestive algorithm descriptors from this list: :regression, :classification, :clustering, :gradient_descent, :iterative_algorithms, :incremental_algorithms, :dimension_reduction, :encoders, :static_algorithms, :missing_value_imputation, :ensemble_algorithms, :wrappers, :time_series_forecasting, :time_series_classification, :survival_analysis, :distribution_fitters, :Bayesian_algorithms, :outlier_detection, :collaborative_filtering, :text_analysis, :audio_analysis, :natural_language_processing, :image_processing (do LearnAPI.descriptors() to reproduce).\n\nwarning: Warning\nThe value of this trait guarantees no particular behavior. The trait is intended for informal classification purposes only.\n\nNew implementations\n\nThis trait should return a tuple of symbols, as in (:classifier, :probabilistic).\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.is_pure_julia","page":"Algorithm Traits","title":"LearnAPI.is_pure_julia","text":"LearnAPI.is_pure_julia(algorithm)\n\nReturns true if training algorithm requires evaluation of pure Julia code only.\n\nNew implementations\n\nThe fallback is false.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.pkg_name","page":"Algorithm Traits","title":"LearnAPI.pkg_name","text":"LearnAPI.pkg_name(algorithm)\n\nReturn the name of the package module which supplies the core training algorithm for algorithm.  This is not necessarily the package providing the LearnAPI interface.\n\nReturns \"unknown\" if the algorithm implementation has failed to overload the trait. \n\nNew implementations\n\nMust return a string, as in \"DecisionTree\".\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.pkg_license","page":"Algorithm Traits","title":"LearnAPI.pkg_license","text":"LearnAPI.pkg_license(algorithm)\n\nReturn the name of the software license, such as \"MIT\", applying to the package where the core algorithm for algorithm is implemented.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.doc_url","page":"Algorithm Traits","title":"LearnAPI.doc_url","text":"LearnAPI.doc_url(algorithm)\n\nReturn a url where the core algorithm for algorithm is documented.\n\nReturns \"unknown\" if the algorithm implementation has failed to overload the trait. \n\nNew implementations\n\nMust return a string, such as \"https://en.wikipedia.org/wiki/Decision_tree_learning\".\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.load_path","page":"Algorithm Traits","title":"LearnAPI.load_path","text":"LearnAPI.load_path(algorithm)\n\nReturn a string indicating where the struct for typeof(algorithm) can be found, beginning with the name of the package module defining it. For example, a return value of \"FastTrees.LearnAPI.DecisionTreeClassifier\" means the following julia code will return the algorithm type:\n\nimport FastTrees\nFastTrees.LearnAPI.DecisionTreeClassifier\n\nReturns \"unknown\" if the algorithm implementation has failed to overload the trait. \n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.is_wrapper","page":"Algorithm Traits","title":"LearnAPI.is_wrapper","text":"LearnAPI.is_wrapper(algorithm)\n\nReturns true if one or more properties (fields) of algorithm may themselves be algorithms, and false otherwise.\n\nNew implementations\n\nThis trait must be overloaded if one or more properties (fields) of algorithm may take algorithm values. Fallback return value is false.\n\nThe value of the trait must depend only on the type of algorithm. \n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.fit_keywords","page":"Algorithm Traits","title":"LearnAPI.fit_keywords","text":"LearnAPI.fit_keywords(algorithm)\n\nReturn a list of keywords that can be provided to fit that correspond to metadata; metadata is for extra information pertaining to the data that is never iterated or subsampled. Examples, include target class weights and group lasso feature groupings. Further examples include feature names, and the pool of target classes, when these are not embedded in the data representation. \n\nNew implementations\n\nIf LearnAPI.fit(algorithm, ...) supports keyword arguments, then this trait must be overloaded, and otherwise not. Fallback returns ().\n\nHere's a sample implementation for a classifier that implements a LearnAPI.fit method with signature fit(algorithm::MyClassifier, verbosity, X, y; class_weights=nothing):\n\nLearnAPI.fit_keywords(::Type{<:MyClassifier}) = (:class_weights,)\n\nor the shorthand\n\n@trait MyClassifier fit_keywords=(:class_weights,)\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.human_name","page":"Algorithm Traits","title":"LearnAPI.human_name","text":"LearnAPI.human_name(algorithm)\n\nA human-readable string representation of typeof(algorithm). Primarily intended for auto-generation of documentation.\n\nNew implementations\n\nOptional. A fallback takes the type name, inserts spaces and removes capitalization. For example, KNNRegressor becomes \"knn regressor\". Better would be to overload the trait to return \"K-nearest neighbors regressor\". Ideally, this is a \"concrete\" noun like \"ridge regressor\" rather than an \"abstract\" noun like \"ridge regression\".\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.iteration_parameter","page":"Algorithm Traits","title":"LearnAPI.iteration_parameter","text":"LearnAPI.iteration_parameter(algorithm)\n\nThe name of the iteration parameter of algorithm, or nothing if the algorithm is not iterative.\n\nNew implementations\n\nImplement if algorithm is iterative. Returns a symbol or nothing.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.fit_scitype","page":"Algorithm Traits","title":"LearnAPI.fit_scitype","text":"LearnAPI.fit_scitype(algorithm)\n\nReturn an upper bound on the scitype of data guaranteeing it to work when training algorithm.\n\nSpecifically, if the return value is S and ScientificTypes.scitype(data) <: S, then the following low-level calls are allowed (assuming metadata is also valid and verbosity is an integer):\n\n# apply data front-end:\ndata2, metadata2 = LearnAPI.reformat(algorithm, LearnAPI.fit, data...; metadata...)\n\n# train:\nLearnAPI.fit(algorithm, verbosity, data2...; metadata2...)\n\nSee also LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\nNew implementations\n\nOptional. The fallback return value is Union{}.  No more than one of the following should be overloaded for an algorithm type: LearnAPI.fit_scitype, LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.fit_type","page":"Algorithm Traits","title":"LearnAPI.fit_type","text":"LearnAPI.fit_type(algorithm)\n\nReturn an upper bound on the type of data guaranteeing it to work when training algorithm.\n\nSpecifically, if the return value is T and typeof(data) <: T, then the following low-level calls are allowed (assuming metadata is also valid and verbosity is an integer):\n\n# apply data front-end:\ndata2, metadata2 = LearnAPI.reformat(algorithm, LearnAPI.fit, data...; metadata...)\n\n# train:\nLearnAPI.fit(algorithm, verbosity, data2...; metadata2...)\n\nSee also LearnAPI.fit_scitype, LearnAPI.fit_observation_type. LearnAPI.fit_observation_scitype\n\nNew implementations\n\nOptional. The fallback return value is Union{}. No more than one of the following should be overloaded for an algorithm type: LearnAPI.fit_scitype, LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.fit_observation_scitype","page":"Algorithm Traits","title":"LearnAPI.fit_observation_scitype","text":"LearnAPI.fit_observation_scitype(algorithm)\n\nReturn an upper bound on the scitype of observations guaranteed to work when training algorithm (independent of the type/scitype of the data container itself).\n\nSpecifically, denoting the type returned above by S, suppose a user supplies training data, data - typically a tuple, such as (X, y) - and valid metadata, metadata, and one computes\n\ndata2, metadata2 = LearnAPI.reformat(algorithm, LearnAPI.fit, data...; metadata...)\n\nThen, assuming\n\nScientificTypes.scitype(LearnAPI.getobs(algorithm, LearnAPI.fit, data2, i)) <: S\n\nfor any valid index i, the following is guaranteed to work:\n\nLearnAPI.fit(algorithm, verbosity, data2...; metadata2...)\n\nSee also See also LearnAPI.fit_type, LearnAPI.fit_scitype, LearnAPI.fit_observation_type.\n\nNew implementations\n\nOptional. The fallback return value is Union{}. No more than one of the following should be overloaded for an algorithm type: LearnAPI.fit_scitype, LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.fit_observation_type","page":"Algorithm Traits","title":"LearnAPI.fit_observation_type","text":"LearnAPI.fit_observation_type(algorithm)\n\nReturn an upper bound on the type of observations guaranteed to work when training algorithm (independent of the type/scitype of the data container itself).\n\nSpecifically, denoting the type returned above by T, suppose a user supplies training data, data - typically a tuple, such as (X, y) - and valid metadata, metadata, and one computes\n\ndata2, metadata2 = LearnAPI.reformat(algorithm, LearnAPI.fit, data...; metadata...)\n\nThen, assuming\n\ntypeof(LearnAPI.getobs(algorithm, LearnAPI.fit, data2, i)) <: T\n\nfor any valid index i, the following is guaranteed to work:\n\nLearnAPI.fit(algorithm, verbosity, data2...; metadata2...)\n\nSee also See also LearnAPI.fit_type, LearnAPI.fit_scitype, LearnAPI.fit_observation_scitype.\n\nNew implementations\n\nOptional. The fallback return value is Union{}. No more than one of the following should be overloaded for an algorithm type: LearnAPI.fit_scitype, LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.predict_input_scitype","page":"Algorithm Traits","title":"LearnAPI.predict_input_scitype","text":" LearnAPI.predict_input_scitype(algorithm)\n\nReturn an upper bound on the scitype of input data guaranteed to work with the predict  operation.\n\nSpecifically, if S is the value returned and ScientificTypes.scitype(data) <: S,  then the following low-level calls are allowed\n\n data2 = LearnAPI.reformat(algorithm, LearnAPI.predict, data...)\n LearnAPI.predict(algorithm, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to  LearnAPI.fit.\n\nSee also LearnAPI.predict_input_type.\n\nNew implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be  overloaded if LearnAPI.predict_input_type is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.predict_output_scitype","page":"Algorithm Traits","title":"LearnAPI.predict_output_scitype","text":"LearnAPI.predict_output_scitype(algorithm, kind_of_proxy::KindOfProxy)\n\nReturn an upper bound for the scitypes of predictions of the specified form where supported, and otherwise return Any. For example, if\n\nŷ, report = LearnAPI.predict(algorithm, LearnAPI.Distribution(), data...)\n\nsuccessfully returns (i.e., algorithm supports predictions of target probability distributions) then the following is guaranteed to hold:\n\nscitype(ŷ) <: LearnAPI.predict_output_scitype(algorithm, LearnAPI.Distribution())\n\nNote. This trait has a single-argument \"convenience\" version LearnAPI.predict_output_scitype(algorithm) derived from this one, which returns a dictionary keyed on target proxy types.\n\nSee also LearnAPI.KindOfProxy, LearnAPI.predict, LearnAPI.predict_input_scitype.\n\nNew implementations\n\nOverloading the trait is optional. Here's a sample implementation for a supervised regressor type MyRgs that only predicts actual values of the target:\n\nLearnAPI.predict(alogrithm::MyRgs, ::LearnAPI.LiteralTarget, data...) = ...\nLearnAPI.predict_output_scitype(::Type{<:MyRgs}, ::LearnAPI.LiteralTarget) =\n    AbstractVector{ScientificTypesBase.Continuous}\n\nThe fallback method returns Any.\n\n\n\n\n\nLearnAPI.predict_output_scitype(algorithm)\n\nReturn a dictionary of upper bounds on the scitype of predictions, keyed on concrete subtypes of LearnAPI.KindOfProxy. Each of these subtypes respresents a different form of target prediction (LiteralTarget, Distribution, SurvivalFunction, etc) possibly supported by algorithm, but the existence of a key does not guarantee that form is supported.\n\nAs an example, if\n\nŷ, report = LearnAPI.predict(algorithm, LearnAPI.Distribution(), data...)\n\nsuccessfully returns (i.e., algorithm supports predictions of target probability distributions) then the following is guaranteed to hold:\n\nscitype(ŷ) <: LearnAPI.predict_output_scitype(algorithm)[LearnAPI.Distribution]\n\nSee also LearnAPI.KindOfProxy, LearnAPI.predict, LearnAPI.predict_input_scitype.\n\nNew implementations\n\nThis single argument trait should not be overloaded. Instead, overload LearnAPI.predict_output_scitype(algorithm, kindofproxy). See above.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.predict_input_type","page":"Algorithm Traits","title":"LearnAPI.predict_input_type","text":"LearnAPI.predict_input_type(algorithm)\n\nReturn an upper bound on the type of input data guaranteed to work with the predict operation.\n\nSpecifically, if T is the value returned and typeof(data) <: S, then the following low-level calls are allowed\n\ndata2 = LearnAPI.reformat(algorithm, LearnAPI.predict, data...)\nLearnAPI.predict(algorithm, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to LearnAPI.fit.\n\nSee also LearnAPI.predict_input_scitype.\n\nNew implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be overloaded if LearnAPI.predict_input_scitype is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.predict_output_type","page":"Algorithm Traits","title":"LearnAPI.predict_output_type","text":"LearnAPI.predict_output_type(algorithm, kind_of_proxy::KindOfProxy)\n\nReturn an upper bound for the types of predictions of the specified form where supported, and otherwise return Any. For example, if\n\nŷ, report = LearnAPI.predict(algorithm, LearnAPI.Distribution(), data...)\n\nsuccessfully returns (i.e., algorithm supports predictions of target probability distributions) then the following is guaranteed to hold:\n\ntype(ŷ) <: LearnAPI.predict_output_type(algorithm, LearnAPI.Distribution())\n\nNote. This trait has a single-argument \"convenience\" version LearnAPI.predict_output_type(algorithm) derived from this one, which returns a dictionary keyed on target proxy types.\n\nSee also LearnAPI.KindOfProxy, LearnAPI.predict, LearnAPI.predict_input_type.\n\nNew implementations\n\nOverloading the trait is optional. Here's a sample implementation for a supervised regressor type MyRgs that only predicts actual values of the target:\n\nLearnAPI.predict(alogrithm::MyRgs, ::LearnAPI.LiteralTarget, data...) = ...\nLearnAPI.predict_output_type(::Type{<:MyRgs}, ::LearnAPI.LiteralTarget) =\n    AbstractVector{ScientificTypesBase.Continuous}\n\nThe fallback method returns Any.\n\n\n\n\n\nLearnAPI.predict_output_type(algorithm)\n\nReturn a dictionary of upper bounds on the type of predictions, keyed on concrete subtypes of LearnAPI.KindOfProxy. Each of these subtypes respresents a different form of target prediction (LiteralTarget, Distribution, SurvivalFunction, etc) possibly supported by algorithm, but the existence of a key does not guarantee that form is supported.\n\nAs an example, if\n\nŷ, report = LearnAPI.predict(algorithm, LearnAPI.Distribution(), data...)\n\nsuccessfully returns (i.e., algorithm supports predictions of target probability distributions) then the following is guaranteed to hold:\n\ntype(ŷ) <: LearnAPI.predict_output_type(algorithm)[LearnAPI.Distribution]\n\nSee also LearnAPI.KindOfProxy, LearnAPI.predict, LearnAPI.predict_input_type.\n\nNew implementations\n\nThis single argument trait should not be overloaded. Instead, overload LearnAPI.predict_output_type(algorithm, kindofproxy). See above.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.transform_input_scitype","page":"Algorithm Traits","title":"LearnAPI.transform_input_scitype","text":" LearnAPI.transform_input_scitype(algorithm)\n\nReturn an upper bound on the scitype of input data guaranteed to work with the transform  operation.\n\nSpecifically, if S is the value returned and ScientificTypes.scitype(data) <: S,  then the following low-level calls are allowed\n\n data2 = LearnAPI.reformat(algorithm, LearnAPI.transform, data...)\n LearnAPI.transform(algorithm, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to  LearnAPI.fit.\n\nSee also LearnAPI.transform_input_type.\n\nNew implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be  overloaded if LearnAPI.transform_input_type is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.transform_output_scitype","page":"Algorithm Traits","title":"LearnAPI.transform_output_scitype","text":"LearnAPI.transform_output_scitype(algorithm)\n\nReturn an upper bound on the scitype of the output of the transform operation.\n\nSpecifically, if S is the value returned, and if\n\noutput, report = LearnAPI.transform(algorithm, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\nScientificTypes.scitype(output) <: S\n\nSee also LearnAPI.transform_input_scitype.\n\nNew implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.transform_input_type","page":"Algorithm Traits","title":"LearnAPI.transform_input_type","text":"LearnAPI.transform_input_type(algorithm)\n\nReturn an upper bound on the type of input data guaranteed to work with the transform operation.\n\nSpecifically, if T is the value returned and typeof(data) <: S, then the following low-level calls are allowed\n\ndata2 = LearnAPI.reformat(algorithm, LearnAPI.transform, data...)\nLearnAPI.transform(algorithm, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to LearnAPI.fit.\n\nSee also LearnAPI.transform_input_scitype.\n\nNew implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be overloaded if LearnAPI.transform_input_scitype is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_traits/#LearnAPI.transform_output_type","page":"Algorithm Traits","title":"LearnAPI.transform_output_type","text":"LearnAPI.transform_output_type(algorithm)\n\nReturn an upper bound on the type of the output of the transform operation.\n\nSpecifically, if T is the value returned, and if\n\noutput, report = LearnAPI.transform(algorithm, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\ntypeof(output) <: T\n\nSee also LearnAPI.transform_input_type.\n\nNew implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"patterns/supervised_bayesian_algorithms/#Supervised-Bayesian-Models","page":"Supervised Bayesian Models","title":"Supervised Bayesian Models","text":"","category":"section"},{"location":"patterns/classifiers/#Classifiers","page":"Classifiers","title":"Classifiers","text":"","category":"section"},{"location":"common_implementation_patterns/#Common-Implementation-Patterns","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"","category":"section"},{"location":"common_implementation_patterns/","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"warning: Warning\nThis section is only an implementation guide. The definitive specification of the Learn API is given in Reference.","category":"page"},{"location":"common_implementation_patterns/","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"This guide is intended to be consulted after reading Anatomy of an Implementation, which introduces the main interface objects and terminology.","category":"page"},{"location":"common_implementation_patterns/","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"Although an implementation is defined purely by the methods and traits it implements, most implementations fall into one (or more) of the following informally understood patterns or \"tasks\":","category":"page"},{"location":"common_implementation_patterns/","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"Classifiers: Supervised learners for categorical targets\nRegressors: Supervised learners for continuous targets\nIterative Algorithms\nIncremental Algorithms\nStatic Transformers: Transformations that do not learn but which have hyperparameters and/or deliver ancillary information about the transformation\nDimension Reduction: Transformers that learn to reduce feature space dimension\nMissing Value Imputation: Transformers that replace missing values.\nClusterering: Algorithms that group data into clusters for classification and possibly dimension reduction. May be true learners (generalize to new data) or static.\nOutlier Detection: Supervised, unsupervised, or semi-supervised learners for anomaly detection.\nLearning a Probability Distribution: Algorithms that fit a distribution or distribution-like object to data\nTime Series Forecasting\nTime Series Classification\nSupervised Bayesian Algorithms\nSurvival Analysis","category":"page"},{"location":"patterns/static_transformers/#Static-Transformers","page":"Static Transformers","title":"Static Transformers","text":"","category":"section"},{"location":"patterns/supervised_bayesian_models/#Supervised-Bayesian-Algorithms","page":"Supervised Bayesian Algorithms","title":"Supervised Bayesian Algorithms","text":"","category":"section"},{"location":"patterns/regressors/#Regressors","page":"Regressors","title":"Regressors","text":"","category":"section"},{"location":"testing_an_implementation/#Testing-an-Implementation","page":"Testing an Implementation","title":"Testing an Implementation","text":"","category":"section"},{"location":"patterns/time_series_classification/#Time-Series-Classification","page":"Time Series Classification","title":"Time Series Classification","text":"","category":"section"},{"location":"anatomy_of_an_implementation/#Anatomy-of-an-Implementation","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Summary. Formally, an algorithm is a container for the hyperparameters of some ML/statistics algorithm.  A basic implementation of the ridge regressor requires implementing fit and predict methods dispatched on the algorithm type; predict is an example of an operation, the others are transform and inverse_transform. In this example we also implement an accessor function, called feature_importance, returning the absolute values of the linear coefficients. The ridge regressor has a target variable and outputs literal predictions of the target (rather than, say, probabilistic predictions); accordingly the overloaded predict method is dispatched on the LiteralTarget subtype of KindOfProxy. An algorithm trait declares this type as the preferred kind of target proxy. Other traits articulate the algorithm's training data type requirements and the input/output type of predict.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"We begin by describing an implementation of LearnAPI.jl for basic ridge regression (without intercept) to introduce the main actors in any implementation.","category":"page"},{"location":"anatomy_of_an_implementation/#Defining-an-algorithm-type","page":"Anatomy of an Implementation","title":"Defining an algorithm type","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The first line below imports the lightweight package LearnAPI.jl whose methods we will be extending, the second, libraries needed for the core algorithm.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"using LearnAPI\nusing LinearAlgebra, Tables\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Next, we define a struct to store the single hyperparameter lambda of this algorithm:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"struct MyRidge <: LearnAPI.Algorithm\n        lambda::Float64\nend\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The subtyping MyRidge <: LearnAPI.Algorithm is optional but recommended where it is not otherwise disruptive.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Instances of MyRidge are called algorithms and MyRidge is an algorithm type.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"A keyword argument constructor providing defaults for all hyperparameters should be provided:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"nothing # hide\nMyRidge(; lambda=0.1) = MyRidge(lambda)\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/#Implementing-training-(fit)","page":"Anatomy of an Implementation","title":"Implementing training (fit)","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"A ridge regressor requires two types of data for training: input features X and a target y. Training is implemented by overloading fit. Here verbosity is an integer (0 should train silently, unless warnings are needed):","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"function LearnAPI.fit(algorithm::MyRidge, verbosity, X, y)\n\n        # process input:\n        x = Tables.matrix(X)  # convert table to matrix\n        s = Tables.schema(X)\n        features = s.names\n\n        # core solver:\n        coefficients = (x'x + algorithm.lambda*I)\\(x'y)\n\n        # prepare output - learned parameters:\n        fitted_params = (; coefficients)\n\n        # prepare output - algorithm state:\n        state = nothing  # not relevant here\n\n        # prepare output - byproducts of training:\n        feature_importances =\n                [features[j] => abs(coefficients[j]) for j in eachindex(features)]\n        sort!(feature_importances, by=last) |> reverse!\n        verbosity > 0 && @info \"Features in order of importance: $(first.(feature_importances))\"\n        report = (; feature_importances)\n\n        return fitted_params, state, report\nend\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Regarding the return value of fit:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The fitted_params variable is for the algorithm's learned parameters, for passing to predict (see below).\nThe state variable is only relevant when additionally implementing a LearnAPI.update! or LearnAPI.ingest! method (see Fit, update! and ingest!).\nThe report is for other byproducts of training, apart from the learned parameters (the ones we'll need to provide predict below).","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Our fit method assumes that X is a table (satisfies the Tables.jl spec) whose rows are the observations; and it will need need y to be an AbstractFloat vector. An algorithm implementation is free to dictate the representation of data that fit accepts but articulates its requirements using appropriate traits; see Training data types below. We recommend against data type checks internal to fit; this would ordinarily be the responsibility of a higher level API, using those traits. ","category":"page"},{"location":"anatomy_of_an_implementation/#Operations","page":"Anatomy of an Implementation","title":"Operations","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Now we need a method for predicting the target on new input features:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"function LearnAPI.predict(::MyRidge, ::LearnAPI.LiteralTarget, fitted_params, Xnew)\n    Xmatrix = Tables.matrix(Xnew)\n    report = nothing\n    return Xmatrix*fitted_params.coefficients, report\nend\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The second argument of predict is always an instance of KindOfProxy, and will always be LiteralTarget() in this case, as only literal values of the target (rather than, say probabilistic predictions) are being supported.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"In some algorithms predict computes something of interest in addition to the target prediction, and this report item is returned as the second component of the return value. When there's nothing to report, we must return nothing, as here.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Our predict method is an example of an operation. Other operations include transform and inverse_transform and an algorithm can implement more than one. For example, a K-means clustering algorithm might implement transform for dimension reduction, and predict to return cluster labels. ","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The predict method is reserved for predictions of a target variable, and only predict has the extra ::KindOfProxy argument.","category":"page"},{"location":"anatomy_of_an_implementation/#Accessor-functions","page":"Anatomy of an Implementation","title":"Accessor functions","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The arguments of an operation are always (algorithm, fitted_params, data...). The interface also provides accessor functions for extracting information, from the fitted_params and/or fit report, that is shared by several algorithm types.  There is one for feature importances that we can implement for MyRidge:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"LearnAPI.feature_importances(::MyRidge, fitted_params, report) =\n    report.feature_importances\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Another example of an accessor function is LearnAPI.training_losses.","category":"page"},{"location":"anatomy_of_an_implementation/#traits","page":"Anatomy of an Implementation","title":"Algorithm traits","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"We have implemented predict, and it is possible to implement predict methods for multiple KindOfProxy types (see See Target proxies for a complete list). Accordingly, we are required to declare a preferred target proxy, which we do using LearnAPI.preferred_kind_of_proxy:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"LearnAPI.preferred_kind_of_proxy(::Type{<:MyRidge}) = LearnAPI.LiteralTarget()\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Or, you can use the shorthand","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge preferred_kind_of_proxy=LearnAPI.LiteralTarget()\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"LearnAPI.preferred_kind_of_proxy is an example of a algorithm trait. A complete list of traits and the contracts they imply is given in Algorithm Traits.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"We also need to indicate that a target variable appears in training (this is a supervised algorithm). We do this by declaring where in the list of training data arguments (in this case (X, y)) the target variable (in this case y) appears:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge position_of_target=2\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"As explained in the introduction, LearnAPI.jl does not attempt to define strict algorithm categories, such as \"regression\" or \"clustering\". However, we can optionally specify suggestive descriptors, as in","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge descriptors=(:regression,)\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"This declaration actually promises nothing, but can help in generating documentation. Do LearnAPI.descriptors() to get a list of available descriptors.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Finally, we are required to declare what methods (excluding traits) we have explicitly overloaded for our type:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge methods=(\n        :fit,\n        :predict,\n        :feature_importances,\n)\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/#Training-data-types","page":"Anatomy of an Implementation","title":"Training data types","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Since LearnAPI.jl is a basement level API, one is discouraged from including explicit type checks in an implementation of fit. Instead one uses traits to make promises about the acceptable type of data consumed by fit. In general, this can be a promise regarding the ordinary type of data or the scientific type of data (but not both). Alternatively, one may only promise a bound on the type/scitype of observations in the data . See Algorithm Traits for further details. In this case we'll be happy to restrict the scitype of the data:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"import ScientificTypesBase: scitype, Table, Continuous\n@trait MyRidge fit_scitype = Tuple{Table(Continuous), AbstractVector{Continuous}}\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"This is a contract that data is acceptable in the call fit(algorithm, verbosity, data...) whenever","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"scitype(data) <: Tuple{Table(Continuous), AbstractVector{Continuous}}","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Or, in other words:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"X in fit(algorithm, verbosity, X, y) is acceptable, provided scitype(X) <: Table(Continuous) - meaning that X Tables.istable(X) == true (see Tables.jl) and each column has some <:AbstractFloat element type.\ny in fit(algorithm, verbosity, X, y) is acceptable if scitype(y) <: AbstractVector{Continuous} - meaning that it is an abstract vector with <:AbstractFloat elements.","category":"page"},{"location":"anatomy_of_an_implementation/#Input-types-for-operations","page":"Anatomy of an Implementation","title":"Input types for operations","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"An optional promise about what data is guaranteed to work in a call like predict(algorithm, fitted_params, data...) is articulated this way:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge predict_input_scitype = Tuple{AbstractVector{<:Continuous}}","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Note that data is always a Tuple, even if it has only one component (the typical case), which explains the Tuple on the right-hand side.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Optionally, we may express our promise using regular types, using the LearnAPI.predict_input_type trait.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"One can optionally make promises about the outut of an operation. See Algorithm Traits for details.","category":"page"},{"location":"anatomy_of_an_implementation/#workflow","page":"Anatomy of an Implementation","title":"Illustrative fit/predict workflow","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"We now illustrate how to interact directly with MyRidge instances using the methods we have implemented:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Here's some toy data for supervised learning:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"using Tables\n\nn = 10          # number of training observations\ntrain = 1:6\ntest = 7:10\n\na, b, c = rand(n), rand(n), rand(n)\nX = (; a, b, c) |> Tables.rowtable\ny = 2a - b + 3c + 0.05*rand(n)\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Instantiate an algorithm with relevant hyperparameters (which is all the object stores):","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"algorithm = MyRidge(lambda=0.5)","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Train the algorithm (the 0 means do so silently):","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"import LearnAPI: fit, predict, feature_importances\n\nfitted_params, state, fit_report = fit(algorithm, 0, X[train], y[train])","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Inspect the learned parameters and report:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@info \"training outcomes\" fitted_params fit_report","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Inspect feature importances:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"feature_importances(algorithm, fitted_params, fit_report)","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Make a prediction using new data:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"yhat, predict_report = predict(algorithm, LearnAPI.LiteralTarget(), fitted_params, X[test])","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Compare predictions with ground truth","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"deviations = yhat - y[test]\nloss = deviations .^2 |> sum\n@info \"Sum of squares loss\" loss","category":"page"},{"location":"patterns/clusterering/#Clusterering","page":"Clusterering","title":"Clusterering","text":"","category":"section"},{"location":"reference/#reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Summary In LearnAPI.jl an algorithm is a container for hyperparameters of some ML/Statistics algorithm (which may or may not \"learn\"). Functionality is created by overloading methods provided by the interface, which are divided into training methods (e.g., fit), operations (e.g.,. predict and transform) and accessor functions (e.g., feature_importances). Promises of particular behavior are articulated by algorithm traits.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Here we give the definitive specification of the interface provided by LearnAPI.jl. For a more informal guide see  Anatomy of an Implementation and Common Implementation Patterns.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"important: Important\nThe reader is assumed to be familiar with the LearnAPI-specific meanings of     the following terms, as outlined in  Scope and undefined notions: data, metadata,  hyperparameter, observation, target, target proxy.","category":"page"},{"location":"reference/#Algorithms","page":"Reference","title":"Algorithms","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"In LearnAPI.jl an algorithm is some julia object alg storing the hyperparameters of some MLJ/statistics algorithm that transforms data in some way. Typically the algorithm \"learns\" from data in a training event, but this is not essential; \"static\" data processing, with parameters, is included.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"The type of alg will have a name reflecting that of the algorithm, such as DecisionTreeRegressor.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Additionally, for alg::Alg to be a LearnAPI algorithm, we require:","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Base.propertynames(alg) returns the hyperparameters of alg.\nIf alg is an algorithm, then so are all instances of the same type.\nIf _alg is another algorithm, then alg == _alg if and only if typeof(alg) == typeof(_alg) and corresponding properties are ==. This includes properties that are random number generators (which should be copied in training to avoid mutation).\nIf an algorithm has other algorithms as hyperparameters, then LearnAPI.is_wrapper(alg) must be true.\nA keyword constructor for Alg exists, providing default values for all non-algorithm hyperparameters.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Whenever any LearnAPI method (excluding traits) is overloaded for some type Alg (e.g., predict, transform, fit) then that is a promise that all instances of Alg are algorithms (and the trait LearnAPI.functions(Alg) will be non-empty).","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"It is supposed that making copies of algorithm objects is a cheap operation. Consequently, learned parameters, such as weights in a neural network (the fitted_params described in Fit, update! and ingest!) should not be stored in the algorithm object. Storing learned parameters in an algorithm is not explicitly ruled out, but doing so might lead to performance issues in packages adopting LearnAPI.jl.","category":"page"},{"location":"reference/#Example","page":"Reference","title":"Example","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Any instance of GradientRidgeRegressor defined below is a valid LearnAPI.jl algorithm:","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"struct GradientRidgeRegressor{T<:Real} <: LearnAPI.Algorithm\n    learning_rate::T\n    epochs::Int\n    l2_regularization::T\nend","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"The same is true if we omit the subtyping <: LearnAPI.Algorithm, but not if we also make this a mutable struct. In that case we will need to overload Base.== for GradientRidgeRegressor.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"LearnAPI.Algorithm","category":"page"},{"location":"reference/#LearnAPI.Algorithm","page":"Reference","title":"LearnAPI.Algorithm","text":"LearnAPI.Algorithm\n\nAn optional abstract type for algorithms implementing LearnAPI.jl.\n\nIf typeof(alg) <: LearnAPI.Algorithm, then alg is guaranteed to be an ML/statistical algorithm in the strict LearnAPI sense.\n\nNew implementations\n\nWhile not a formal requirement, algorithm types implementing the LearnAPI.jl are encouraged to subtype LearnAPI.Algorithm, unless it is disruptive to do so.\n\nSee also LearnAPI.functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Methods","page":"Reference","title":"Methods","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"None of the methods described in the linked sections below are compulsory, but any implemented or overloaded method that is not an algorithm trait must be added to the return value of LearnAPI.functions, as in","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"LearnAPI.functions(::Type{<SomeAlgorithmType}) = (:fit, :update!, :predict)","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"or using the shorthand","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"@trait SomeAlgorithmType functions=(:fit, :update!, :predict)","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Fit, update! and ingest! (training methods): for algorithms that \"learn\" (generalize to new data)\nOperations: predict, transform and their relatives\nAccessor Functions: accessing certain byproducts of training that many algorithms share, such as feature importances and training losses\nOptional Data Interface: getobs and reformat\nAlgorithm Traits: contracts for specific behavior, such as \"The second data argument of fit is a target variable\" or \"I predict probability distributions\"","category":"page"},{"location":"operations/#operations","page":"Predict and other operations","title":"Predict and Other Operations","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Summary An method delivering output for some algorithm which has finished learning, applied to (new) data, is called an operation.  The output depends on the fitted parameters associated with the algorithm, which is nothing for non-generalizing algorithms. Implement the predict operation when the output is predictions of a target variable or, more generally a proxy for the target, such as probability distributions. Otherwise implement transform and, optionally inverse_transform.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"The methods predict, transform and inverse_transform are called operations. They are all dispatched on an algorithm, fitted parameters and data. The predict operation additionally includes a ::ProxyType argument in position two. If LearnAPI.fit is not implemented, then the fitted parameters will always be nothing.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Here's a snippet of code with a LearnAPI.predict call:","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"fitted_params, state, fit_report = LearnAPI.fit(some_algorithm, 1, X, y)\nŷ, predict_report = \n    LearnAPI.predict(some_algorithm, LearnAPI.LiteralTarget(), fitted_params, Xnew)","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"method compulsory? fallback requires\nLearnAPI.predict no none \nLearnAPI.transform no none \nLearnAPI.inverse_transform no none transform","category":"page"},{"location":"operations/#General-requirements","page":"Predict and other operations","title":"General requirements","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Operations always return a tuple (output, report) where output is the usual output (e.g., the target predictions if the operation is predict) and report includes byproducts of the computation, typically nothing unless the algorithm does not generalize to new data (does not implement fit). \nIf implementing a predict method, you must also make a LearnAPI.preferred_kind_of_proxy declaration.\nThe name of each operation explicitly overloaded must be included in the return value of the LearnAPI.functions trait.","category":"page"},{"location":"operations/#Predict-or-transform?","page":"Predict and other operations","title":"Predict or transform?","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"If the algorithm has a notion of target variable, then implement a predict method for each supported kind of target proxy (LiteralTarget(), Distribution(), etc). See Target proxies below.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"If an operation is to have an inverse operation, then it cannot be predict - use transform, and (optionally) inverse_transform, for inversion, broadly understood. See LearnAPI.inverse_transform below.","category":"page"},{"location":"operations/#Target-proxies","page":"Predict and other operations","title":"Target proxies","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"The concept of target proxy is defined under Targets and target proxies. The available kinds of target proxy are classified by subtypes of LearnAPI.KindOfProxy. These types are intended for dispatch only and have no fields.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"LearnAPI.KindOfProxy","category":"page"},{"location":"operations/#LearnAPI.KindOfProxy","page":"Predict and other operations","title":"LearnAPI.KindOfProxy","text":"LearnAPI.KindOfProxy\n\nAbstract type whose concrete subtypes T each represent a different kind of proxy for the target variable, associated with some algorithm. Instances T() are used to request the form of target predictions in LearnAPI.predict calls.\n\nFor example, LearnAPI.Distribution is a concrete subtype of LearnAPI.KindOfProxy and the call LearnAPI.predict(algorithm , LearnAPI.Distribution(), data...) returns a data object whose observations are probability density/mass functions, assuming algorithm supports predictions of that form.\n\nRun subtypes(LearnAPI.KindOfProxy) and subtypes(LearnAPI.IID) to list all concrete subtypes of KindOfProxy.\n\n\n\n\n\n","category":"type"},{"location":"operations/#Predictions-for-i.i.d-models","page":"Predict and other operations","title":"Predictions for i.i.d  models","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"LearnAPI.IID","category":"page"},{"location":"operations/#LearnAPI.IID","page":"Predict and other operations","title":"LearnAPI.IID","text":"LearnAPI.IID <: LearnAPI.KindOfProxy\n\nAbstract subtype of LearnAPI.KindOfProxy appropriate when requesting target predictions for statistical models where input-target pairs (x, y) are generated by an iid process.\n\nMore generally, if kind_of_proxy is an instance of LearnAPI.IID then, given data constisting of n observations, the following must hold:\n\nLearnAPI.predict(algorithm, kind_of_proxy, data...) == (ŷ, report) where ŷ is data also consisting of n observations; and\nThe jth observation of ŷ, for any j, depends only on the jth observation of the provided data (no correlation between observations).\n\nSee also LearnAPI.KindOfProxy.\n\n\n\n\n\n","category":"type"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"type form of an observation\nLearnAPI.None has no declared relationship with a target variable\nLearnAPI.LiteralTarget same as target observations\nLearnAPI.Sampleable object that can be sampled to obtain object of the same form as target observation\nLearnAPI.Distribution explicit probability density/mass function whose sample space is all possible target observations\nLearnAPI.LogDistribution explicit log-probability density/mass function whose sample space is possible target observations\n† LearnAPI.Probability raw numerical probability or probability vector\n† LearnAPI.LogProbability log-probability or log-probability vector\n† LearnAPI.Parametric a list of parameters (e.g., mean and variance) describing some distribution\nLearnAPI.LabelAmbiguous collections of labels (in case of multi-class target) but without a known correspondence to the original target labels (and of possibly different number) as in, e.g., clustering\nLearnAPI.LabelAmbiguousSampleable sampleable version of LabelAmbiguous; see Sampleable above\nLearnAPI.LabelAmbiguousDistribution pdf/pmf version of LabelAmbiguous; see Distribution  above\nLearnAPI.ConfidenceInterval confidence interval (possible requirement:  observation isa Tuple{Real,Real})\nLearnAPI.Set finite but possibly varying number of target observations\nLearnAPI.ProbabilisticSet as for Set but labeled with probabilities (not necessarily summing to one)\nLearnAPI.SurvivalFunction survival function (possible requirement: observation is single-argument function mapping Real to Real)\nLearnAPI.SurvivalDistribution probability distribution for survival time\nLearnAPI.OutlierScore numerical score reflecting degree of outlierness (not necessarily normalized)\nLearnAPI.Continuous real-valued approximation/interpolation of a discrete-valued target, such as a count (e.g., number of phone calls)","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"† Provided for completeness but discouraged to avoid ambiguities in representation.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Table of concrete subtypes of LearnAPI.IID <: LearnAPI.KindOfProxy.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"In the following table of subtypes T <: LearnAPI.KindOfProxy not falling under the IID umbrella, the first return value of predict(algorithm, ::T, fitted_params, data...) is not divided into individual observations, but represents a single probability distribution for the sample space Y^n, where Y is the space the target variable takes its values, and n is the number of observations in data.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"type T form of output of predict(algorithm, ::T, fitted_params, data...)\nLearnAPI.JointSampleable object that can be sampled to obtain a vector whose elements have the form of target observations; the vector length matches the number of observations in data.\nLearnAPI.JointDistribution explicit probability density/mass function whose sample space is vectors of target observations;  the vector length matches the number of observations in data\nLearnAPI.JointLogDistribution explicit log-probability density/mass function whose sample space is vectors of target observations;  the vector length matches the number of observations in data","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Table of LearnAPI.KindOfProxy subtypes not subtyping LearnAPI.IID","category":"page"},{"location":"operations/#Reference","page":"Predict and other operations","title":"Reference","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"LearnAPI.predict\nLearnAPI.transform\nLearnAPI.inverse_transform","category":"page"},{"location":"operations/#LearnAPI.predict","page":"Predict and other operations","title":"LearnAPI.predict","text":"LearnAPI.predict(algorithm, kind_of_proxy::LearnAPI.KindOfProxy, fitted_params, data...)\n\nReturn (ŷ, report) where ŷ is the predictions (a data object with target predictions as observations) or a proxy for these, for the specified algorithm having learned parameters fitted_params (first object returned by LearnAPI.fit(algorithm, ...)).  The report contains ancilliary byproducts of the computation, or is nothing; data is a tuple of data objects, generally a single object representing new observations not seen in training. \n\nWhere available, use kind_of_proxy=LiteralTarget() for ordinary target predictions, and kind_of_proxy=Distribution() for PDF/PMF predictions. Always available is kind_of_proxy=LearnAPI.preferredkindof_proxy(algorithm)`.\n\nFor a full list of target proxy types, run subtypes(LearnAPI.KindOfProxy) and subtypes(LearnAPI.IID).\n\nNew implementations\n\nIf implemented, you must include :predict in the tuple returned by the LearnAPI.functions trait. \n\nIf implementing LearnAPI.predict, then a LearnAPI.preferred_kind_of_proxy declaration is required, as in\n\nLearnAPI.preferred_kind_of_proxy(::Type{<:SomeAlgorithm}) = LearnAPI.Distribution()\n\nwhich has the shorthand\n\n@trait SomeAlgorithm preferred_kind_of_proxy=LearnAPI.Distribution()\n\nThe value of this trait must be an instance T(), where T <: LearnAPI.KindOfProxy.\n\nSee also LearnAPI.fit.\n\n\n\n\n\n","category":"function"},{"location":"operations/#LearnAPI.transform","page":"Predict and other operations","title":"LearnAPI.transform","text":"LearnAPI.transform(algorithm, fitted_params, data...)\n\nReturn (output, report), where output is some kind of transformation of data, provided by algorithm, based on the learned parameters fitted_params (the first object returned by LearnAPI.fit(algorithm, ...)). The fitted_params could be nothing, in the case of algorithms that do not generalize to new data. The report contains ancilliary byproducts of the computation, or is nothing; data is a tuple of data objects, generally a single object representing new observations not seen in training. \n\nNew implementations\n\nIf implemented, you must include :transform in the tuple returned by the LearnAPI.functions trait. \n\nSee also LearnAPI.inverse_transform, LearnAPI.fit, LearnAPI.predict,\n\n\n\n\n\n","category":"function"},{"location":"operations/#LearnAPI.inverse_transform","page":"Predict and other operations","title":"LearnAPI.inverse_transform","text":"LearnAPI.inverse_transform(algorithm, fitted_params, data)\n\nReturn (data_inverted, report), where data_inverted is valid input to the call\n\nLearnAPI.transform(algorithm, fitted_params, data_inverted)\n\nThe report contains ancilliary byproducts of the computation, or is nothing; data is a tuple of data objects, generally a single object representing new observations not seen in training. \n\nTypically, the map\n\ndata -> first(inverse_transform(algorithm, fitted_params, data))\n\nwill be an inverse, approximate inverse, right inverse, or approximate right inverse, for the map\n\ndata -> first(transform(algorithm, fitted_params, data))\n\nFor example, if transform corresponds to a projection, inverse_transform might be the corresponding embedding.\n\nNew implementations\n\nIf implemented, you must include :transform in the tuple returned by the LearnAPI.functions trait. \n\nSee also LearnAPI.fit, LearnAPI.predict,\n\n\n\n\n\n","category":"function"},{"location":"accessor_functions/#Accessor-Functions","page":"Accessor Functions","title":"Accessor Functions","text":"","category":"section"},{"location":"accessor_functions/","page":"Accessor Functions","title":"Accessor Functions","text":"Summary. While byproducts of training are ordinarily recorded in the report component of the output of fit/update!/ingest!, some families of algorithms report an item that is likely shared by multiple algorithm types, and it is useful to have common interface for accessing these directly. Training losses and feature importances are two examples.","category":"page"},{"location":"accessor_functions/","page":"Accessor Functions","title":"Accessor Functions","text":"LearnAPI.feature_importances\nLearnAPI.training_losses\nLearnAPI.training_scores\nLearnAPI.training_labels","category":"page"},{"location":"accessor_functions/#LearnAPI.feature_importances","page":"Accessor Functions","title":"LearnAPI.feature_importances","text":"LearnAPI.feature_importances(algorithm, fitted_params, report)\n\nReturn the algorithm-specific feature importances of algorithm, given fitted_params and report, as returned by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!. The value returned has the form of an abstract vector of feature::Symbol => importance::Real pairs (e.g [:gender => 0.23, :height => 0.7, :weight => 0.1]).\n\nThe algorithm supports feature importances if :feature_importance in LearnAPI.functions(algorithm).\n\nIf an algorithm is sometimes unable to report feature importances then feature_importances will return all importances as 0.0, as in [:gender => 0.0, :height => 0.0, :weight => 0.0].\n\nNew implementations\n\nLearnAPI.feature_importances(algorithm::SomeAlgorithmType, fitted_params, report) may be overloaded for any type SomeAlgorithmType whose instances are algorithms in the LearnAPI sense. If an algorithm can report multiple feature importance types, then the specific type to be reported should be controlled by a hyperparameter (i.e., by some property of algorithm).\n\nIf implemented, you must include :feature_importances in the tuple returned by the LearnAPI.functions trait. .\n\n\n\n\n\n","category":"function"},{"location":"accessor_functions/#LearnAPI.training_losses","page":"Accessor Functions","title":"LearnAPI.training_losses","text":"training_losses(algorithm, fitted_params, report)\n\nReturn the training losses for algorithm, given fitted_params and report, as returned by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!.\n\nNew implementations\n\nImplement for iterative algorithms that compute and record training losses as part of training (e.g. neural networks).\n\nIf implemented, you must include :training_losses in the tuple returned by the LearnAPI.functions trait. .\n\n\n\n\n\n","category":"function"},{"location":"accessor_functions/#LearnAPI.training_scores","page":"Accessor Functions","title":"LearnAPI.training_scores","text":"training_scores(algorithm, fitted_params, report)\n\nReturn the training scores for algorithm, given fitted_params and report, as returned by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!.\n\nNew implementations\n\nImplement for algorithms, such as outlier detection algorithms, which associate a score with each observation during training, where these scores are of interest in later processes (e.g, in defining normalized scores on new data).\n\nIf implemented, you must include :training_scores in the tuple returned by the LearnAPI.functions trait. .\n\n\n\n\n\n","category":"function"},{"location":"accessor_functions/#LearnAPI.training_labels","page":"Accessor Functions","title":"LearnAPI.training_labels","text":"training_labels(algorithm, fitted_params, report)\n\nReturn the training labels for algorithm, given fitted_params and report, as returned by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!.\n\nNew implementations\n\nIf implemented, you must include :training_labels in the tuple returned by the LearnAPI.functions trait. .\n\n\n\n\n\n","category":"function"},{"location":"patterns/incremental_models/#Incremental-Algorithms","page":"Incremental Algorithms","title":"Incremental Algorithms","text":"","category":"section"},{"location":"goals_and_approach/#Goals-and-Approach","page":"Goals and Approach","title":"Goals and Approach","text":"","category":"section"},{"location":"goals_and_approach/#Goals","page":"Goals and Approach","title":"Goals","text":"","category":"section"},{"location":"goals_and_approach/","page":"Goals and Approach","title":"Goals and Approach","text":"Ease of implementation for existing ML/statistics algorithms\nBreadth of applicability\nFlexibility in extending functionality\nProvision of clear interface points for algorithm-generic tooling, such as performance evaluation through resampling, hyperparameter optimization, and iterative algorithm control.\nShould make minimal assumptions about data containers\nShould be documented in detail","category":"page"},{"location":"goals_and_approach/","page":"Goals and Approach","title":"Goals and Approach","text":"In particular, the first three goals are to take precedence over user convenience, which is addressed with a separate, User Interface.","category":"page"},{"location":"goals_and_approach/#Approach","page":"Goals and Approach","title":"Approach","text":"","category":"section"},{"location":"goals_and_approach/","page":"Goals and Approach","title":"Goals and Approach","text":"ML/Statistics algorithms have a complicated taxonomy. Grouping algorithms, or modelling tasks, into a relatively small number of categories, such as \"classification\" and \"clusterering\", and then imposing uniform behavior within each group, is challenging. In our experience developing the MLJ ecosystem, this either leads to limitations on the algorithms that can be included in a general interface, or additional complexity needed to cope with exceptional cases. Even if a complete data science framework might benefit from such groupings, a basement-level API should, in our view, avoid them.","category":"page"},{"location":"goals_and_approach/","page":"Goals and Approach","title":"Goals and Approach","text":"In addition to basic methods, like fit and predict, LearnAPI provides a number of optional algorithm traits, each promising a specific kind of behavior, such as \"This algorithm supports class weights\".  There is no abstract type hierarchy for ML/statistics algorithms.","category":"page"},{"location":"goals_and_approach/","page":"Goals and Approach","title":"Goals and Approach","text":"LearnAPI.jl intentionally focuses on the notion of target variables and target proxies, which can exist in both the superised and unsupervised setting, rather than on the supervised/unsupervised dichotomy. In this view a supervised model is simply one which has a target variable and whose target variable appears in training.","category":"page"},{"location":"goals_and_approach/","page":"Goals and Approach","title":"Goals and Approach","text":"LearnAPI is a basement-level interface and not a general ML/statistics toolbox. Algorithms can be supervised or not supervised, can generalize to new data observations (i.e., \"learn\") or not generalize (e.g., \"one-shot\" clusterers).","category":"page"},{"location":"patterns/learning_a_probability_distribution/#Learning-a-Probability-Distribution","page":"Learning a Probability Distribution","title":"Learning a Probability Distribution","text":"","category":"section"},{"location":"patterns/dimension_reduction/#Dimension-Reduction","page":"Dimension Reduction","title":"Dimension Reduction","text":"","category":"section"},{"location":"patterns/time_series_forecasting/#Time-Series-Forecasting","page":"Time Series Forecasting","title":"Time Series Forecasting","text":"","category":"section"},{"location":"fit_update_and_ingest/#Fit,-update!-and-ingest!","page":"Fit, update and ingest","title":"Fit, update! and ingest!","text":"","category":"section"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"Summary. Algorithms that learn, i.e., generalize to new data, must overload fit; the fallback performs no operation and returns all nothing. Implement update! if certain hyperparameter changes do not necessitate retraining from scratch (e.g., increasing an iteration parameter). Implement ingest! to implement incremental learning. All training methods implemented must be named in the return value of the functions trait.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"method fallback compulsory? requires\nLearnAPI.fit does nothing, returns (nothing, nothing, nothing) no \nLearnAPI.update! calls fit no LearnAPI.fit\nLearnAPI.ingest! none no LearnAPI.fit","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"All three methods above return a triple (fitted_params, state, report) whose components are explained under LearnAPI.fit below.  Items that might be returned in report include: feature rankings/importances, SVM support vectors, clustering centers, methods for visualizing training outcomes, methods for saving learned parameters in a custom format, degrees of freedom, deviances. Precisely what report includes might be controlled by hyperparameters (algorithm properties) especially if there is a performance cost to it's inclusion.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"Implement fit unless all operations, such as predict and transform, ignore their fitted_params argument (which will be nothing). This is the case for many algorithms that have hyperparameters, but do not generalize to new data, such as a basic DBSCAN clustering algorithm.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"The update! method is intended for all subsequent calls to train an algorithm using the same observations, but with possibly altered hyperparameters (algorithm argument). A fallback implementation simply calls fit. The main use cases for implementing update are: ","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"warm-restarting iterative algorithms\n\"smart\" training of composite algorithms, such as linear pipelines; here \"smart\" means that hyperparameter changes only trigger the retraining of downstream components.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"The ingest! method supports incremental learning (same hyperparameters, but new training observations). Like update!, it depends on the output a preceding fit or ingest! call.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"LearnAPI.fit\nLearnAPI.update!\nLearnAPI.ingest!","category":"page"},{"location":"fit_update_and_ingest/#LearnAPI.fit","page":"Fit, update and ingest","title":"LearnAPI.fit","text":"LearnAPI.fit(algorithm, verbosity, data...; metadata...)\n\nPerform training associated with algorithm using the provided data and metadata. With the exception of warnings, training will be silent if verbosity == 0. Lower values should suppress warnings; any integer ought to be admissible. Here:\n\nalgorithm is a property-accessible object whose properties are the hyperparameters of  some ML/statistical algorithm.\ndata is a tuple of data objects with a common number of observations, for example, data = (X, y, w) where X is a table of features, y is a target vector with the same number of rows, and w a vector of per-observation weights.\nmetadata is for extra information pertaining to the data that is never iterated or subsampled. Examples, include target class weights and group lasso feature groupings. Further examples include feature names, and the pool of target classes, when these are not embedded in the data representation.  To see the keyword names for metadata supported by algorithm, do LearnAPI.fit_keywords(algorithm). \"\n\nReturn value\n\nReturns a tuple (fitted_params, state, report) where:\n\nThe fitted_params is the algorithm's learned parameters (eg, the coefficients in a linear algorithm) in a form understood by operations. An operation is a method dispatched on an algorithm, associated learned parameters, and data. The LearnAPI operations are: LearnAPI.predict, LearnAPI.transform, LearnAPI.inverse_transform.  If some training outcome of user-interest is not needed for operations, it should be part of report instead (see below).\nThe state is for passing to LearnAPI.update! or LearnAPI.ingest!. For algorithms that implement neither, state should be nothing.\nThe report records byproducts of training not in the fitted_params, such as feature rankings, or out-of-sample estimates of performance.\n\nNew implementations\n\nOverloading this method for new algorithms is optional.  A fallback performs no computation, returning (nothing, nothing, nothing).\n\nSee the LearnAPI.jl documentation for the detailed requirements of LearnAPI.jl algorithm objects.\n\nIn LearnAPI, data is any tuple of objects sharing a common number of \"observations. \"\n\nnote: Note\nThe method is not permitted to mutate algorithm. In particular, if algorithm has a random number generator as a hyperparameter (property) then it must be copied before use.\n\nIf implemented, you must include :fit in the tuple returned by the LearnAPI.functions trait. \n\nIf supporting metadata, you must also implement LearnAPI.fit_keywords to list the supported keyword argument names (e.g., class_weights).\n\nSee also LearnAPI.update!, LearnAPI.ingest!.\n\n\n\n\n\n","category":"function"},{"location":"fit_update_and_ingest/#LearnAPI.update!","page":"Fit, update and ingest","title":"LearnAPI.update!","text":"LearnAPI.update!(algorithm, verbosity, fitted_params, state, data...; metadata...)\n\nBased on the values of state, and fitted_params returned by a preceding call to LearnAPI.fit, LearnAPI.ingest!, or LearnAPI.update!, update a algorithm's fitted parameters, returning new (or mutated) state and fitted_params.\n\nIntended for retraining when the training data has not changed, but algorithm properties (hyperparameters) may have changed, e.g., when increasing an iteration parameter. Specifically, the assumption is that data and metadata have the same values seen in the most recent call to fit/update!/ingest!.\n\nFor incremental training (same algorithm, new data) see instead LearnAPI.ingest!.\n\nReturn value\n\nSame as LearnAPI.fit, namely a tuple (fitted_params, state, report). See LearnAPI.fit for details.\n\nNew implementations\n\nOverloading this method is optional. A fallback calls LearnAPI.fit:\n\nLearnAPI.update!(algorithm, verbosity, fitted_params, state, data...; metadata...) =\n    fit(algorithm, verbosity, data; metadata...)\n\nIf implemented, you must include :fit in the tuple returned by the LearnAPI.functions trait. \n\nIn LearnAPI, data is any tuple of objects sharing a common number of \"observations. \"\n\nThe most common use case is continuing training of an iterative algorithm: state is simply a copy of the algorithm used in the last training call (fit, update! or ingest!) and this will include the current number of iterations as a property. If algorithm and state differ only in the number of iterations (e.g., epochs in a neural network), which has increased, then the fitted parameters (weights) are updated, rather than computed from scratch. Otherwise, update! simply calls fit, to force retraining from scratch.\n\nIt is permitted to return mutated versions of state and fitted_params.\n\nnote: Note\nThe method is not permitted to mutate algorithm. In particular, if algorithm has a random number generator as a hyperparameter (property) then it must be copied before use.\n\nSee also LearnAPI.fit, LearnAPI.ingest!.\n\n\n\n\n\n","category":"function"},{"location":"fit_update_and_ingest/#LearnAPI.ingest!","page":"Fit, update and ingest","title":"LearnAPI.ingest!","text":"LernAPI.ingest!(algorithm, verbosity, fitted_params, state, data...; metadata...)\n\nFor an algorithm that supports incremental learning, update the fitted parameters using data, which has typically not been seen before.  The arguments state and fitted_params are the output of a preceding call to LearnAPI.fit, LearnAPI.ingest!, or LearnAPI.update!, of which mutated or new versions are returned.\n\nFor updating fitted parameters using the same data but new hyperparameters, see instead LearnAPI.update!.\n\nFor training an algorithm with new hyperparameters but unchanged data, see instead LearnAPI.update!.\n\nReturn value\n\nSame as LearnAPI.fit, namely a tuple (fitted_params, state, report). See LearnAPI.fit for details.\n\nNew implementations\n\nImplementing this method is optional. It has no fallback.\n\nIf implemented, you must include :fit in the tuple returned by the LearnAPI.functions trait. \n\nnote: Note\nThe method is not permitted to mutate algorithm. In particular, if algorithm has a random number generator as a hyperparameter (property) then it must be copied before use.\n\nSee also LearnAPI.fit, LearnAPI.update!.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Overview","title":"Overview","text":"<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n<span style=\"color: #9558B2;font-size:4.5em;\">\nLearnAPI.jl</span>\n<br>\n<span style=\"color: #9558B2;font-size:1.6em;font-style:italic;\">\nA base Julia interface for machine learning and statistics </span>\n<br><br>","category":"page"},{"location":"#Accelerated-overview","page":"Overview","title":"Accelerated overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"LearnAPI.jl provides a collection methods stubs, such as fit and predict, to be implemented by algorithms from machine learning and statistics. Through such implementations, such algorithms buy into algorithm-generic functionality, such as hyperparameter optimization, as provided by ML/statistics toolboxes and other packages. LearnAPI.jl also provides a number of Julia traits for making specific promises of behavior.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"It is designed to be powerful, from the point of view of adding algorithm-generic functionality, while minimizing the burden on developers implementing the API for a specific algorithm.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"To see how to DEVELOPERS INTERACT with algorithms implementing LearnAPI, see Basic fit/predict workflow.\nTo see how USERS INTERACT with LearnAPI algorithms, see User Interface.[under construction]\nFor developers wanting to IMPLEMENT LearnAPI, see Anatomy of an Implementation.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"For more on package goals and philosophy, see Goals and Approach.","category":"page"},{"location":"#Methods","page":"Overview","title":"Methods","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"In LearnAPI an algorithm is a Julia object storing the hyperparameters of some ML/statistics algorithm.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The following methods, dispatched on algorithm type, are provided:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"fit, overloaded if an algorithm involves a learning step, as in classical supervised learning; the principal output of fit is learned parameters\nupdate!, for adding iterations to an algorithm, or responding efficiently to other post-fitchanges in hyperparameters\ningest!, for incremental learning (training further using new data, without re-initializing learned parameters)\noperations, which apply the algorithm to data, typically not seen in training, if there is any:\npredict, for predicting values of a target variable or a proxy for the target, such\tas probability distributions; see below\ntransform, for other kinds transformations\ninverse_transform, for reconstructing data from a transformed representation\ncommon accessor functions, such as feature_importances and training_losses, for extracting, from training outcomes, information common to a number of different algorithms\nalgorithm traits, such as predict_output_type(algorithm), for promising specific behavior","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Since this is a functional-style interface, fit returns algorithm state, in addition to learned parameters, for passing to the optional update! and ingest! methods. These training methods also return a report component, for exposing byproducts of training different from learned parameters. Similarly, all operations also return a report component (important for algorithms that do not generalize to new data).","category":"page"},{"location":"#scope","page":"Overview","title":"Informal concepts","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"LearnAPI.jl is predicated on a few basic, informally defined notions, in italics below, which some higher-level interface might decide to formalize.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"An object which generates ordered sequences of individual observations is called data. For example a DataFrame instance, from DataFrames.jl, is considered data, the observations being the rows. A matrix can be considered data, but whether the observations are rows or columns is ambiguous and not fixed by LearnAPI.\nEach machine learning algorithm's behavior is governed by a number of user-specified hyperparameters. The regularization parameter in ridge regression is an example. Hyperparameters are data-independent. For example, the number of target classes is not a hyperparameter.\nInformation needed for training that is not a hyperparameter and not data is called metadata. Examples, include target class weights and group lasso feature groupings. Further examples include feature names, and the pool of target classes, when these are not embedded in the data representation.","category":"page"},{"location":"#proxy","page":"Overview","title":"Targets and target proxies","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"After training, a supervised classifier predicts labels on some input which are then compared with ground truth labels using some accuracy measure, to assesses the performance of the classifier. Alternatively, the classifier predicts class probabilities, which are instead paired with ground truth labels using a proper scoring rule, say. In outlier detection, \"outlier\"/\"inlier\" predictions, or probability-like scores, are similarly compared with ground truth labels. In clustering, integer labels assigned to observations by the clustering algorithm can can be paired with human labels using, say, the Rand index. In survival analysis, predicted survival functions or probability distributions are compared with censored ground truth survival times.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"More generally, whenever we have a predicted variable (e.g., a class label) paired with itself or some proxy (such as a class probability) we call the variable a target variable, and the predicted output a target proxy. It is immaterial whether or not the target appears in training (is supervised) or whether the model generalizes to new observations (learns) or not. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The target and the kind of predicted proxy are crucial features of ML/statistics performance measures and LearnAPI.jl provides a detailed list of proxy dispatch types (see Target proxies), as well as algorithm traits to articulate target type /scitype.","category":"page"},{"location":"#Optional-data-interface","page":"Overview","title":"Optional data interface","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"It can be useful to distinguish between data that exists at some high level, convenient for the general user - such as a table (dataframe) or the path to a directory containing image files - and a performant, algorithm-specific representation of that data, such as a matrix or image \"data loader\". When retraining using the same data with new hyperparameters, one wants to avoid recreating the algorithm-specific representation, and, accordingly, a higher level interface may want to cache such representations. Furthermore, in resampling (e.g., cross-validation), a higher level interface wants to directly resample the algorithm-specific representation, so it needs to know how to do that. To meet these two ends, LearnAPI provides two additional data methods dispatched on algorithm type:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"reformat(algorithm, ...), for converting from a user data representation to a performant algorithm-specific representation, whose output is for use in fit, predict, etc. above\ngetobs(algorithm, ...), for extracting a subsample of observations of the algorithm-specific representation","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"It should be emphasized that LearnAPI is itself agnostic to particular representations of data or the particular methods of accessing observations within them. By overloading these methods, each algorithm is free to choose its own data interface.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"See Optional data Interface for more details.","category":"page"},{"location":"#Contents","page":"Overview","title":"Contents","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"It is useful to have a guide to the interface, linked below, organized around common informally defined patterns or \"tasks\". However, the definitive specification of the interface is the Reference section.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Overview: Anatomy of an Implementation\nOfficial Specification: Reference\nUser guide: Common Implementation Patterns [under construction]\nTesting an Implementation [under construction]","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"info: Info\nIt is recommended developers read Anatomy of an Implementation before consulting the guide or reference sections.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Note. In the future, LearnAPI.jl may become the new foundation for the MLJ toolbox. However, LearnAPI.jl is meant as a general purpose, stand-alone, lightweight, low level API (and has no reference to the \"machines\" used in MLJ).","category":"page"},{"location":"patterns/outlier_detection/#Outlier-Detection","page":"Outlier Detection","title":"Outlier Detection","text":"","category":"section"},{"location":"patterns/incremental_algorithms/#Incremental-Models","page":"Incremental Models","title":"Incremental Models","text":"","category":"section"}]
}
