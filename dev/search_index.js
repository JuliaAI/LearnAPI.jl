var documenterSearchIndex = {"docs":
[{"location":"patterns/missing_value_imputation/#Missing-Value-Imputation","page":"Missing Value Imputation","title":"Missing Value Imputation","text":"","category":"section"},{"location":"patterns/survival_analysis/#Survival-Analysis","page":"Survival Analysis","title":"Survival Analysis","text":"","category":"section"},{"location":"optional_data_interface/#data_interface","page":"Optional Data Interface","title":"Optional Data Interface","text":"","category":"section"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"Summary. Implement getobs to articulate how to generate individual observations from data consumed by a LearnAPI model. Implement reformat to provide a higher level interface the means to avoid repeating transformations from user representations of data (such as a dataframe) and model-specific representations (such as a matrix).","category":"page"},{"location":"optional_data_interface/#Resampling","page":"Optional Data Interface","title":"Resampling","text":"","category":"section"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"To aid in programmatic resampling, such as cross-validation, it is helpful if each machine learning model articulates how the data it consumes can be subsampled - that is, how a subset of observations can be extracted from that data. Another advantage of doing so is to mitigate some of the ambiguities around structuring observations within the container: Are the observations in a matrix the rows or the columns?","category":"page"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"In LearnAPI, an implementation can articulate a subsampling method by implementing LearnAPI.getobs(model, func, I, data...) for each function func consuming data, such as fit and predict. Examples are given below.","category":"page"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"LearnAPI.getobs","category":"page"},{"location":"optional_data_interface/#LearnAPI.getobs","page":"Optional Data Interface","title":"LearnAPI.getobs","text":"LearnAPI.getobs(model, LearnAPI.fit, I, data...)\n\nReturn a subsample of data consisting of all observations with indices in I. Here data is data of the form expected in a call like LearnAPI.fit(model, verbosity, data...; metadata...).\n\nAlways returns a tuple of the same length as data.\n\nLearnAPI.getobs(model, operation, I, data...)\n\nReturn a subsample of data consisting of all observations with indices in I. Here data is data of the form expected in a call of the specified operation, e.g., in a call like LearnAPI.predict(model, data...), if operation = LearnAPI.predict. Possible values for operation are: :predict, :predict_joint, :transform, :inverse_transform.\n\nAlways returns a tuple of the same length as data.\n\nNew model implementations\n\nImplementation is optional. If implemented, then ordinarily implemented for each signature of fit and operation implemented for model.\n\nIf implemented, you must include :reformat in the tuple returned by the LearnAPI.functions trait. \n\nThe subsample returned must be acceptable in place of data in calls of the function named in the second argument.\n\nExample implementation\n\nSuppose that MyClassifier is a model type for simple supervised classification, with LearnAPI.fit(model::MyClassifier, verbosity, A, y) and predict(model::MyClassifier, fitted_params, A) implemented assuming the target y is an ordinary abstract vector and the features A is an abstract matrix with columns as observations. Then the following is a valid implementation of getobs:\n\nLearnAPI.getobs(::MyClassifier, ::typeof(LearnAPI.fit), I, A, y) =\n    (view(A, :, I), view(y, I))\nLearnAPI.getobs(::MyClassifier, ::typeof(LearnAPI.predict), I, A) = (view(A, :, I),)\n\n\n\n\n\n","category":"function"},{"location":"optional_data_interface/#Preprocessing","page":"Optional Data Interface","title":"Preprocessing","text":"","category":"section"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"So that a higher level interface can avoid unnecessarily repeating calls to convert user-supplied data (e.g., a dataframe) into some performant, model-specific representation, a model can move such data conversions out of fit, predict, etc., and into an implementation of LearnAPI.reformat created for each signature of such methods that are implemented. Examples are given below.","category":"page"},{"location":"optional_data_interface/","page":"Optional Data Interface","title":"Optional Data Interface","text":"LearnAPI.reformat","category":"page"},{"location":"optional_data_interface/#LearnAPI.reformat","page":"Optional Data Interface","title":"LearnAPI.reformat","text":"LearnAPI.reformat(model, LearnAPI.fit, user_data...; metadata...)\n\nReturn the model-specific representations (data, metadata) of user-supplied (user_data, user_metadata), for consumption, after splatting, by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!.\n\nLearnAPI.reformat(model, operation, user_data...)\n\nReturn the model-specific representation data of user-supplied user_data, for consumption, after splatting, by the specified operation, dispatched on model. Here operation is one of: :predict, :predict_joint, :transform, :inverse_transform.\n\nThe following sample workflow illustrates the use of both versions of reformatabove. The data objects X, y, and Xtest are the user-supplied versions of data.\n\ndata, metadata = LearnAPI.reformat(model, LearnAPI.fit, X, y; class_weights=some_dictionary)\nfitted_params, state, fit_report = LearnAPI.fit(model, 0, data...; metadata...)\n\ntest_data = LearnAPI.reformat(model, LearnAPI.predict, Xtest)\nyÌ‚, predict_report = LearnAPI.predict(model, fitted_params, test_data...)\n\nNew model implementations\n\nImplementation of reformat is optional. The fallback simply slurps the supplied data/metadata. You will want to implement for each fit or operation signature implemented for model.\n\nIf overloaded, you must include :reformat in the tuple returned by the LearnAPI.functions trait. \n\nIdeally, any potentially expensive transformation of user-supplied data that is carried out during training only once, at the beginning, should occur in reformat instead of fit/update!/ingest!.\n\nNote that the first form of reformat, for operations, should always return a tuple, because the output is splat in calls to the operation (see the sample workflow above). Similarly, in the return value (data, metadata) for the fit variant, data is always a tuple and metadata always a named tuple (or Base.Pairs object). If there is no metadata, a NamedTuple() can be returned in its place.\n\nExample implementation\n\nSuppose that MyClassifier is a model type for simple supervised classification, with LearnAPI.fit(model::MyClassifier, verbosity, A, y; names=...) and predict(model::MyClassifier, fitted_params, A) implemented assuming that the target y is an ordinary vector, the features A is a matrix with columns as observations, and names are the names of the features. Then, supposing users supply features in tabular form, but target as expected, then we can provide the following implementation of reformat:\n\nusing Tables\nfunction LearnAPI.reformat(::MyClassifier, ::typeof(LearnAPI.fit), X, y)\n    names = Tables.schema(Tables.rows(X)).names\n    return ((Tables.matrix(X)', y), (; names))\nend\nLearnAPI.reformat(::MyClassifier, ::typeof(LearnAPI.predict), X) = (Tables.matrix(X)',)\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#Model-Traits","page":"Model Traits","title":"Model Traits","text":"","category":"section"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"Summary. Traits allow one to promise particular behaviour for a model, such as: This model supports per-observation weights, which must appear as the third argument of fit, or This model predicts probability distributions for the target, or This model's transform method predicts Real vectors.","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"Traits are optional, except where required by the implementation of some LearnAPI method and documented in that method's docstring. Unless a model has no functionality whatsoever, LearnAPI.functions(model) will need to be overloaded.","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"Traits are often called on instances but are frequently defined on model types, as in","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"LearnAPI.is_pure_julia(::Type{<:MyModelType}) = true","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"which has the shorthand","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"@trait MyModelType is_pure_julia=true","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"So, for convenience, every trait t is provided the fallback implementation","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"t(model) = t(typeof(model))","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"This means LearnAPI.is_pure_julia(model) = true whenever model isa MyModelType in the above example.","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"Every trait has a global fallback implementation for ::Type. ","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"Traits that vary from instance to instance of the same type are discouraged, except in the case of composite models (is_wrapper(model) = true) where this is unavoidable. One reason for this is so one can associate with each model type a unique set of trait-based \"model metadata\" for inclusion in searchable model databases. This requirement occasionally requires that an existing model implementation be split into several separate LearnAPI implementations (e.g., one for regression and another for classification).","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"Ordinary traits are available for overloading by an new model implementation. Derived traits are not.","category":"page"},{"location":"model_traits/#Ordinary-traits","page":"Model Traits","title":"Ordinary traits","text":"","category":"section"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"In the examples column of the table below, Table, Continuous, Sampleable are names owned by the package ScientificTypesBase.jl.","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"trait fallback value return value example\nLearnAPI.functions(model) () implemented LearnAPI functions (traits excluded) (:fit, :predict)\nLearnAPI.predict_proxy(model) LearnAPI.None() form of target proxy output by predict LearnAPI.Distribution()\nLearnAPI.predict_joint_proxy(model) LearnAPI.None() form of target proxy output by predict_joint LearnAPI.Distribution()\nLearnAPI.position_of_target(model) 0 â€  the positional index of the target in data in fit(..., data...; metadata) calls 2\nLearnAPI.position_of_weights(model) 0 â€  the positional index of per-observation weights in data in fit(..., data...; metadata) 3\nLearnAPI.descriptors(model) () lists one or more suggestive model descriptors from LearnAPI.descriptors() (:classifier, :probabilistic)\nLearnAPI.is_pure_julia(model) false is true if implementation is 100% Julia code true\nLearnAPI.pkg_name(model) \"unknown\" name of package providing core algorithm (may be different from package providing LearnAPI.jl implementation) \"DecisionTree\"\nLearnAPI.pkg_license(model) \"unknown\" name of license of package providing core algorithm \"MIT\"\nLearnAPI.doc_url(model) \"unknown\" url providing documentation of the core algorithm \"https://en.wikipedia.org/wiki/Decision_tree_learning\"\nLearnAPI.load_path(model) \"unknown\" a string indicating where the struct for typeof(model) is defined, beginning with name of package providing implementation FastTrees.LearnAPI.DecisionTreeClassifier\nLearnAPI.is_wrapper(model) false is true if one or more properties (fields) of model may be a model true\nLearnAPI.human_name(model) type name with spaces human name for the model; should be a noun \"elastic net regressor\"\nLearnAPI.iteration_parameter(model) nothing symbolic name of an iteration parameter :epochs\nLearnAPI.fit_keywords(model) () tuple of symbols for keyword arguments accepted by fit (corresponding  to metadata) (:class_weights,)\nLearnAPI.fit_scitype(model) Union{} upper bound on scitype(data) in fit(model, verbosity, data...)â€ â€  Tuple{Table(Continuous), AbstractVector{Continuous}}\nLearnAPI.fit_observation_scitype(model) Union{} upper bound on scitype(observation) for observation in data and data in fit(model, verbosity, data...)â€ â€  Tuple{AbstractVector{Continuous}, Continuous}\nLearnAPI.fit_type(model) Union{} upper bound on type(data) in fit(model, verbosity, data...)â€ â€  Tuple{AbstractMatrix{<:Real}, AbstractVector{<:Real}}\nLearnAPI.fit_observation_type(model) Union{} upper bound on type(observation) for observation in data and data in fit(model, verbosity, data...)* Tuple{AbstractVector{<:Real}, Real}\nLearnAPI.predict_input_scitype(model) Union{} upper bound on scitype(data) in predict(model, fitted_params, data...)â€ â€  Table(Continuous)\nLearnAPI.predict_output_scitype(model) Any upper bound on scitype(first(predict(model, ...))) AbstractVector{Continuous}\nLearnAPI.predict_input_type(model) Union{} upper bound on typeof(data) in predict(model, fitted_params, data...)â€ â€  AbstractMatrix{<:Real}\nLearnAPI.predict_output_type(model) Any upper bound on typeof(first(predict(model, ...))) AbstractVector{<:Real}\nLearnAPI.predict_joint_input_scitype(model) Union{} upper bound on scitype(data) in predict_joint(model, fitted_params, data...)â€ â€  Table(Continuous)\nLearnAPI.predict_joint_output_scitype(model) Any upper bound on scitype(first(predict_joint(model, ...))) Sampleable{<:AbstractVector{Continuous}}\nLearnAPI.predict_joint_input_type(model) Union{} upper bound on typeof(data) in predict_joint(model, fitted_params, data...)â€ â€  AbstractMatrix{<:Real}\nLearnAPI.predict_joint_output_type(model) Any upper bound on typeof(first(predict_joint(model, ...))) Distributions.Sampleable{Distributions.Multivariate,Distributions.Continuous}\nLearnAPI.transform_input_scitype(model) Union{} upper bound on scitype(data) in transform(model, fitted_params, data...)â€ â€  Table(Continuous)\nLearnAPI.transform_output_scitype(model) Any upper bound on scitype(first(transform(model, ...))) Table(Continuous)\nLearnAPI.transform_input_type(model) Union{} upper bound on typeof(data) in transform(model, fitted_params, data...)â€ â€  AbstractMatrix{<:Real}}\nLearnAPI.transform_output_type(model) Any upper bound on typeof(first(transform(model, ...))) AbstractMatrix{<:Real}\nLearnAPI.inverse_transform_input_scitype(model) Union{} upper bound on scitype(data) in inverse_transform(model, fitted_params, data...)â€ â€  Table(Continuous)\nLearnAPI.inverse_transform_output_scitype(model) Any upper bound on scitype(first(inverse_transform(model, ...))) Table(Continuous)\nLearnAPI.inverse_transform_input_type(model) Union{} upper bound on typeof(data) in inverse_transform(model, fitted_params, data...)â€ â€  AbstractMatrix{<:Real}\nLearnAPI.inverse_transform_output_type(model) Any upper bound on typeof(first(inverse_transform(model, ...))) AbstractMatrix{<:Real}","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"â€  If the value is 0, then the variable in boldface type is not supported and not expected to appear in data. If length(data) is less than the trait value, then data is understood to exclude the variable, but note that fit can have multiple signatures of varying lengths, as in fit(model, verbosity, X, y) and fit(model, verbosity, X, y, w). A non-zero value is a promise that fit includes a signature of sufficient length to include the variable.","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"â€ â€  Assuming no optional data interface is implemented. See docstring for the general case.","category":"page"},{"location":"model_traits/#Derived-Traits","page":"Model Traits","title":"Derived Traits","text":"","category":"section"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"The following convenience methods are provided but intended for overloading:","category":"page"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"trait return value example\nLearnAPI.name(model) model type name as string \"PCA\"\nLearnAPI.is_model(model) true if functions(model) is not empty true","category":"page"},{"location":"model_traits/#Reference","page":"Model Traits","title":"Reference","text":"","category":"section"},{"location":"model_traits/","page":"Model Traits","title":"Model Traits","text":"LearnAPI.functions\nLearnAPI.predict_proxy\nLearnAPI.predict_joint_proxy\nLearnAPI.position_of_target\nLearnAPI.position_of_weights\nLearnAPI.descriptors\nLearnAPI.is_pure_julia\nLearnAPI.pkg_name\nLearnAPI.pkg_license\nLearnAPI.doc_url\nLearnAPI.load_path\nLearnAPI.is_wrapper\nLearnAPI.fit_keywords\nLearnAPI.human_name\nLearnAPI.iteration_parameter\nLearnAPI.fit_scitype\nLearnAPI.fit_type\nLearnAPI.fit_observation_scitype\nLearnAPI.fit_observation_type\nLearnAPI.predict_input_scitype\nLearnAPI.predict_output_scitype\nLearnAPI.predict_input_type\nLearnAPI.predict_output_type\nLearnAPI.predict_joint_input_scitype\nLearnAPI.predict_joint_output_scitype\nLearnAPI.predict_joint_input_type\nLearnAPI.predict_joint_output_type\nLearnAPI.transform_input_scitype\nLearnAPI.transform_output_scitype\nLearnAPI.transform_input_type\nLearnAPI.transform_output_type\nLearnAPI.inverse_transform_input_scitype\nLearnAPI.inverse_transform_output_scitype\nLearnAPI.inverse_transform_input_type\nLearnAPI.inverse_transform_output_type","category":"page"},{"location":"model_traits/#LearnAPI.functions","page":"Model Traits","title":"LearnAPI.functions","text":"LearnAPI.functions(model)\n\nReturn a tuple of symbols, such as (:fit, :predict), corresponding to LearnAPI methods specifically implemented for objects having the same type as model. If non-empty, this also guarantees model is a model, in the LearnAPI sense. See the Reference section of the manual for details.\n\nNew model implementations\n\nEvery LearnAPI method that is not a trait and which is specifically implemented for typeof(model) must be included in the return value of this trait. Specifically, the return value is a tuple of symbols from this list: :fit, :update!, :ingest!, :predict, :predict_joint, :transform, :inverse_transform, :features_importances, :training_labels, :training_losses, :training_scores. To regenerate this list, do LearnAPI.functions().\n\nSee also LearnAPI.Model.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_proxy","page":"Model Traits","title":"LearnAPI.predict_proxy","text":"LearnAPI.predict_proxy(model)\n\nReturns an object with abstract type LearnAPI.TargetProxy indicating the kind of proxy for the target returned by the predict method, when called on model and some data. For example, a value of LearnAPI.Distribution() means that predict returns probability distributions, rather than actual values of the target. (LearnAPI.predict also returns a report as second value). A value of LearnAPI.TrueTarget() indicates that ordinary (non-proxy) target values are returned. A value of LearnAPI.None(), implies the output of predict has no declared relationship with any target variable.\n\nNew implementations\n\nA model with a concept of \"target\" must overload this trait. The fallback return value is LearnAPI.None().\n\nFor more on target variables and target proxies, refer to the \"Predict and Other Operations\" section of the LearnAPI documentation.\n\nThe trait must return a lone instance T() for some subtype T <: LearnAPI.TargetProxy. Here's a sample implementation for a supervised model where predictions are ordinary values of the target variable:\n\n@trait MyNewModel predict_proxy = LearnAPI.TrueTarget()\n\nwhich is shorthand for\n\nLearnAPI.predict_proxy(::Type{<:MyNewModelType}) = LearnAPI.TrueTarget()\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_joint_proxy","page":"Model Traits","title":"LearnAPI.predict_joint_proxy","text":"LearnAPI.predict_joint_proxy(model)\n\nReturns an object with abstract type LearnAPI.TargetProxy indicating the kind of proxy for the target returned by the predict_joint method, when called on model and some data. For example, a value of LearnAPI.Distribution() means that predict_joint returns a probability distribution, rather than, say a merely sampleable object.\n\nNew implementations\n\nAny model implementing LearnAPI.predict_joint must overload this trait.\n\nFor more on target variables and target proxies, refer to the LearnAPI documentation.\n\nThe possible return values for this trait are: LearnAPI.JointSampleable(), LearnAPI.JointDistribution() and LearnAPI.JointLogDistribution().\n\nHere's a sample implementation:\n\n@trait MyNewModel predict_joint_proxy = LearnAPI.JointDistribution()\n\nwhich is shorthand for\n\nLearnAPI.predict_joint_proxy(::Type{<:MyNewModelType}) = LearnAPI.JointDistribution()\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.position_of_target","page":"Model Traits","title":"LearnAPI.position_of_target","text":"LearnAPI.position_of_target(model)\n\nReturn the expected position of the target variable within data in calls of the form LearnAPI.fit(model, verbosity, data...).\n\nIf this number is 0, then no target is expected. If this number exceeds length(data), then data is understood to exclude the target variable.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.position_of_weights","page":"Model Traits","title":"LearnAPI.position_of_weights","text":"LearnAPI.position_of_weights(model)\n\nReturn the expected position of per-observation weights within data in calls of the form LearnAPI.fit(model, verbosity, data...).\n\nIf this number is 0, then no weights are expected. If this number exceeds length(data), then data is understood to exclude weights, which are assumed to be uniform.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.descriptors","page":"Model Traits","title":"LearnAPI.descriptors","text":"LearnAPI.descriptors(model)\n\nLists one or more suggestive model descriptors from this list: :regression, :classification, :clustering, :gradient_descent, :iterative_model, :incremental_model, :dimension_reduction, :transformer, :static_transformer, :missing_value_imputer, :ensemble_model, :wrapper, :time_series_forecaster, :time_series_classifier, :survival_analysis, :distribution_fitter, :Bayesian_model, :outlier_detection, :collaborative_filtering, :text_analysis, :audio_analysis, :natural_language_processing, :image_processing (do LearnAPI.descriptors() to reproduce).\n\nwarning: Warning\nThe value of this trait guarantees no particular behavior. The trait is intended for informal classification purposes only.\n\nNew model implementations\n\nThis trait should return a tuple of symbols, as in (:classifier, :probabilistic).\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.is_pure_julia","page":"Model Traits","title":"LearnAPI.is_pure_julia","text":"LearnAPI.is_pure_julia(model)\n\nReturns true if training model requires evaluation of pure Julia code only.\n\nNew model implementations\n\nThe fallback is false.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.pkg_name","page":"Model Traits","title":"LearnAPI.pkg_name","text":"LearnAPI.pkg_name(model)\n\nReturn the name of the package module which supplies the core training algorithm for model.  This is not necessarily the package providing the LearnAPI interface.\n\nReturns \"unknown\" if the model implementation has failed to overload the trait. \n\nNew model implementations\n\nMust return a string, as in \"DecisionTree\".\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.pkg_license","page":"Model Traits","title":"LearnAPI.pkg_license","text":"LearnAPI.pkg_license(model)\n\nReturn the name of the software license, such as \"MIT\", applying to the package where the core algorithm for model is implemented.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.doc_url","page":"Model Traits","title":"LearnAPI.doc_url","text":"LearnAPI.doc_url(model)\n\nReturn a url where the core algorithm for model is documented.\n\nReturns \"unknown\" if the model implementation has failed to overload the trait. \n\nNew model implementations\n\nMust return a string, such as \"https://en.wikipedia.org/wiki/Decision_tree_learning\".\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.load_path","page":"Model Traits","title":"LearnAPI.load_path","text":"LearnAPI.load_path(model)\n\nReturn a string indicating where the struct for typeof(model) can be found, beginning with the name of the package module defining it. For example, a return value of \"FastTrees.LearnAPI.DecisionTreeClassifier\" means the following julia code will return the model type:\n\nimport FastTrees\nFastTrees.LearnAPI.DecisionTreeClassifier\n\nReturns \"unknown\" if the model implementation has failed to overload the trait. \n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.is_wrapper","page":"Model Traits","title":"LearnAPI.is_wrapper","text":"LearnAPI.is_wrapper(model)\n\nReturns true if one or more properties (fields) of model may themselves be models, and false otherwise.\n\nNew model implementations\n\nThis trait must be overloaded if one or more properties (fields) of model may take model values. Fallback return value is false.\n\nThe value of the trait must depend only on the type of model. \n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.fit_keywords","page":"Model Traits","title":"LearnAPI.fit_keywords","text":"LearnAPI.fit_keywords(model)\n\nReturn a list of keywords that can be provided to fit that correspond to metadata; metadata is for extra information pertaining to the data that is never iterated or subsampled, eg., weights for target classes, or feature names (if these are not embedded in the representation of data). Another example would be feature groupings in the group lasso algorithm. \n\nNew model implementations\n\nIf LearnAPI.fit(model, ...) supports keyword arguments, then this trait must be overloaded, and otherwise not. Fallback returns ().\n\nHere's a sample implementation for a classifier that implements a LearnAPI.fit method with signature fit(model::MyClassifier, verbosity, X, y; class_weights=nothing):\n\nLearnAPI.fit_keywords(::Type{<:MyClassifier}) = (:class_weights,)\n\nor the shorthand\n\n@trait MyClassifier fit_keywords=(:class_weights,)\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.human_name","page":"Model Traits","title":"LearnAPI.human_name","text":"LearnAPI.human_name(model)\n\nA human-readable string representation of typeof(model). Primarily intended for auto-generation of documentation.\n\nNew model implementations\n\nOptional. A fallback takes the type name, inserts spaces and removes capitalization. For example, KNNRegressor becomes \"knn regressor\". Better would be to overload the trait to return \"K-nearest neighbors regressor\". Ideally, this is a \"concrete\" noun like \"ridge regressor\" rather than an \"abstract\" noun like \"ridge regression\".\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.iteration_parameter","page":"Model Traits","title":"LearnAPI.iteration_parameter","text":"LearnAPI.iteration_parameter(model)\n\nThe name of the iteration parameter of model, or nothing if the model is not iterative.\n\nNew model implementations\n\nImplement if model is iterative. Returns a symbol or nothing.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.fit_scitype","page":"Model Traits","title":"LearnAPI.fit_scitype","text":"LearnAPI.fit_scitype(model)\n\nReturn an upper bound on the scitype of data guaranteeing it to work when training model.\n\nSpecifically, if the return value is S and ScientificTypes.scitype(data) <: S, then the following low-level calls are allowed (assuming metadata is also valid and verbosity is an integer):\n\n# apply data front-end:\ndata2, metadata2 = LearnAPI.reformat(model, LearnAPI.fit, data...; metadata...)\n\n# train:\nLearnAPI.fit(model, verbosity, data2...; metadata2...)\n\nSee also LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\nNew model implementations\n\nOptional. The fallback return value is Union{}.  No more than one of the following should be overloaded for a model type: LearnAPI.fit_scitype, LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.fit_type","page":"Model Traits","title":"LearnAPI.fit_type","text":"LearnAPI.fit_type(model)\n\nReturn an upper bound on the type of data guaranteeing it to work when training model.\n\nSpecifically, if the return value is T and typeof(data) <: T, then the following low-level calls are allowed (assuming metadata is also valid and verbosity is an integer):\n\n# apply data front-end:\ndata2, metadata2 = LearnAPI.reformat(model, LearnAPI.fit, data...; metadata...)\n\n# train:\nLearnAPI.fit(model, verbosity, data2...; metadata2...)\n\nSee also LearnAPI.fit_scitype, LearnAPI.fit_observation_type. LearnAPI.fit_observation_scitype\n\nNew model implementations\n\nOptional. The fallback return value is Union{}. No more than one of the following should be overloaded for a model type: LearnAPI.fit_scitype, LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.fit_observation_scitype","page":"Model Traits","title":"LearnAPI.fit_observation_scitype","text":"LearnAPI.fit_observation_scitype(model)\n\nReturn an upper bound on the scitype of observations guaranteed to work when training model (independent of the type/scitype of the data container itself).\n\nSpecifically, denoting the type returned above by S, suppose a user supplies training data, data - typically a tuple, such as (X, y) - and valid metadata, metadata, and one computes\n\ndata2, metadata2 = LearnAPI.reformat(model, LearnAPI.fit, data...; metadata...)\n\nThen, assuming\n\nScientificTypes.scitype(LearnAPI.getobs(model, LearnAPI.fit, data2, i)) <: S\n\nfor any valid index i, the following is guaranteed to work:\n\nLearnAPI.fit(model, verbosity, data2...; metadata2...)\n\nSee also See also LearnAPI.fit_type, LearnAPI.fit_scitype, LearnAPI.fit_observation_type.\n\nNew model implementations\n\nOptional. The fallback return value is Union{}. No more than one of the following should be overloaded for a model type: LearnAPI.fit_scitype, LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.fit_observation_type","page":"Model Traits","title":"LearnAPI.fit_observation_type","text":"LearnAPI.fit_observation_type(model)\n\nReturn an upper bound on the type of observations guaranteed to work when training model (independent of the type/scitype of the data container itself).\n\nSpecifically, denoting the type returned above by T, suppose a user supplies training data, data - typically a tuple, such as (X, y) - and valid metadata, metadata, and one computes\n\ndata2, metadata2 = LearnAPI.reformat(model, LearnAPI.fit, data...; metadata...)\n\nThen, assuming\n\ntypeof(LearnAPI.getobs(model, LearnAPI.fit, data2, i)) <: T\n\nfor any valid index i, the following is guaranteed to work:\n\nLearnAPI.fit(model, verbosity, data2...; metadata2...)\n\nSee also See also LearnAPI.fit_type, LearnAPI.fit_scitype, LearnAPI.fit_observation_scitype.\n\nNew model implementations\n\nOptional. The fallback return value is Union{}. No more than one of the following should be overloaded for a model type: LearnAPI.fit_scitype, LearnAPI.fit_type, LearnAPI.fit_observation_scitype, LearnAPI.fit_observation_type.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_input_scitype","page":"Model Traits","title":"LearnAPI.predict_input_scitype","text":" LearnAPI.predict_input_scitype(model)\n\nReturn an upper bound on the scitype of input data guaranteed to work with the predict  operation.\n\nSpecifically, if S is the value returned and ScientificTypes.scitype(data) <: S,  then the following low-level calls are allowed\n\n data2 = LearnAPI.reformat(model, LearnAPI.predict, data...)\n LearnAPI.predict(model, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to  LearnAPI.fit.\n\nSee also LearnAPI.predict_input_type.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be  overloaded if LearnAPI.predict_input_type is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_output_scitype","page":"Model Traits","title":"LearnAPI.predict_output_scitype","text":"LearnAPI.predict_output_scitype(model)\n\nReturn an upper bound on the scitype of the output of the predict operation.\n\nSpecifically, if S is the value returned, and if\n\noutput, report = LearnAPI.predict(model, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\nScientificTypes.scitype(output) <: S\n\nSee also LearnAPI.predict_input_scitype.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_input_type","page":"Model Traits","title":"LearnAPI.predict_input_type","text":"LearnAPI.predict_input_type(model)\n\nReturn an upper bound on the type of input data guaranteed to work with the predict operation.\n\nSpecifically, if T is the value returned and typeof(data) <: S, then the following low-level calls are allowed\n\ndata2 = LearnAPI.reformat(model, LearnAPI.predict, data...)\nLearnAPI.predict(model, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to LearnAPI.fit.\n\nSee also LearnAPI.predict_input_scitype.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be overloaded if LearnAPI.predict_input_scitype is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_output_type","page":"Model Traits","title":"LearnAPI.predict_output_type","text":"LearnAPI.predict_output_type(model)\n\nReturn an upper bound on the type of the output of the predict operation.\n\nSpecifically, if T is the value returned, and if\n\noutput, report = LearnAPI.predict(model, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\ntypeof(output) <: T\n\nSee also LearnAPI.predict_input_type.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_joint_input_scitype","page":"Model Traits","title":"LearnAPI.predict_joint_input_scitype","text":" LearnAPI.predict_joint_input_scitype(model)\n\nReturn an upper bound on the scitype of input data guaranteed to work with the predict_joint  operation.\n\nSpecifically, if S is the value returned and ScientificTypes.scitype(data) <: S,  then the following low-level calls are allowed\n\n data2 = LearnAPI.reformat(model, LearnAPI.predict_joint, data...)\n LearnAPI.predict_joint(model, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to  LearnAPI.fit.\n\nSee also LearnAPI.predict_joint_input_type.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be  overloaded if LearnAPI.predict_joint_input_type is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_joint_output_scitype","page":"Model Traits","title":"LearnAPI.predict_joint_output_scitype","text":"LearnAPI.predict_joint_output_scitype(model)\n\nReturn an upper bound on the scitype of the output of the predict_joint operation.\n\nSpecifically, if S is the value returned, and if\n\noutput, report = LearnAPI.predict_joint(model, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\nScientificTypes.scitype(output) <: S\n\nSee also LearnAPI.predict_joint_input_scitype.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_joint_input_type","page":"Model Traits","title":"LearnAPI.predict_joint_input_type","text":"LearnAPI.predict_joint_input_type(model)\n\nReturn an upper bound on the type of input data guaranteed to work with the predict_joint operation.\n\nSpecifically, if T is the value returned and typeof(data) <: S, then the following low-level calls are allowed\n\ndata2 = LearnAPI.reformat(model, LearnAPI.predict_joint, data...)\nLearnAPI.predict_joint(model, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to LearnAPI.fit.\n\nSee also LearnAPI.predict_joint_input_scitype.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be overloaded if LearnAPI.predict_joint_input_scitype is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.predict_joint_output_type","page":"Model Traits","title":"LearnAPI.predict_joint_output_type","text":"LearnAPI.predict_joint_output_type(model)\n\nReturn an upper bound on the type of the output of the predict_joint operation.\n\nSpecifically, if T is the value returned, and if\n\noutput, report = LearnAPI.predict_joint(model, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\ntypeof(output) <: T\n\nSee also LearnAPI.predict_joint_input_type.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.transform_input_scitype","page":"Model Traits","title":"LearnAPI.transform_input_scitype","text":" LearnAPI.transform_input_scitype(model)\n\nReturn an upper bound on the scitype of input data guaranteed to work with the transform  operation.\n\nSpecifically, if S is the value returned and ScientificTypes.scitype(data) <: S,  then the following low-level calls are allowed\n\n data2 = LearnAPI.reformat(model, LearnAPI.transform, data...)\n LearnAPI.transform(model, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to  LearnAPI.fit.\n\nSee also LearnAPI.transform_input_type.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be  overloaded if LearnAPI.transform_input_type is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.transform_output_scitype","page":"Model Traits","title":"LearnAPI.transform_output_scitype","text":"LearnAPI.transform_output_scitype(model)\n\nReturn an upper bound on the scitype of the output of the transform operation.\n\nSpecifically, if S is the value returned, and if\n\noutput, report = LearnAPI.transform(model, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\nScientificTypes.scitype(output) <: S\n\nSee also LearnAPI.transform_input_scitype.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.transform_input_type","page":"Model Traits","title":"LearnAPI.transform_input_type","text":"LearnAPI.transform_input_type(model)\n\nReturn an upper bound on the type of input data guaranteed to work with the transform operation.\n\nSpecifically, if T is the value returned and typeof(data) <: S, then the following low-level calls are allowed\n\ndata2 = LearnAPI.reformat(model, LearnAPI.transform, data...)\nLearnAPI.transform(model, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to LearnAPI.fit.\n\nSee also LearnAPI.transform_input_scitype.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be overloaded if LearnAPI.transform_input_scitype is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.transform_output_type","page":"Model Traits","title":"LearnAPI.transform_output_type","text":"LearnAPI.transform_output_type(model)\n\nReturn an upper bound on the type of the output of the transform operation.\n\nSpecifically, if T is the value returned, and if\n\noutput, report = LearnAPI.transform(model, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\ntypeof(output) <: T\n\nSee also LearnAPI.transform_input_type.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.inverse_transform_input_scitype","page":"Model Traits","title":"LearnAPI.inverse_transform_input_scitype","text":" LearnAPI.inverse_transform_input_scitype(model)\n\nReturn an upper bound on the scitype of input data guaranteed to work with the inverse_transform  operation.\n\nSpecifically, if S is the value returned and ScientificTypes.scitype(data) <: S,  then the following low-level calls are allowed\n\n data2 = LearnAPI.reformat(model, LearnAPI.inverse_transform, data...)\n LearnAPI.inverse_transform(model, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to  LearnAPI.fit.\n\nSee also LearnAPI.inverse_transform_input_type.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be  overloaded if LearnAPI.inverse_transform_input_type is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.inverse_transform_output_scitype","page":"Model Traits","title":"LearnAPI.inverse_transform_output_scitype","text":"LearnAPI.inverse_transform_output_scitype(model)\n\nReturn an upper bound on the scitype of the output of the inverse_transform operation.\n\nSpecifically, if S is the value returned, and if\n\noutput, report = LearnAPI.inverse_transform(model, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\nScientificTypes.scitype(output) <: S\n\nSee also LearnAPI.inverse_transform_input_scitype.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.inverse_transform_input_type","page":"Model Traits","title":"LearnAPI.inverse_transform_input_type","text":"LearnAPI.inverse_transform_input_type(model)\n\nReturn an upper bound on the type of input data guaranteed to work with the inverse_transform operation.\n\nSpecifically, if T is the value returned and typeof(data) <: S, then the following low-level calls are allowed\n\ndata2 = LearnAPI.reformat(model, LearnAPI.inverse_transform, data...)\nLearnAPI.inverse_transform(model, fitted_params, data2...)\n\nHere fitted_params are the learned parameters returned by an appropriate call to LearnAPI.fit.\n\nSee also LearnAPI.inverse_transform_input_scitype.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Union{}. Should not be overloaded if LearnAPI.inverse_transform_input_scitype is overloaded.\n\n\n\n\n\n","category":"function"},{"location":"model_traits/#LearnAPI.inverse_transform_output_type","page":"Model Traits","title":"LearnAPI.inverse_transform_output_type","text":"LearnAPI.inverse_transform_output_type(model)\n\nReturn an upper bound on the type of the output of the inverse_transform operation.\n\nSpecifically, if T is the value returned, and if\n\noutput, report = LearnAPI.inverse_transform(model, fitted_params, data...)\n\nfor suitable fitted_params and data, then\n\ntypeof(output) <: T\n\nSee also LearnAPI.inverse_transform_input_type.\n\nNew model implementations\n\nImplementation is optional. The fallback return value is Any.\n\n\n\n\n\n","category":"function"},{"location":"patterns/classifiers/#Classifiers","page":"Classifiers","title":"Classifiers","text":"","category":"section"},{"location":"common_implementation_patterns/#Common-Implementation-Patterns","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"","category":"section"},{"location":"common_implementation_patterns/","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"warning: Warning\nThis section is only an implementation guide. The definitive specification of the Learn API is given in Reference.","category":"page"},{"location":"common_implementation_patterns/","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"This guide is intended to be consulted after reading Anatomy of an Implementation, which introduces the main interface objects and terminology.","category":"page"},{"location":"common_implementation_patterns/","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"Although an implementation is defined purely by the methods and traits it implements, most implementations fall into one (or more) of the following informally understood patterns or \"tasks\":","category":"page"},{"location":"common_implementation_patterns/","page":"Common Implementation Patterns","title":"Common Implementation Patterns","text":"Classifiers: Supervised learners for categorical targets\nRegressors: Supervised learners for continuous targets\nIterative Models\nIncremental Models\nStatic Transformers: Transformations that do not learn but which have hyper-parameters and/or deliver ancillary information about the transformation\nDimension Reduction: Transformers that learn to reduce feature space dimension\nMissing Value Imputation: Transformers that replace missing values.\nClusterering: Algorithms that group data into clusters for classification and possibly dimension reduction. May be true learners (generalize to new data) or static.\nOutlier Detection: Supervised, unsupervised, or semi-supervised learners for anomaly detection.\nLearning a Probability Distribution: Models that fit a distribution or distribution-like object to data\nTime Series Forecasting\nTime Series Classification\nSupervised Bayesian Models\nSurvival Analysis","category":"page"},{"location":"patterns/static_transformers/#Static-Transformers","page":"Static Transformers","title":"Static Transformers","text":"","category":"section"},{"location":"patterns/supervised_bayesian_models/#Supervised-Bayesian-Models","page":"Supervised Bayesian Models","title":"Supervised Bayesian Models","text":"","category":"section"},{"location":"patterns/regressors/#Regressors","page":"Regressors","title":"Regressors","text":"","category":"section"},{"location":"testing_an_implementation/#Testing-an-Implementation","page":"Testing an Implementation","title":"Testing an Implementation","text":"","category":"section"},{"location":"patterns/time_series_classification/#Time-Series-Classification","page":"Time Series Classification","title":"Time Series Classification","text":"","category":"section"},{"location":"anatomy_of_an_implementation/#Anatomy-of-an-Implementation","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Summary. A model is just a container for hyper-parameters. A basic implementation of the ridge regressor requires implementing fit and predict methods dispatched on the model type; predict is an example of an operation (another is transform). In this example we also implement an accessor function, called feature_importance, returning the absolute values of the linear coefficients. The ridge regressor has a target variable and predict makes literal predictions of the target (rather than, say, probabilistic predictions); this behavior is flagged by the predict_proxy model trait.  Other traits articulate the model's training data type requirements and the input/output type of predict.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"We begin by describing an implementation of LearnAPI.jl for basic ridge regression (no intercept) to introduce the main actors in any implementation.","category":"page"},{"location":"anatomy_of_an_implementation/#Defining-a-model-type","page":"Anatomy of an Implementation","title":"Defining a model type","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The first line below imports the lightweight package LearnAPI.jl whose methods we will be extending, the second, libraries needed for the core algorithm.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"using LearnAPI\nusing LinearAlgebra, Tables\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Next, we define a struct to store the single hyper-parameter lambda of this model:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"struct MyRidge <: LearnAPI.Model\n        lambda::Float64\nend\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The subtyping MyRidge <: LearnAPI.Model is optional but recommended where it is not otherwise disruptive.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Instances of MyRidge are called models and MyRidge is a model type.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"A keyword argument constructor providing defaults for all hyper-parameters should be provided:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"nothing # hide\nMyRidge(; lambda=0.1) = MyRidge(lambda)\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/#A-method-to-fit-the-model","page":"Anatomy of an Implementation","title":"A method to fit the model","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"A ridge regressor requires two types of data for training: input features X and a target y. Training is implemented by overloading fit. Here verbosity is an integer (0 should train silently, unless warnings are needed):","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"function LearnAPI.fit(model::MyRidge, verbosity, X, y)\n\n        # process input:\n        x = Tables.matrix(X)  # convert table to matrix\n        s = Tables.schema(X)\n        features = s.names\n\n        # core solver:\n        coefficients = (x'x + model.lambda*I)\\(x'y)\n\n        # prepare output - learned parameters:\n        fitted_params = (; coefficients)\n\n        # prepare output - model state:\n        state = nothing  # not relevant here\n\n        # prepare output - byproducts of training:\n        feature_importances =\n                [features[j] => abs(coefficients[j]) for j in eachindex(features)]\n        sort!(feature_importances, by=last) |> reverse!\n        verbosity > 0 && @info \"Features in order of importance: $(first.(feature_importances))\"\n        report = (; feature_importances)\n\n        return fitted_params, state, report\nend\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Regarding the return value of fit:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The fitted_params variable is for the model's learned parameters, for passing to predict (see below).\nThe state variable is only relevant when additionally implementing a LearnAPI.update! or LearnAPI.ingest! method (see Fit, update! and ingest!).\nThe report is for other byproducts of training, apart from the learned parameters (the ones we'll need to provide predict below).","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Our fit method assumes that X is a table (satisfies the Tables.jl spec) whose rows are the observations; and it will need need y to be an AbstractFloat vector. A model implementation is free to dictate the representation of data that fit accepts but articulates its requirements using appropriate traits; see Training data types below. We recommend against data type checks internal to fit; this would ordinarily be the responsibility of a higher level API, using those traits. ","category":"page"},{"location":"anatomy_of_an_implementation/#Operations","page":"Anatomy of an Implementation","title":"Operations","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Now we need a method for predicting the target on new input features:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"function LearnAPI.predict(::MyRidge, fitted_params, Xnew)\n    Xmatrix = Tables.matrix(Xnew)\n    report = nothing\n    return Xmatrix*fitted_params.coefficients, report\nend\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"In some models predict computes something of interest in addition to the target prediction, and this report item is returned as the second component of the return value. When there's nothing to report, we must return nothing, as here.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Our predict method is an example of an operation. Other operations include transform and inverse_transform and a model can implement more than one. For example, a K-means clustering model might implement a transform for dimension reduction, and a predict to return cluster labels.","category":"page"},{"location":"anatomy_of_an_implementation/#Accessor-functions","page":"Anatomy of an Implementation","title":"Accessor functions","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"The arguments of an operation are always (model, fitted_params, data...). The interface also provides accessor functions for extracting information, from the fitted_params and/or fit report, that is shared by several model types.  There is one for feature importances that we can implement for MyRidge:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"LearnAPI.feature_importances(::MyRidge, fitted_params, report) =\n    report.feature_importances\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Another example of an accessor function is LearnAPI.training_losses.","category":"page"},{"location":"anatomy_of_an_implementation/#traits","page":"Anatomy of an Implementation","title":"Model traits","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Our model has a target variable, in the sense outlined in Scope and undefined notions, and predict returns an object with exactly the same form as the target. We indicate this behavior by declaring","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"LearnAPI.predict_proxy(::Type{<:MyRidge}) = LearnAPI.TrueTarget()\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Or, you can use the shorthand","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge predict_proxy=LearnAPI.TrueTarget()\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"More generally, predict only returns a proxy for the target, such as probability distributions, and we would make a different declaration here. See Target proxies for details.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"LearnAPI.predict_proxy is an example of a model trait. A complete list of traits and the contracts they imply is given in Model Traits.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"We also need to indicate that a target variable appears in training (this is a supervised model). We do this by declaring where in the list of training data arguments (in this case (X, y)) the target variable (in this case y) appears:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge position_of_target=2\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"As explained in the introduction, LearnAPI.jl does not attempt to define strict model \"types\", such as \"regressor\" or \"clusterer\". However, we can optionally specify suggestive descriptors, as in","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge descriptors=(:regression,)\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"but note that this declaration promises nothing. Do LearnAPI.descriptors() to get a list of available descriptors.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Finally, we are required to declare what methods (excluding traits) we have explicitly overloaded for our type:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge methods=(\n        :fit,\n        :predict,\n        :feature_importances,\n)\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/#Training-data-types","page":"Anatomy of an Implementation","title":"Training data types","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Since LearnAPI.jl is a basement level API, one is discouraged from including explicit type checks in an implementation of fit. Instead one uses traits to make promises about the acceptable type of data consumed by fit. In general, this can be a promise regarding the ordinary type of data or the scientific type of data (but not both). Alternatively, one may only make a promise about the type/scitype of observations in the data . See Model Traits for further details. In this case we'll be happy to restrict the scitype of the data:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"import ScientificTypesBase: scitype, Table, Continuous\n@trait MyRidge fit_scitype = Tuple{Table(Continuous), AbstractVector{Continuous}}\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"This is a contract that data is acceptable in the call fit(model, verbosity, data...) whenever","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"scitype(data) <: Tuple{Table(Continuous), AbstractVector{Continuous}}","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Or, in other words:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"X in fit(model, verbosity, X, y) is acceptable, provided scitype(X) <: Table(Continuous) - meaning that X Tables.istable(X) == true (see Tables.jl) and each column has some <:AbstractFloat element type.\ny in fit(model, verbosity, X, y) is acceptable if scitype(y) <: AbstractVector{Continuous} - meaning that it is an abstract vector with <:AbstractFloat elements.","category":"page"},{"location":"anatomy_of_an_implementation/#Input-types-for-operations","page":"Anatomy of an Implementation","title":"Input types for operations","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"An optional promise about what data is guaranteed to work in a call like predict(model, fitted_params, data...) is articulated this way:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@trait MyRidge predict_input_scitype = Tuple{AbstractVector{<:Continuous}}","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Note that data is always a Tuple, even if it has only one component (the typical case), which explains the Tuple on the right-hand side.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Optionally, we may express our promise using regular types, using the LearnAPI.predict_input_type trait.","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"One can optionally make promises about the outut of an operation. See Model Traits for details.","category":"page"},{"location":"anatomy_of_an_implementation/#workflow","page":"Anatomy of an Implementation","title":"Illustrative fit/predict workflow","text":"","category":"section"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Here's some toy data for supervised learning:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"using Tables\n\nn = 10          # number of training observations\ntrain = 1:6\ntest = 7:10\n\na, b, c = rand(n), rand(n), rand(n)\nX = (; a, b, c) |> Tables.rowtable\ny = 2a - b + 3c + 0.05*rand(n)\nnothing # hide","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Instantiate a model with relevant hyperparameters (which is all the object stores):","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"model = MyRidge(lambda=0.5)","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Train the model (the 0 means do so silently):","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"import LearnAPI: fit, predict, feature_importances\n\nfitted_params, state, fit_report = fit(model, 0, X[train], y[train])","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Inspect the learned parameters and report:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"@info \"training outcomes\" fitted_params fit_report","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Inspect feature importances:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"feature_importances(model, fitted_params, fit_report)","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Make a prediction using new data:","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"yhat, predict_report = predict(model, fitted_params, X[test])","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"Compare predictions with ground truth","category":"page"},{"location":"anatomy_of_an_implementation/","page":"Anatomy of an Implementation","title":"Anatomy of an Implementation","text":"deviations = yhat - y[test]\nloss = deviations .^2 |> sum\n@info \"Sum of squares loss\" loss","category":"page"},{"location":"patterns/clusterering/#Clusterering","page":"Clusterering","title":"Clusterering","text":"","category":"section"},{"location":"patterns/iterative_models/#Iterative-Models","page":"Iterative Models","title":"Iterative Models","text":"","category":"section"},{"location":"reference/#reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Summary In LearnAPI.jl a model is a container for hyper-parameters of some learning algorithm. Functionality is created by overloading methods provided by the interface, which are divided into training methods (e.g., fit), operations (e.g.,. predict and transform) and accessor functions (e.g., feature_importances). Promises of particular behavior are articulated by model traits.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Here we give the definitive specification of the interface provided by LearnAPI.jl. For a more informal guide see  Anatomy of an Implementation and Common Implementation Patterns.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"The reader is assumed to be familiar with the LearnAPI-specific meanings of the following terms, as outlined in Scope and undefined notions: data, metadata, hyperparameter, observation, and target.","category":"page"},{"location":"reference/#Models","page":"Reference","title":"Models","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"In this document the word \"model\" has a very specific meaning that may differ from the reader's common understanding of the word - in statistics, for example.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Here a model is some julia object storing the hyper-parameters of some learning algorithm. Typically the type of m will have a name reflecting that of the algorithm, such as DecisionTreeRegressor.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Additionally, for m::M to be a LearnAPI model, we require:","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Base.propertynames(m) returns the hyper-parameters of m.\nIf m is a model, then so are all instances of the same type.\nIf n is another model, then m == n if and only if typeof(n) == typeof(m) and corresponding properties are ==. This includes properties that are random number generators (which should be copied in training to avoid mutation).\nIf a model has other models as hyper-parameters, then LearnAPI.is_wrapper(m) must be true.\nA keyword constructor for M exists, providing default values for all non-model hyper-parameters.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Whenever any LearnAPI method (excluding traits) is overloaded for some type M (e.g., predict, transform, fit) then that is a promise that all instances of M are models. (In particular, LearnAPI.functions(M) will be non-empty in this case.)","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"It is supposed that making copies of model objects is a cheap operation. Consequently, learned parameters, such as weights in a neural network (the fitted_params described in Fit, update! and ingest!) are not expected to be part of a model. Storing learned parameters in a model is not explicitly ruled out, but doing so might lead to performance issues in packages adopting LearnAPI.jl.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"A model type is a type whose instances are models.","category":"page"},{"location":"reference/#Example","page":"Reference","title":"Example","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Any instance of GradientRidgeRegressor defined below is a valid LearnAPI.jl model:","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"struct GradientRidgeRegressor{T<:Real} <: LearnAPI.Model\n    learning_rate::T\n    epochs::Int\n    l2_regularization::T\nend","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"The same is true if we omit the subtyping <: LearnAPI.Model, but not if we also make this a mutable struct. In that case we will need to overload Base.== for GradientRidgeRegressor.","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"LearnAPI.Model","category":"page"},{"location":"reference/#LearnAPI.Model","page":"Reference","title":"LearnAPI.Model","text":"LearnAPI.Model\n\nAn optional abstract type for models implementing LearnAPI.jl.\n\nIf typeof(m) <: LearnAPI.Model, then m is guaranteed to be a model in the LearnAPI sense.\n\nNew model implementations\n\nWhile not a formal requirement, model types implementing the LearnAPI interface are encouraged to subtype LearnAPI.Model, unless it is disruptive to do so.\n\nSee also LearnAPI.functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Methods","page":"Reference","title":"Methods","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"None of the methods described in the linked sections below are compulsory, but any implemented or overloaded method that is not a model trait must be added to the return value of LearnAPI.functions, as in","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"LearnAPI.functions(::Type{<SomeModelType}) = (:fit, :update!, :predict)","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"or using the shorthand","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"@trait SomeModelType functions=(:fit, :update!, :predict)","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Fit, update! and ingest! (training methods): for models that \"learn\" (generalize to new data)\nOperations: predict, transform and their relatives\nAccessor Functions: accessing certain byproducts of training that many models share, such as feature importances and training losses\nOptional Data Interface\nModel Traits: contracts for specific behavior, such as \"The second data argument of fit is a target variable\" or \"I predict probability distributions\"","category":"page"},{"location":"operations/#operations","page":"Predict and other operations","title":"Predict and Other Operations","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Summary Methods like predict and transform, that generally depend on learned parameters, are called operations. All implemented operations must be included in the output of the functions model trait. When an operation returns a target proxy, it must make a target_proxies trait declaration.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"An operation is any method with signature some_operation(model, fitted_params, data...). Here fitted_params is the learned parameters object, as returned by LearnAPI.fit(model, ...), which will be nothing if fit is not implemented (true for models that do not generalize to new data). For example, LearnAPI.predict in the following code snippet is an operation:","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"fitted_params, state, fit_report = LearnAPI.fit(some_model, 1, X, y)\nyÌ‚, predict_report = LearnAPI.predict(some_model, fitted_params, Xnew)","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"LearnAPI.jl only provides these operations:","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"method compulsory? fallback requires\nLearnAPI.predict no none \nLearnAPI.predict_joint no none \nLearnAPI.transform no none \nLearnAPI.inverse_transform no none transform","category":"page"},{"location":"operations/#General-requirements","page":"Predict and other operations","title":"General requirements","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Operations always return a tuple (output, report) where output is the usual output (e.g., the target predictions if the operation is predict) and report includes byproducts of the computation, typically nothing unless the model does not generalize to new data (does not implement fit). \nOnly implement predict_joint for outputting a single multivariate probability distribution for multiple input observations, as described further at LearnAPI.predict_joint.\nThe name of each operation explicitly overloaded must be included in the return value of the LearnAPI.functions trait.","category":"page"},{"location":"operations/#Predict-or-transform?","page":"Predict and other operations","title":"Predict or transform?","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"If the model has a target, as defined under Scope and undefined notions, then only predict or predict_joint can be used to compute a corresponding target proxy.\nIf an operation is to have an inverse operation, then it cannot be predict - use transform and inverse_transform.\nIf only a single operation is implemented, and there is no target variable, use transform.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Here an \"inverse\" of transform is very broadly understood as any operation that can be applied to the output of transform to obtain an object of the same form as the input of transform; for example this includes one-sided inverses, and approximate one-sided inverses. ","category":"page"},{"location":"operations/#Target-proxies","page":"Predict and other operations","title":"Target proxies","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"In the case that a model has the concept of a target variable, as described under Scope and undefined notions, the output of predict may have the form of a proxy for the target, such as a vector of truth-probabilities for binary targets.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"We assume the reader is already familiar with the notion of a target variable in supervised learning, but target variables are not limited to supervised models. For example, we may regard the \"outlier\"/\"inlier\" assignments in unsupervised anomaly detection as a target. A target proxy in this example would be probabilities for outlierness, as these can be paired with \"outlier\"/\"inlier\" labels assigned by humans, using, say, area under the ROC curve, to quantify performance.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"Similarly, the integer labels assigned to some observations by a clustering algorithm can be regarded as a target variable. The labels obtained can be paired with human labels using, say, the Rand index. ","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"The kind of proxy one has is informally classified by a subtype of the abstract type LearnAPI.TargetProxy. These types are intended for dispatch outside of LearnAPI.jl and have no fields (i.e., only one instance). ","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"In reading the table below, recall that an observation is just anything generated by iterating over the contents of some data object.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"type form of an observation\nLearnAPI.None has no declared relationship with a target variable\nLearnAPI.TrueTarget same as target observations (possible requirement: observations have same type as target observations)\nLearnAPI.Sampleable object that can be sampled to obtain object of the same form as target observation (possible requirement: observation implements Base.rand)\nLearnAPI.Distribution explicit probability density/mass function whose sample space is all possible target observations (possible requirement: observation implements Distributions.pdf and Base.rand)\nLearnAPI.LogDistribution explicit log-probability density/mass function whose sample space is possible target observations (possible requirement: observation implements Distributions.logpdf and Base.rand)\nâ€  LearnAPI.Probability raw numerical probability or probability vector\nâ€  LearnAPI.LogProbability log-probability or log-probability vector\nâ€  LearnAPI.Parametric a list of parameters (e.g., mean and variance) describing some distribution\nLearnAPI.LabelAmbiguous collections of labels (in case of multi-class target) but without a known correspondence to the original target labels (and of possibly different number) as in, e.g., clustering\nLearnAPI.LabelAmbiguousSampleable sampleable version of LabelAmbiguous; see Sampleable above\nLearnAPI.LabelAmbiguousDistribution pdf/pmf version of LabelAmbiguous; see Distribution  above\nLearnAPI.ConfidenceInterval confidence interval (possible requirement:  observation isa Tuple{Real,Real})\nLearnAPI.Set finite but possibly varying number of target observations (possible requirement: observation isa Set{target_observation_type})\nLearnAPI.ProbabilisticSet as for Set but labeled with probabilities (not necessarily summing to one)\nLearnAPI.SurvivalFunction survival function (possible requirement: observation is single-argument function mapping Real to Real)\nLearnAPI.SurvivalDistribution probability distribution for survival time (possible requirement: observation have type Distributions.ContinuousUnivariateDistribution)","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"â€  Provided for completeness but discouraged to avoid ambiguities in representation.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"warning: Warning\nThe \"possible requirement\"s listed are not part of LearnAPI.jl.","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"When predict outputs a target proxy, there must be LearnAPI.predict_proxy declaration, as in","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"LearnAPI.predict_proxy(::Type{<:SomeModel}) = LearnAPI.Distribution()","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"which has the short form","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"LearnAPI.@trait predict_proxy = (predict=LearnAPI.Distribution(),)","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"If predict_joint is implemented, then an analogous LearnAPI.predict_joint_proxy declaration is required. The output of predict_joint is not a number of observations but a single object, and the trait value must be an instance of one of the following types:","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"type form of output of predict_joint(model, fitted_params, data...)\nLearnAPI.JointSampleable object that can be sampled to obtain a vector whose elements have the form of target observations; the vector length matches the number of observations in data.\nLearnAPI.JointDistribution explicit probability density/mass function whose sample space is vectors of target observations;  the vector length matches the number of observations in data\nLearnAPI.JointLogDistribution explicit log-probability density/mass function whose sample space is vectors of target observations;  the vector length matches the number of observations in data","category":"page"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"See more at LearnAPI.predict_joint below.","category":"page"},{"location":"operations/#Reference","page":"Predict and other operations","title":"Reference","text":"","category":"section"},{"location":"operations/","page":"Predict and other operations","title":"Predict and other operations","text":"LearnAPI.predict\nLearnAPI.predict_joint\nLearnAPI.transform\nLearnAPI.inverse_transform","category":"page"},{"location":"operations/#LearnAPI.predict","page":"Predict and other operations","title":"LearnAPI.predict","text":"LearnAPI.predict(model, fitted_params, data...)\n\nReturn (yÌ‚, report) where yÌ‚ are the predictions, or prediction-like output (such as probabilities), for a machine learning model model, with learned parameters fitted_params (first object returned by LearnAPI.fit(model, ...)). The report contains ancilliary byproducts of the computation, or is nothing; data is a tuple of data objects, generally a single object representing new observations not seen in training. \n\nNew model implementations\n\nIf implemented, you must include :predict in the tuple returned by the LearnAPI.functions trait. \n\nIf predict is computing a target proxy, as defined in the LearnAPI documentation, then a LearnAPI.predict_proxy declaration is required, as in\n\nLearnAPI.predict_proxy(::Type{<:SomeModel}) = LearnAPI.Distribution()\n\nwhich has the shorthand\n\n@trait SomeModel predict_proxy=LearnAPI.Distribution()\n\nThe value of this trait must be an instance T(), where T <: LearnAPI.TargetProxy.\n\nSee also LearnAPI.fit.\n\n\n\n\n\n","category":"function"},{"location":"operations/#LearnAPI.predict_joint","page":"Predict and other operations","title":"LearnAPI.predict_joint","text":"LearnAPI.predict_joint(model, fitted_params, data...)\n\nFor a supervised learning model, return (d, report), where d is some representation of the single probability distribution for the sample space Y^n. Here Y is the space in which the target variable associated with model takes its values, and n is the number of observations in data. The specific form of the representation is given by LearnAPI.predict_joint_proxy(model).\n\nHere fitted_params are the model's learned parameters (the first object returned by LearnAPI.fit). The report contains ancilliary byproducts of the computation, or is nothing; data is a tuple of data objects, generally a single object representing new observations not seen in training. .\n\nWhile the interpretation of this distribution depends on the model, marginalizing component-wise will generally deliver n correlated distributions, and these will generally not agree with those returned by LearnAPI.predict on the same the same n input observations, if also implemented.\n\nNew model implementations\n\nOnly implement this method if model has an associated concept of target variable, as defined in the LearnAPI.jl documentation. A trait declaration for LearnAPI.predict_joint_proxy is required, such as\n\nLearnAPI.predict_joint_proxy(::Type{SomeModel}) = JointSampleable()\n\nwhich has the shorhand\n\n@trait SomeModel predict_joint_proxy=JointSampleable()\n\nThe possible values for this trait are: LearnAPI.JointSampleable(), LearnAPI.JointDistribution, and LearnAPI.JointLogDistribution().\n\nIf implemented, you must include :predict_joint in the tuple returned by the LearnAPI.functions trait. .\n\nSee also LearnAPI.fit, LearnAPI.predict.\n\n\n\n\n\n","category":"function"},{"location":"operations/#LearnAPI.transform","page":"Predict and other operations","title":"LearnAPI.transform","text":"LearnAPI.transform(model, fitted_params, data...)\n\nReturn (output, report), where output is some kind of transformation of data, provided by model, based on the learned parameters fitted_params (the first object returned by LearnAPI.fit(model, ...)). The fitted_params could be nothing, in the case of models that do not generalize to new data. The report contains ancilliary byproducts of the computation, or is nothing; data is a tuple of data objects, generally a single object representing new observations not seen in training. \n\nNew model implementations\n\nIf implemented, you must include :transform in the tuple returned by the LearnAPI.functions trait. \n\nSee also LearnAPI.inverse_transform, LearnAPI.fit, LearnAPI.predict,\n\n\n\n\n\n","category":"function"},{"location":"operations/#LearnAPI.inverse_transform","page":"Predict and other operations","title":"LearnAPI.inverse_transform","text":"LearnAPI.inverse_transform(model, fitted_params, data)\n\nReturn (data_inverted, report), where data_inverted is valid input to the call\n\nLearnAPI.transform(model, fitted_params, data_inverted)\n\nThe report contains ancilliary byproducts of the computation, or is nothing; data is a tuple of data objects, generally a single object representing new observations not seen in training. \n\nTypically, the map\n\ndata -> first(inverse_transform(model, fitted_params, data))\n\nwill be an inverse, approximate inverse, right inverse, or approximate right inverse, for the map\n\ndata -> first(transform(model, fitted_params, data))\n\nFor example, if transform corresponds to a projection, inverse_transform might be the corresponding embedding.\n\nNew model implementations\n\nIf implemented, you must include :transform in the tuple returned by the LearnAPI.functions trait. \n\nSee also LearnAPI.fit, LearnAPI.predict,\n\n\n\n\n\n","category":"function"},{"location":"accessor_functions/#Accessor-Functions","page":"Accessor Functions","title":"Accessor Functions","text":"","category":"section"},{"location":"accessor_functions/","page":"Accessor Functions","title":"Accessor Functions","text":"Summary. While byproducts of training are ordinarily recorded in the report component of the output of fit/update!/ingest!, some families of models report an item that is likely shared by multiple model types, and it is useful to have common interface for accessing these directly. Training losses and feature importances are two examples.","category":"page"},{"location":"accessor_functions/","page":"Accessor Functions","title":"Accessor Functions","text":"LearnAPI.feature_importances\nLearnAPI.training_losses\nLearnAPI.training_scores\nLearnAPI.training_labels","category":"page"},{"location":"accessor_functions/#LearnAPI.feature_importances","page":"Accessor Functions","title":"LearnAPI.feature_importances","text":"LearnAPI.feature_importances(model, fitted_params, report)\n\nReturn the model-specific feature importances of model, given fitted_params and report, as returned by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!. The value returned has the form of an abstract vector of feature::Symbol => importance::Real pairs (e.g [:gender => 0.23, :height => 0.7, :weight => 0.1]).\n\nThe model supports feature importances if :feature_importance in LearnAPI.functions(model).\n\nIf for some reason a model is sometimes unable to report feature importances, then feature_importances will return all importances as 0.0, as in [:gender => 0.0, :height => 0.0, :weight => 0.0].\n\nNew model implementations\n\nLearnAPI.feature_importances(model::SomeModelType, fitted_params, report) may be overloaded for any type SomeModelType whose instances are models in the LearnAPI sense. If a model can report multiple feature importance types, then the specific type to be reported should be controlled by a hyperparameter (i.e., by some property of model).\n\nIf implemented, you must include :feature_importances in the tuple returned by the LearnAPI.functions trait. .\n\n\n\n\n\n","category":"function"},{"location":"accessor_functions/#LearnAPI.training_losses","page":"Accessor Functions","title":"LearnAPI.training_losses","text":"training_losses(model, fitted_params, report)\n\nReturn the training losses for model, given fitted_params and report, as returned by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!.\n\nNew model implementations\n\nImplement for iterative models that compute and record training losses as part of training (e.g. neural networks).\n\nIf implemented, you must include :training_losses in the tuple returned by the LearnAPI.functions trait. .\n\n\n\n\n\n","category":"function"},{"location":"accessor_functions/#LearnAPI.training_scores","page":"Accessor Functions","title":"LearnAPI.training_scores","text":"training_scores(model, fitted_params, report)\n\nReturn the training scores for model, given fitted_params and report, as returned by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!.\n\nNew model implementations\n\nImplement for models, such as outlier detection models, which associate a score with each observation during training, where these scores are of interest in later processes (e.g, in defining normalized scores on new data).\n\nIf implemented, you must include :training_scores in the tuple returned by the LearnAPI.functions trait. .\n\n\n\n\n\n","category":"function"},{"location":"accessor_functions/#LearnAPI.training_labels","page":"Accessor Functions","title":"LearnAPI.training_labels","text":"training_labels(model, fitted_params, report)\n\nReturn the training labels for model, given fitted_params and report, as returned by LearnAPI.fit, LearnAPI.update! or LearnAPI.ingest!.\n\nNew model implementations\n\nIf implemented, you must include :training_labels in the tuple returned by the LearnAPI.functions trait. .\n\n\n\n\n\n","category":"function"},{"location":"patterns/incremental_models/#Incremental-Models","page":"Incremental Models","title":"Incremental Models","text":"","category":"section"},{"location":"patterns/learning_a_probability_distribution/#Learning-a-Probability-Distribution","page":"Learning a Probability Distribution","title":"Learning a Probability Distribution","text":"","category":"section"},{"location":"patterns/dimension_reduction/#Dimension-Reduction","page":"Dimension Reduction","title":"Dimension Reduction","text":"","category":"section"},{"location":"patterns/time_series_forecasting/#Time-Series-Forecasting","page":"Time Series Forecasting","title":"Time Series Forecasting","text":"","category":"section"},{"location":"fit_update_and_ingest/#Fit,-update!-and-ingest!","page":"Fit, update and ingest","title":"Fit, update! and ingest!","text":"","category":"section"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"Summary. Models that learn, i.e., generalize to new data, must overload fit; the fallback performs no operation and returns all nothing. Implement update! if certain hyper-parameter changes do not necessitate retraining from scratch (e.g., increasing an iteration parameter). Implement ingest! to implement incremental learning. All training methods implemented must be named in the return value of the functions trait.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"method fallback compulsory? requires\nLearnAPI.fit does nothing, returns (nothing, nothing, nothing) no \nLearnAPI.update! calls fit no LearnAPI.fit\nLearnAPI.ingest! none no LearnAPI.fit","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"All three methods above return a triple (fitted_params, state, report) whose components are explained under LearnAPI.fit below.  Items that might be returned in report include: feature rankings/importances, SVM support vectors, clustering centers, methods for visualizing training outcomes, methods for saving learned parameters in a custom format, degrees of freedom, deviances. Precisely what report includes might be controlled by model hyperparameters, especially if there is a performance cost to it's inclusion.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"Implement fit unless all operations, such as predict and transform, ignore their fitted_params argument (which will be nothing). This is the case for many models that have hyperparameters, but do not generalize to new data, such as a basic DBSCAN clustering algorithm.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"The update! method is intended for all subsequent calls to train a model using the same observations, but with possibly altered hyperparameters (model argument). A fallback implementation simply calls fit. The main use cases for implementing update are: ","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"warm-restarting iterative models\n\"smart\" training of composite models, such as linear pipelines; here \"smart\" means that hyperparameter changes only trigger the retraining of downstream components.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"The ingest! method supports incremental learning (same hyperparameters, but new training observations). Like update!, it depends on the output a preceding fit or ingest! call.","category":"page"},{"location":"fit_update_and_ingest/","page":"Fit, update and ingest","title":"Fit, update and ingest","text":"LearnAPI.fit\nLearnAPI.update!\nLearnAPI.ingest!","category":"page"},{"location":"fit_update_and_ingest/#LearnAPI.fit","page":"Fit, update and ingest","title":"LearnAPI.fit","text":"LearnAPI.fit(model, verbosity, data...; metadata...)\n\nFit model to the provided data and metadata. With the exception of warnings, training will be silent if verbosity == 0. Lower values should suppress warnings; any integer ought to be admissible. Here:\n\nmodel is a property-accessible object whose properties are the hyper-parameters of  some machine learning algorithm.\ndata is a tuple of data objects with a common number of observations, for example, data = (X, y, w) where X is a table of features, y is a target vector with the same number of rows, and w a vector of per-observation weights.\nmetadata is for extra information pertaining to the data that is never iterated or subsampled, eg., weights for target classes, or feature names (if these are not embedded in the representation of data). Another example would be feature groupings in the group lasso algorithm.  To see the keyword names for metadata supported by model, do LearnAPI.fit_keywords(model). \"\n\nReturn value\n\nReturns a tuple (fitted_params, state, report) where:\n\nThe fitted_params is the model's learned parameters (eg, the coefficients in a linear model) in a form understood by model operations. An operation is a method, like LearnAPI.predict or LearnAPI.transform, that has signature (model, fitted_params, data....); do LearnAPI.OPERATIONS to list. If some training outcome of user-interest is not needed for operations, it should be part of report instead (see below).\nThe state is for passing to LearnAPI.update! or LearnAPI.ingest!. For models that implement neither, state should be nothing.\nThe report records byproducts of training not in the fitted_params, such as feature rankings, or out-of-sample estimates of performance.\n\nNew model implementations\n\nOverloading this method for new models is optional.  A fallback performs no computation, returning (nothing, nothing, nothing).\n\nSee the LearnAPI.jl documentation for the detailed requirements of LearnAPI.jl model objects.\n\nNote that in LearnAPI.jl the word \"data\" is only defined informally, as an object generating \"observations\", which are not defined at all.\n\nnote: Note\nThe method is not permitted to mutate model. In particular, if model has a random number generator as a hyperparameter (property) then it must be copied before use.  \n\nIf implemented, you must include :fit in the tuple returned by the LearnAPI.functions trait. \n\nIf supporting metadata, you must also implement LearnAPI.fit_keywords to list the supported keyword argument names (e.g., class_weights).\n\nSee also LearnAPI.update!, LearnAPI.ingest!.\n\n\n\n\n\n","category":"function"},{"location":"fit_update_and_ingest/#LearnAPI.update!","page":"Fit, update and ingest","title":"LearnAPI.update!","text":"LearnAPI.update!(model, verbosity, fitted_params, state, data...; metadata...)\n\nBased on the values of state, and fitted_params returned by a preceding call to LearnAPI.fit, LearnAPI.ingest!, or LearnAPI.update!, update a model's fitted parameters, returning new (or mutated) state and fitted_params.\n\nIntended for retraining a model when the training data has not changed, but model properties (hyperparameters) may have changed, e.g., when increasing an iteration parameter. Specifically, the assumption is that data and metadata have the same values seen in the most recent call to fit/update!/ingest! (and will typically be ignored).\n\nFor incremental training (same model, new data) see instead LearnAPI.ingest!.\n\nReturn value\n\nSame as LearnAPI.fit, namely a tuple (fitted_params, state, report). See LearnAPI.fit for details.\n\nNew model implementations\n\nOverloading this method is optional. A fallback calls LearnAPIperforms.fit:\n\nLearnAPI.update!(model, verbosity, fitted_params, state, data...; metadata...) =\n    fit(model, verbosity, data; metadata...)\n\nIf implemented, you must include :fit in the tuple returned by the LearnAPI.functions trait. \n\nNote that in LearnAPI.jl the word \"data\" is only defined informally, as an object generating \"observations\", which are not defined at all.\n\nThe most common use case is for continuing the training of an iterative model: state is simply a copy of the model used in the last training call (fit, update! or ingest!) and this will include the current number of iterations as a property. If model and state differ only in the number of iterations (e.g., epochs in a neural network), which has increased, then the fitted parameters (weights) are updated, rather than computed from scratch. Otherwise, update! simply calls fit, to force retraining from scratch.\n\nIt is permitted to return mutated versions of state and fitted_params.\n\nnote: Note\nThe method is not permitted to mutate model. In particular, if model has a random number generator as a hyperparameter (property) then it must be copied before use.  \n\nSee also LearnAPI.fit, LearnAPI.ingest!.\n\n\n\n\n\n","category":"function"},{"location":"fit_update_and_ingest/#LearnAPI.ingest!","page":"Fit, update and ingest","title":"LearnAPI.ingest!","text":"LernAPI.ingest!(model, verbosity, fitted_params, state, data...; metadata...)\n\nFor a model that supports incremental learning, update the fitted parameters using data, which has typically not been seen before.  The arguments state and fitted_params are the output of a preceding call to LearnAPI.fit, LearnAPI.ingest!, or LearnAPI.update!, of which mutated or new versions are returned.\n\nFor updating fitted parameters using the same data but new hyperparameters, see instead LearnAPI.update!.\n\nFor training a model with new hyperparameters bue unchanged data, see instead LearnAPI.update!.\n\nReturn value\n\nSame as LearnAPI.fit, namely a tuple (fitted_params, state, report). See LearnAPI.fit for details.\n\nNew model implementations\n\nImplementing this method is optional. It has no fallback.\n\nIf implemented, you must include :fit in the tuple returned by the LearnAPI.functions trait. \n\nnote: Note\nThe method is not permitted to mutate model. In particular, if model has a random number generator as a hyperparameter (property) then it must be copied before use.  \n\nSee also LearnAPI.fit, LearnAPI.update!.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Overview","title":"Overview","text":"<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n<span style=\"color: #9558B2;font-size:4.5em;\">\nLearnAPI.jl</span>\n<br>\n<span style=\"color: #9558B2;font-size:1.6em;font-style:italic;\">\nA basement-level Julia interface for training and applying machine learning models </span>\n<br><br>","category":"page"},{"location":"#Goals","page":"Overview","title":"Goals","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Ease of implementation for existing machine learning algorithms\nApplicability to a large variety of algorithms\nProvision of clear interface points for model-generic tooling, such as performance evaluation through resampling, hyperparameter optimization, and iterative model control.\nShould be data container agnostic\nShould be documented in detail","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"It is not a design goal of LearnAPI.jl to provide a convenient interface for the general user to directly interact with ML models. ","category":"page"},{"location":"#Quick-tours","page":"Overview","title":"Quick tours","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"To see how to INTERACT WITH models implementing LearnAPI: Basic fit/predict workflow.\nFor developers wanting to IMPLEMENT LearnAPI: Anatomy of an Implementation.","category":"page"},{"location":"#Approach","page":"Overview","title":"Approach","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Machine learning algorithms, also called models, have a complicated taxonomy. Grouping models, or modeling tasks, into a relatively small number of types, such as \"classifier\" and \"clusterer\", and attempting to impose uniform behavior within each group, is challenging. In our experience developing the MLJ ecosystem, this either leads to limitations on the models that can be included in a general interface, or additional complexity needed to cope with exceptional cases. Even if a complete user interface for machine learning might benefit from such groupings, a basement-level API for ML should, in our view, avoid them.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"In addition to basic methods, like fit and predict, LearnAPI provides a number of optional model traits, each promising a specific kind of behavior, such as \"The predictions of this model are probability distributions\".  There is no abstract type model hierarchy.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Our preceding remarks notwithstanding, there is, for certain applications involving a \"target\" variable (understood in a rather general way - see below) a clear-cut distinction between models, based on the proxy for the target that is actually output by the model. Probability distributions, confidence intervals and survival functions are examples of Target proxies. LearnAPI provides a trait for distinguishing such models based on the target proxy.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"LearnAPI is a basement-level interface and not a general ML toolbox. Almost no assumptions are made about the data manipulated by LearnAPI models. These models can be supervised or not supervised, can generalize to new data observations, or not generalize.","category":"page"},{"location":"#Methods","page":"Overview","title":"Methods","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"In LearnAPI.jl a model is just a container for the hyper-parameters of some machine learning algorithm, and does not typically include learned parameters.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The following methods, dispatched on model type, are provided:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"fit, for regular training, overloaded if the model generalizes to new data, as in classical supervised learning; the principal output of fit is the learned parameters\nupdate!, for adding model iterations, or responding efficiently to other post-fitchanges in hyperparameters\ningest!, for incremental learning (training further using new data, without re-initializing learned parameters)\noperations, predict, predict_joint, transform and inverse_transform for applying the model to data not used for training\ncommon accessor functions, such as feature_importances and training_losses, for extracting, from training outcomes, information common to some models\nmodel traits, such as predict_output_type(model), for promising specific behavior","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"There is flexibility about how much of the interface is implemented by a given model type. A special trait functions(model) declares what has been explicitly implemented to work with model, excluding traits.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Since this is a functional-style interface, fit returns model state, in addition to learned parameters, for passing to the optional update! and ingest! methods. These training methods also return a report component, for exposing byproducts of training different from learned parameters. Similarly, all operations also return a report component (important for models that do not generalize to new data).","category":"page"},{"location":"#scope","page":"Overview","title":"Scope and undefined notions","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The basic LearnAPI.jl interface provides methods for training and applying machine learning models, and that is all. The interface specification is predicated on a few basic undefined notions (in boldface) which some higher-level interface might decide to formalize:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"An object which generates ordered sequences of individual observations is called data. For example a DataFrame instance, from DataFrames.jl, is considered data, the observations being the rows. A matrix can be considered data, but whether the observations are rows or columns is ambiguous and not fixed by LearnAPI.\nEach machine learning model's behavior is governed by a number of user-specified hyperparameters. The regularization parameter in ridge regression is an example. Hyperparameters are data-independent. For example, the number of target classes is not a hyperparameter.\nInformation needed for training that is not a model hyperparameter and not data is called metadata. Examples, include target class weights and group lasso feature groupings.\nSome models involve the notion of a target variable and generate output with the same form as the target, or, more generally, some kind of target proxy, such as probability distributions. A target proxy is something that can be paired with target data to obtain useful information about the model and the data that has been presented to it, typically a measure of the model's expected performance on unseen data. A target variable is not necessarily encountered during training, i.e., target variables can make sense for unsupervised models, and also for models that do not generalize to new observations.  For examples, and an informal classification of target proxy types, refer to Target proxies.","category":"page"},{"location":"#Optional-data-interface","page":"Overview","title":"Optional data interface","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"It can be useful to distinguish between data that exists at some high level, convenient for the general user - such as a table (dataframe) or the path to a directory containing image files - and a performant, model-specific representation of that data, such as a matrix or image \"data loader\". When retraining using the same data with new hyper-parameters, one wants to avoid recreating the model-specific representation, and, accordingly, a higher level ML interface may want to cache such representations. Furthermore, in resampling (e.g., performing cross-validation), a higher level interface wants only to resample the model-specific representation, so it needs to know how to do that. To meet these two ends, LearnAPI provides two additional data methods dispatched on model type:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"reformat(model, ...), for converting from a user data representation to a performant model-specific representation, whose output is for use in fit, predict, etc. above\ngetobs(model, ...), for extracting a subsample of observations of the model-specific representation","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"It should be emphasized that LearnAPI is itself agnostic to particular representations of data or the particular methods of accessing observations within them. By overloading these methods, each model is free to choose its own data interface.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"See Optional data Interface for more details. ","category":"page"},{"location":"#Contents","page":"Overview","title":"Contents","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"It is useful to have a guide to the interface, linked below, organized around common informally defined patterns or \"tasks\". However, the definitive specification of the interface is the Reference section.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Overview: Anatomy of an Implementation\nOfficial Specification: Reference\nUser guide: Common Implementation Patterns [under construction]\nTesting an Implementation [under construction]","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"info: Info\nIt is recommended users read  Anatomy of an Implementation before consulting the guide or reference sections.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Note. In the future, LearnAPI.jl may become the new foundation for the MLJ toolbox created by the same developers. However, LearnAPI.jl is meant as a general purpose, stand-alone, lightweight, low level API for machine learning algorithms (and has no reference to the \"machines\" used there).","category":"page"},{"location":"patterns/outlier_detection/#Outlier-Detection","page":"Outlier Detection","title":"Outlier Detection","text":"","category":"section"}]
}
