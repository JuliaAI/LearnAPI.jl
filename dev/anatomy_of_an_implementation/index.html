<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Anatomy of an Implementation · LearnAPI.jl</title><meta name="title" content="Anatomy of an Implementation · LearnAPI.jl"/><meta property="og:title" content="Anatomy of an Implementation · LearnAPI.jl"/><meta property="twitter:title" content="Anatomy of an Implementation · LearnAPI.jl"/><meta name="description" content="Documentation for LearnAPI.jl."/><meta property="og:description" content="Documentation for LearnAPI.jl."/><meta property="twitter:description" content="Documentation for LearnAPI.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LearnAPI.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Anatomy of an Implementation</a><ul class="internal"><li><a class="tocitem" href="#A-basic-implementation"><span>A basic implementation</span></a></li><li><a class="tocitem" href="#workflow"><span>Demonstration</span></a></li><li><a class="tocitem" href="#di"><span>Other data patterns</span></a></li><li><a class="tocitem" href="#Providing-a-separate-data-front-end"><span>Providing a separate data front end</span></a></li><li><a class="tocitem" href="#advanced_demo"><span>Demonstration of an advanced <code>obs</code> workflow</span></a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../reference/">Overview</a></li><li><a class="tocitem" href="../list_of_public_names/">Public Names</a></li><li><a class="tocitem" href="../kinds_of_learner/">Kinds of learner</a></li><li><a class="tocitem" href="../fit_update/">fit/update</a></li><li><a class="tocitem" href="../predict_transform/">predict/transform</a></li><li><a class="tocitem" href="../kinds_of_target_proxy/">Kinds of Target Proxy</a></li><li><a class="tocitem" href="../obs/">obs and Data Interfaces</a></li><li><a class="tocitem" href="../features_target_weights/">features/target/weights</a></li><li><a class="tocitem" href="../accessor_functions/">Accessor Functions</a></li><li><a class="tocitem" href="../traits/">Learner Traits</a></li></ul></li><li><a class="tocitem" href="../common_implementation_patterns/">Common Implementation Patterns</a></li><li><a class="tocitem" href="../testing_an_implementation/">Testing an Implementation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Anatomy of an Implementation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Anatomy of an Implementation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaAI/LearnAPI.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaAI/LearnAPI.jl/blob/dev/docs/src/anatomy_of_an_implementation.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Anatomy-of-an-Implementation"><a class="docs-heading-anchor" href="#Anatomy-of-an-Implementation">Anatomy of an Implementation</a><a id="Anatomy-of-an-Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Anatomy-of-an-Implementation" title="Permalink"></a></h1><p>LearnAPI.jl supports three core patterns. The default pattern, known as the <a href="../kinds_of_learner/#LearnAPI.Descriminative"><code>LearnAPI.Descriminative</code></a> pattern, looks like this:</p><pre><code class="language-julia hljs">model = fit(learner, data)
predict(model, newdata)</code></pre><p>Here <code>learner</code> specifies <a href="../reference/#hyperparameters">hyperparameters</a>, while <code>model</code> stores learned parameters and any byproducts of algorithm execution.</p><p><a href="../fit_update/#Transformers">Transformers</a> ordinarily implement <code>transform</code> instead of <code>predict</code>. For more on <code>predict</code> versus <code>transform</code>, see <a href="../predict_transform/#Predict-or-transform?">Predict or transform?</a></p><p>Two other <code>fit</code>/<code>predict</code>/<code>transform</code> patterns supported by LearnAPI.jl are: <a href="../kinds_of_learner/#LearnAPI.Generative"><code>LearnAPI.Generative</code></a> which has the form:</p><pre><code class="language-julia hljs">model = fit(learner, data)
predict(model) # a single distribution, for example</code></pre><p>and <a href="../kinds_of_learner/#LearnAPI.Static"><code>LearnAPI.Static</code></a>, which looks like this:</p><pre><code class="language-julia hljs">model = fit(learner) # no `data` argument
predict(model, data) # may mutate `model` to record byproducts of computation</code></pre><p>Do not read too much into the names for these patterns, which are formalized <a href="../kinds_of_learner/#kinds_of_learner">here</a>. Use may not always correspond to prior associations.</p><p>Elaborating on the common <code>Descriminative</code> pattern above, this tutorial details an implementation of the LearnAPI.jl for naive <a href="https://en.wikipedia.org/wiki/Ridge_regression">ridge regression</a> with no intercept. The kind of workflow we want to enable has been previewed in <a href="../#Sample-workflow">Sample workflow</a>. Readers can also refer to the <a href="#workflow">demonstration</a> of the implementation given later.</p><div class="admonition is-success" id="Quick-Start-for-new-implementations-417704cac73d8678"><header class="admonition-header">Quick Start for new implementations<a class="admonition-anchor" href="#Quick-Start-for-new-implementations-417704cac73d8678" title="Permalink"></a></header><div class="admonition-body"><ol><li>From this tutorial, read at least &quot;<a href="#A-basic-implementation">A basic implementation</a>&quot; below.</li><li>Looking over the examples in &quot;<a href="../common_implementation_patterns/#patterns">Common Implementation Patterns</a>&quot;, identify the appropriate core learner pattern above for your algorithm.</li><li>Implement <code>fit</code> (probably following an existing example). Read the <a href="../fit_update/#LearnAPI.fit"><code>fit</code></a> document string to see what else may need to be implemented, paying particular attention to the &quot;New implementations&quot; section.</li><li>Rinse and repeat with each new method implemented.</li><li>Identify any additional <a href="../traits/#traits">learner traits</a> that have appropriate overloadings; use the <a href="../reference/#LearnAPI.@trait"><code>@trait</code></a> macro to define these in one block.</li><li>Ensure your implementation includes the compulsory method <a href="../accessor_functions/#LearnAPI.learner"><code>LearnAPI.learner</code></a> and compulsory traits <a href="../traits/#LearnAPI.constructor"><code>LearnAPI.constructor</code></a> and <a href="../traits/#LearnAPI.functions"><code>LearnAPI.functions</code></a>. Read and apply &quot;<a href="@ref">Testing your implementation</a>&quot;.</li></ol><p>If you get stuck, refer back to this tutorial and the <a href="../reference/#reference">Reference</a> sections.</p></div></div><h2 id="A-basic-implementation"><a class="docs-heading-anchor" href="#A-basic-implementation">A basic implementation</a><a id="A-basic-implementation-1"></a><a class="docs-heading-anchor-permalink" href="#A-basic-implementation" title="Permalink"></a></h2><p>See <a href="../examples/#code">here</a> for code without explanations.</p><p>Let us suppose our algorithm&#39;s <code>fit</code> method is to consume data in the form <code>(X, y)</code>, where <code>X</code> is a suitable table¹ (the features, a.k.a., covariates or predictors) and <code>y</code> a vector (the target, a.k.a., labels or response).</p><p>The first line below imports the lightweight package LearnAPI.jl whose methods we will be extending. The second imports libraries needed for the core algorithm.</p><pre><code class="language-julia hljs">using LearnAPI
using LinearAlgebra, Tables</code></pre><h3 id="Defining-learners"><a class="docs-heading-anchor" href="#Defining-learners">Defining learners</a><a id="Defining-learners-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-learners" title="Permalink"></a></h3><p>Here&#39;s a new type whose instances specify the single ridge regression hyperparameter:</p><pre><code class="language-julia hljs">struct Ridge{T&lt;:Real}
    lambda::T
end</code></pre><p>Instances of <code>Ridge</code> are <em><a href="../reference/#learners">learners</a></em>, in LearnAPI.jl parlance.</p><p>Associated with each new type of LearnAPI.jl learner will be a keyword argument constructor, providing default values for all properties (typically, struct fields) that are not other learners, and we must implement <a href="../traits/#LearnAPI.constructor"><code>LearnAPI.constructor(learner)</code></a>, for recovering the constructor from an instance:</p><pre><code class="language-julia hljs">&quot;&quot;&quot;
    Ridge(; lambda=0.1)

Instantiate a ridge regression learner, with regularization of `lambda`.
&quot;&quot;&quot;
Ridge(; lambda=0.1) = Ridge(lambda)
LearnAPI.constructor(::Ridge) = Ridge</code></pre><p>For example, in this case, if <code>learner = Ridge(0.2)</code>, then <code>LearnAPI.constructor(learner)(lambda=0.2) == learner</code> is true. Note that we attach the docstring to the <em>constructor</em>, not the struct.</p><h3 id="Implementing-fit"><a class="docs-heading-anchor" href="#Implementing-fit">Implementing <code>fit</code></a><a id="Implementing-fit-1"></a><a class="docs-heading-anchor-permalink" href="#Implementing-fit" title="Permalink"></a></h3><p>A ridge regressor requires two types of data for training: input features <code>X</code>, which here we suppose are tabular¹, and a <a href="../reference/#proxy">target</a> <code>y</code>, which we suppose is a vector.⁴</p><p>It is convenient to define a new type for the <code>fit</code> output, which will include coefficients labelled by feature name for inspection after training:</p><pre><code class="language-julia hljs">struct RidgeFitted{T,F}
    learner::Ridge
    coefficients::Vector{T}
    named_coefficients::F
end</code></pre><p>Note that we also include <code>learner</code> in the struct, for it must be possible to recover <code>learner</code> from the output of <code>fit</code>; see <a href="#af">Accessor functions</a> below.</p><p>The implementation of <code>fit</code> looks like this:</p><pre><code class="language-julia hljs">function LearnAPI.fit(learner::Ridge, data; verbosity=LearnAPI.default_verbosity())
    X, y = data

    # data preprocessing:
    table = Tables.columntable(X)
    names = Tables.columnnames(table) |&gt; collect
    A = Tables.matrix(table, transpose=true)

    lambda = learner.lambda

    # apply core algorithm:
    coefficients = (A*A&#39; + learner.lambda*I)\(A*y) # vector

    # determine named coefficients:
    named_coefficients = [names[j] =&gt; coefficients[j] for j in eachindex(names)]

    # make some noise, if allowed:
    verbosity &gt; 0 &amp;&amp; @info &quot;Coefficients: $named_coefficients&quot;

    return RidgeFitted(learner, coefficients, named_coefficients)
end</code></pre><h3 id="Implementing-predict"><a class="docs-heading-anchor" href="#Implementing-predict">Implementing <code>predict</code></a><a id="Implementing-predict-1"></a><a class="docs-heading-anchor-permalink" href="#Implementing-predict" title="Permalink"></a></h3><p>One way users will be able to call <code>predict</code> is like this:</p><pre><code class="language-julia hljs">predict(model, Point(), Xnew)</code></pre><p>where <code>Xnew</code> is a table (of the same form as <code>X</code> above). The argument <code>Point()</code> signals that literal predictions of the target variable are sought, as opposed to some proxy for the target, such as probability density functions.  <code>Point</code> is an example of a <a href="../kinds_of_target_proxy/#proxy_types"><code>LearnAPI.KindOfProxy</code></a> type. Targets and target proxies are discussed <a href="../reference/#proxy">here</a>.</p><p>We provide this implementation for our ridge regressor:</p><pre><code class="language-julia hljs">LearnAPI.predict(model::RidgeFitted, ::Point, Xnew) =
    Tables.matrix(Xnew)*model.coefficients</code></pre><p>If the kind of proxy is omitted, as in <code>predict(model, Xnew)</code>, then a fallback grabs the first element of the tuple returned by <a href="../traits/#LearnAPI.kinds_of_proxy"><code>LearnAPI.kinds_of_proxy(learner)</code></a>, which we overload appropriately below.</p><h3 id="Data-deconstructors:-target-and-features"><a class="docs-heading-anchor" href="#Data-deconstructors:-target-and-features">Data deconstructors: <code>target</code> and <code>features</code></a><a id="Data-deconstructors:-target-and-features-1"></a><a class="docs-heading-anchor-permalink" href="#Data-deconstructors:-target-and-features" title="Permalink"></a></h3><p>LearnAPI.jl is flexible about the form of training <code>data</code>. However, to buy into meta-functionality, such as cross-validation, we&#39;ll need to say something about the structure of this data. We implement <a href="../features_target_weights/#LearnAPI.target"><code>LearnAPI.target</code></a> to say what part of the data constitutes a <a href="../reference/#proxy">target variable</a>, and <a href="../features_target_weights/#LearnAPI.features"><code>LearnAPI.features</code></a> to say what are the features (valid <code>newdata</code> in a <code>predict(model, newdata)</code> call):</p><pre><code class="language-julia hljs">LearnAPI.target(learner::Ridge, (X, y)) = y
LearnAPI.features(learner::Ridge, (X, y)) = X</code></pre><p>Another data deconstructor, for learners that support per-observation weights in training, is <a href="../features_target_weights/#LearnAPI.weights"><code>LearnAPI.weights</code></a>.</p><h3 id="af"><a class="docs-heading-anchor" href="#af">Accessor functions</a><a id="af-1"></a><a class="docs-heading-anchor-permalink" href="#af" title="Permalink"></a></h3><p>An <a href="../accessor_functions/#accessor_functions">accessor function</a> has the output of <a href="../fit_update/#LearnAPI.fit"><code>fit</code></a> as it&#39;s sole argument.  Every new implementation must implement the accessor function <a href="../accessor_functions/#LearnAPI.learner"><code>LearnAPI.learner</code></a> for recovering a learner from a fitted object:</p><pre><code class="language-julia hljs">LearnAPI.learner(model::RidgeFitted) = model.learner</code></pre><p>Other accessor functions extract learned parameters or some standard byproducts of training, such as feature importances or training losses.² Here we implement an accessor function to extract the linear coefficients:</p><pre><code class="language-julia hljs">LearnAPI.coefficients(model::RidgeFitted) = model.named_coefficients</code></pre><p>The <a href="../accessor_functions/#Base.strip"><code>LearnAPI.strip(model)</code></a> accessor function is for returning a version of <code>model</code> suitable for serialization (typically smaller and data anonymized). It has a fallback that just returns <code>model</code> but for the sake of illustration, we overload it to dump the named version of the coefficients:</p><pre><code class="language-julia hljs">LearnAPI.strip(model::RidgeFitted) =
    RidgeFitted(model.learner, model.coefficients, nothing)</code></pre><p>Crucially, we can still use <code>LearnAPI.strip(model)</code> in place of <code>model</code> to make new predictions.</p><h3 id="Learner-traits"><a class="docs-heading-anchor" href="#Learner-traits">Learner traits</a><a id="Learner-traits-1"></a><a class="docs-heading-anchor-permalink" href="#Learner-traits" title="Permalink"></a></h3><p>Learner <a href="../traits/#traits">traits</a> record extra generic information about a learner, or make specific promises of behavior. They are methods that have a learner as the sole argument, and so we regard <a href="../traits/#LearnAPI.constructor"><code>LearnAPI.constructor</code></a> defined above as a trait.</p><p>Because we have implemented <code>predict</code>, we are required to overload the <a href="../traits/#LearnAPI.kinds_of_proxy"><code>LearnAPI.kinds_of_proxy</code></a> trait. Because we can only make point predictions of the target, we make this definition:</p><pre><code class="language-julia hljs">LearnAPI.kinds_of_proxy(::Ridge) = (Point(),)</code></pre><p>A macro provides a shortcut, convenient when multiple traits are to be defined:</p><pre><code class="language-julia hljs">@trait(
    Ridge,
    constructor = Ridge,
    kinds_of_proxy=(Point(),),
    tags = (&quot;regression&quot;,),
    functions = (
        :(LearnAPI.fit),
        :(LearnAPI.learner),
        :(LearnAPI.clone),
        :(LearnAPI.strip),
        :(LearnAPI.obs),
        :(LearnAPI.features),
        :(LearnAPI.target),
        :(LearnAPI.predict),
        :(LearnAPI.coefficients),
   )
)</code></pre><p><a href="../traits/#LearnAPI.functions"><code>LearnAPI.functions</code></a> (discussed further below) and <a href="../traits/#LearnAPI.constructor"><code>LearnAPI.constructor</code></a>, are the only universally compulsory traits. However, it is worthwhile studying the <a href="../traits/#traits_list">list of all traits</a> to see which might apply to a new implementation, to enable maximum buy into functionality provided by third party packages, and to assist third party algorithms that match machine learning algorithms to user-defined tasks.</p><p>With <a href="../traits/#trait_contract">some exceptions</a>, the value of a trait should depend only on the <em>type</em> of the argument.</p><h3 id="The-functions-trait"><a class="docs-heading-anchor" href="#The-functions-trait">The <code>functions</code> trait</a><a id="The-functions-trait-1"></a><a class="docs-heading-anchor-permalink" href="#The-functions-trait" title="Permalink"></a></h3><p>The last trait, <code>functions</code>, above returns a list of all LearnAPI.jl methods that can be meaningfully applied to the learner or the output of <code>fit</code> (denoted <code>model</code> above), with the exception of traits. You always include the first five you see here: <code>fit</code>, <code>learner</code>, <code>clone</code> ,<code>strip</code>, <code>obs</code>. Here <a href="../reference/#LearnAPI.clone"><code>clone</code></a> is a utility function provided by LearnAPI that you never overload, while <a href="../obs/#LearnAPI.obs"><code>obs</code></a> is discussed under <a href="#Providing-a-separate-data-front-end">Providing a separate data front end</a> below and is always included because it has a meaningful fallback.</p><p>See <a href="../traits/#LearnAPI.functions"><code>LearnAPI.functions</code></a> for a checklist of what the <code>functions</code> trait needs to return.</p><h3 id="Signatures-added-for-convenience"><a class="docs-heading-anchor" href="#Signatures-added-for-convenience">Signatures added for convenience</a><a id="Signatures-added-for-convenience-1"></a><a class="docs-heading-anchor-permalink" href="#Signatures-added-for-convenience" title="Permalink"></a></h3><p>We add one <code>fit</code> signature for user-convenience only. The LearnAPI.jl specification has nothing to say about <code>fit</code> signatures with more than two positional arguments.</p><pre><code class="language-julia hljs">LearnAPI.fit(learner::Ridge, X, y; kwargs...) = fit(learner, (X, y); kwargs...)</code></pre><h2 id="workflow"><a class="docs-heading-anchor" href="#workflow">Demonstration</a><a id="workflow-1"></a><a class="docs-heading-anchor-permalink" href="#workflow" title="Permalink"></a></h2><p>We now illustrate how to interact directly with <code>Ridge</code> instances using the methods just implemented.</p><pre><code class="language-julia hljs"># synthesize some data:
n = 10 # number of observations
train = 1:6
test = 7:10
a, b, c = rand(n), rand(n), rand(n)
X = (; a, b, c)
y = 2a - b + 3c + 0.05*rand(n)</code></pre><pre><code class="language-julia hljs">learner = Ridge(lambda=0.5)
@functions learner</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(LearnAPI.fit, LearnAPI.learner, LearnAPI.clone, strip, LearnAPI.obs, LearnAPI.features, LearnAPI.target, LearnAPI.predict, LearnAPI.coefficients)</code></pre><p>(Exact output may differ here because of way documentation is generated.)</p><p>Training and predicting:</p><pre><code class="language-julia hljs">Xtrain = Tables.subset(X, train)
ytrain = y[train]
model = fit(learner, (Xtrain, ytrain))  # `fit(learner, Xtrain, ytrain)` will also work
ŷ = predict(model, Tables.subset(X, test))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 0.5570507529044278
 2.2247506379321993
 2.683412485483239
 2.481205874106442</code></pre><p>Extracting coefficients:</p><pre><code class="language-julia hljs">LearnAPI.coefficients(model)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Pair{Symbol, Float64}}:
 :a =&gt; 1.1082147594607592
 :b =&gt; 0.25407409321041097
 :c =&gt; 2.1262304472487723</code></pre><p>Serialization/deserialization:</p><pre><code class="language-julia hljs">using Serialization
small_model = LearnAPI.strip(model)
filename = tempname()
serialize(filename, small_model)</code></pre><pre><code class="language-julia hljs">recovered_model = deserialize(filename)
@assert LearnAPI.learner(recovered_model) == learner
@assert predict(recovered_model, X) == predict(model, X)</code></pre><h3 id="Testing-an-implementation"><a class="docs-heading-anchor" href="#Testing-an-implementation">Testing an implementation</a><a id="Testing-an-implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Testing-an-implementation" title="Permalink"></a></h3><pre><code class="language-julia hljs">using LearnTestAPI
@testapi learner (X, y) verbosity=0</code></pre><h2 id="di"><a class="docs-heading-anchor" href="#di">Other data patterns</a><a id="di-1"></a><a class="docs-heading-anchor-permalink" href="#di" title="Permalink"></a></h2><p>Here are some important remarks for implementations deviating in their assumptions about data from those made above.</p><ul><li><p>New implementations of <code>fit</code>, <code>predict</code>, etc, always have a <em>single</em> <code>data</code> argument as above.  For convenience, a signature such as <code>fit(learner, table, formula)</code>, calling <code>fit(learner, (table, formula))</code>, can be added, but the LearnAPI.jl specification is silent on the meaning or existence of signatures with extra arguments.</p></li><li><p>If the <code>data</code> object consumed by <code>fit</code>, <code>predict</code>, or <code>transform</code> is not not a suitable table¹, array³, tuple of tables and arrays, or some other object implementing the <a href="https://juliaml.github.io/MLCore.jl/dev/">MLCore.jl</a> <code>getobs</code>/<code>numobs</code> interface, then an implementation must: (i) overload <a href="../obs/#LearnAPI.obs"><code>obs</code></a> to articulate how provided data can be transformed into a form that does support this interface, as illustrated below under <a href="#Providing-a-separate-data-front-end">Providing a separate data front end</a> below; or (ii) overload the trait <a href="../traits/#LearnAPI.data_interface"><code>LearnAPI.data_interface</code></a> to specify a more relaxed data API.</p></li></ul><h2 id="Providing-a-separate-data-front-end"><a class="docs-heading-anchor" href="#Providing-a-separate-data-front-end">Providing a separate data front end</a><a id="Providing-a-separate-data-front-end-1"></a><a class="docs-heading-anchor-permalink" href="#Providing-a-separate-data-front-end" title="Permalink"></a></h2><p>See <a href="../examples/#code">here</a> for code without explanations.</p><p>An implementation may optionally implement <a href="../obs/#LearnAPI.obs"><code>obs</code></a>, to expose to the user (or some meta-algorithm like cross-validation) the representation of input data internal to <code>fit</code> or <code>predict</code>, such as the matrix version <code>A</code> of <code>X</code> in the ridge example.  That is, we may factor out of <code>fit</code> (and also <code>predict</code>) a data preprocessing step, <code>obs</code>, to expose its outcomes. These outcomes become alternative user inputs to <code>fit</code>/<code>predict</code>.</p><p>The <a href="../obs/#LearnAPI.obs"><code>obs</code></a> methods exist to:</p><ul><li><p>Enable meta-algorithms to avoid redundant conversions of user-provided data into the form ultimately used by the core training algorithms.</p></li><li><p>Through the provision of canned data front ends, enable users to provide data in a variety of formats, while allowing new implementations to focus on core algorithms that consume a standardized, preprocessed, representation of that data.</p></li></ul><div class="admonition is-category-important" id="Important-e1f5ed5f4279cc59"><header class="admonition-header">Important<a class="admonition-anchor" href="#Important-e1f5ed5f4279cc59" title="Permalink"></a></header><div class="admonition-body"><p>While many new learner implementations will want to adopt a canned data front end, such as those provided by <a href="https://juliaai.github.io/LearnDataFrontEnds.jl/dev/">LearnDataFrontEnds.jl</a>, we focus here on a self-contained implementation of <code>obs</code> for the ridge example above, to show how it works.</p></div></div><p>In the typical case, where <a href="../traits/#LearnAPI.data_interface"><code>LearnAPI.data_interface</code></a> is not overloaded, the alternative data representations must implement the MLCore.jl <code>getobs/numobs</code> interface for observation subsampling, which is generally all a user or meta-algorithm will need, before passing the data on to <code>fit</code>/<code>predict</code>, as you would the original data.</p><p>So, instead of the pattern</p><pre><code class="language-julia hljs">model = fit(learner, data)
predict(model, newdata)</code></pre><p>one enables the following alternative:</p><pre><code class="language-julia hljs">observations = obs(learner, data) # preprocessed training data

# optional subsampling:
observations = MLCore.getobs(observations, train_indices)

model = fit(learner, observations)

newobservations = obs(model, newdata)

# optional subsampling:
newobservations = MLCore.getobs(observations, test_indices)

predict(model, newobservations)</code></pre><p>which works for any <a href="../kinds_of_learner/#LearnAPI.Descriminative"><code>LearnAPI.Descriminative</code></a> learner implementing <code>predict</code>, no matter how one is supposed to accesses the individual observations of <code>data</code> or <code>newdata</code>. See also the demonstration <a href="#advanced_demo">below</a>. Furthermore, fallbacks ensure the above pattern still works if we choose not to implement a front end at all, which is allowed, if supported <code>data</code> and <code>newdata</code> already implement <code>getobs</code>/<code>numobs</code>.</p><p>In the ridge regression example we specifically wrap all the preprocessed data into single object, for which we introduce a new type:</p><pre><code class="language-julia hljs">struct RidgeFitObs{T,M&lt;:AbstractMatrix{T}}
    A::M                  # `p` x `n` matrix
    names::Vector{Symbol} # features
    y::Vector{T}          # target
end</code></pre><p>Now we overload <code>obs</code> to carry out the data preprocessing previously in <code>fit</code>, like this:</p><pre><code class="language-julia hljs">function LearnAPI.obs(::Ridge, data)
    X, y = data
    table = Tables.columntable(X)
    names = Tables.columnnames(table) |&gt; collect
    return RidgeFitObs(Tables.matrix(table)&#39;, names, y)
end</code></pre><p>We informally refer to the output of <code>obs</code> as &quot;observations&quot; (see &quot;<a href="#The-obs-contract">The <code>obs</code> contract</a>&quot; below). The previous core <code>fit</code> signature is now replaced with two methods - one to handle &quot;regular&quot; input, and one to handle the pre-processed data (observations) which appears first below:</p><pre><code class="language-julia hljs">function LearnAPI.fit(learner::Ridge, observations::RidgeFitObs; verbosity=LearnAPI.default_verbosity())

    lambda = learner.lambda

    A = observations.A
    names = observations.names
    y = observations.y

    # apply core learner:
    coefficients = (A*A&#39; + learner.lambda*I)\(A*y) # 1 x p matrix

    # determine named coefficients:
    named_coefficients = [names[j] =&gt; coefficients[j] for j in eachindex(names)]

    # make some noise, if allowed:
    verbosity &gt; 0 &amp;&amp; @info &quot;Coefficients: $named_coefficients&quot;

    return RidgeFitted(learner, coefficients, named_coefficients)

end

LearnAPI.fit(learner::Ridge, data; kwargs...) =
    fit(learner, obs(learner, data); kwargs...)</code></pre><h3 id="The-obs-contract"><a class="docs-heading-anchor" href="#The-obs-contract">The <code>obs</code> contract</a><a id="The-obs-contract-1"></a><a class="docs-heading-anchor-permalink" href="#The-obs-contract" title="Permalink"></a></h3><p>Providing <code>fit</code> signatures matching the output of <a href="../obs/#LearnAPI.obs"><code>obs</code></a>, is the first part of the <code>obs</code> contract. Since <code>obs(learner, data)</code> should evidently support all <code>data</code> that <code>fit(learner, data)</code> supports, we must be able to apply <code>obs(learner, _)</code> to it&#39;s own output (<code>observations</code> below). This leads to the additional declaration</p><pre><code class="language-julia hljs">LearnAPI.obs(::Ridge, observations::RidgeFitObs) = observations</code></pre><p>In other words, we ensure that <code>obs(learner, _)</code> is <a href="https://en.wikipedia.org/wiki/Involution_(mathematics)">involutive</a>.</p><p>The second part of the <code>obs</code> contract is this: <em>The output of <code>obs</code> must implement the interface specified by the trait</em> <a href="../traits/#LearnAPI.data_interface"><code>LearnAPI.data_interface(learner)</code></a>. Assuming this is <a href="../obs/#LearnAPI.RandomAccess"><code>LearnAPI.RandomAccess()</code></a> (the default) it usually suffices to overload <code>Base.getindex</code> and <code>Base.length</code>:</p><pre><code class="language-julia hljs">Base.getindex(data::RidgeFitObs, I) =
    RidgeFitObs(data.A[:,I], data.names, y[I])
Base.length(data::RidgeFitObs) = length(data.y)</code></pre><p>We do something similar for <code>predict</code>, but there&#39;s no need for a new type in this case:</p><pre><code class="language-julia hljs">LearnAPI.obs(::RidgeFitted, Xnew) = Tables.matrix(Xnew)&#39;
LearnAPI.obs(::RidgeFitted, observations::AbstractArray) = observations # involutivity

LearnAPI.predict(model::RidgeFitted, ::Point, observations::AbstractMatrix) =
    observations&#39;*model.coefficients

LearnAPI.predict(model::RidgeFitted, ::Point, Xnew) =
    predict(model, Point(), obs(model, Xnew))</code></pre><h3 id="Data-deconstructors:-features-and-target"><a class="docs-heading-anchor" href="#Data-deconstructors:-features-and-target">Data deconstructors: <code>features</code> and <code>target</code></a><a id="Data-deconstructors:-features-and-target-1"></a><a class="docs-heading-anchor-permalink" href="#Data-deconstructors:-features-and-target" title="Permalink"></a></h3><p>These methods must be able to handle any <code>data</code> supported by <code>fit</code>, which includes the output of <code>obs(learner, data)</code>:</p><pre><code class="language-julia hljs">LearnAPI.features(::Ridge, observations::RidgeFitObs) = observations.A
LearnAPI.features(learner::Ridge, data) = LearnAPI.features(learner, obs(learner, data))
LearnAPI.target(::Ridge, observations::RidgeFitObs) = observations.y
LearnAPI.target(learner::Ridge, data) = LearnAPI.target(learner, obs(learner, data))</code></pre><h3 id="Important-notes:"><a class="docs-heading-anchor" href="#Important-notes:">Important notes:</a><a id="Important-notes:-1"></a><a class="docs-heading-anchor-permalink" href="#Important-notes:" title="Permalink"></a></h3><ul><li><p>The observations to be consumed by <code>fit</code> are returned by <code>obs(learner::Ridge, ...)</code>, while those consumed by <code>predict</code> are returned by <code>obs(model::RidgeFitted, ...)</code>. We need the different signatures because the form of data consumed by <code>fit</code> and <code>predict</code> are generally different.</p></li><li><p>We need the adjoint operator, <code>&#39;</code>, because the last dimension in arrays is the observation dimension, according to the MLCore.jl convention. Remember, <code>Xnew</code> is a table here.</p></li></ul><p>Since LearnAPI.jl provides fallbacks for <code>obs</code> that simply return the unadulterated data argument, overloading <code>obs</code> is optional. This is provided data in publicized <code>fit</code>/<code>predict</code> signatures already consists only of objects implementing the <a href="../obs/#LearnAPI.RandomAccess"><code>LearnAPI.RandomAccess</code></a> interface (most tables¹, arrays³, and tuples thereof).</p><p>To opt out of supporting the MLCore.jl interface altogether, an implementation must overload the trait, <a href="../traits/#LearnAPI.data_interface"><code>LearnAPI.data_interface(learner)</code></a>. See <a href="../obs/#data_interfaces">Data interfaces</a> for details.</p><h3 id="Addition-of-signatures-for-user-convenience"><a class="docs-heading-anchor" href="#Addition-of-signatures-for-user-convenience">Addition of signatures for user convenience</a><a id="Addition-of-signatures-for-user-convenience-1"></a><a class="docs-heading-anchor-permalink" href="#Addition-of-signatures-for-user-convenience" title="Permalink"></a></h3><p>As above, we add a signature for convenience, which the LearnAPI.jl specification neither requires nor forbids:</p><pre><code class="language-julia hljs">LearnAPI.fit(learner::Ridge, X, y; kwargs...)  = fit(learner, (X, y); kwargs...)</code></pre><h2 id="advanced_demo"><a class="docs-heading-anchor" href="#advanced_demo">Demonstration of an advanced <code>obs</code> workflow</a><a id="advanced_demo-1"></a><a class="docs-heading-anchor-permalink" href="#advanced_demo" title="Permalink"></a></h2><p>We now can train and predict using internal data representations, resampled using the generic MLCore.jl interface:</p><pre><code class="language-julia hljs">import MLCore
learner = Ridge()
observations_for_fit = obs(learner, (X, y))
model = fit(learner, MLCore.getobs(observations_for_fit, train))
observations_for_predict = obs(model, X)
ẑ = predict(model, MLCore.getobs(observations_for_predict, test))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 2.211822149227018
 1.3290752469540321
 0.10563387149892679
 0.915672529255274</code></pre><pre><code class="language-julia hljs">@assert ẑ == ŷ</code></pre><p>For an application of <a href="../obs/#LearnAPI.obs"><code>obs</code></a> to efficient cross-validation, see <a href="../obs/#obs_workflows">here</a>.</p><hr/><p>¹ In LearnAPI.jl a <em>table</em> is any object <code>X</code> implementing the <a href="https://tables.juliadata.org/dev/">Tables.jl</a> interface, additionally satisfying <code>Tables.istable(X) == true</code> and implementing <code>DataAPI.nrow</code> (and whence <code>MLCore.numobs</code>). Tables that are also (unnamed) tuples are disallowed.</p><p>² An implementation can provide further accessor functions, if necessary, but like the native ones, they must be included in the <a href="../traits/#LearnAPI.functions"><code>LearnAPI.functions</code></a> declaration.</p><p>³ The last index must be the observation index.</p><p>⁴ The <code>data = (X, y)</code> pattern implemented here is not the only supported pattern. For, example, <code>data</code> might be <code>(T, formula)</code> where <code>T</code> is a table and <code>formula</code> is an R-style formula.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../reference/">Overview »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Sunday 19 October 2025 01:10">Sunday 19 October 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
